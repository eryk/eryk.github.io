<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2020-11-29 Quantopian投资组合和绩效分析工具_Pyfolio</title>
    <url>/2020/11/29/2020-11-29%20Quantopian%E6%8A%95%E8%B5%84%E7%BB%84%E5%90%88%E5%92%8C%E7%BB%A9%E6%95%88%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7_Pyfolio/</url>
    <content><![CDATA[<p>title: Quantopian投资组合和绩效分析工具：Pyfolio<br>
date: 2020-11-29 09:53:00<br>
categories: 量化交易系统<br>
tags: [Pyfolio]</p>
<h3 id="介绍">介绍</h3>
<p>pyfolio是由Quantopian开发的Python库，用于对金融投资组合进行绩效和风险分析。它与Zipline开源回溯测试库配合使用良好。<br>
pyfolio的核心是所谓的“tear sheet ”，它由各种单独的图组成，这些图提供了交易算法性能的全面图像展示。</p>
<h3 id="入门示例">入门示例</h3>
<p>这里以双均线策略来做演示，当20日均线上穿40日均线买入股票，当20日均线下穿40日均线则卖出股票，首先我们通过tushare获取股票历史数据</p>
<pre><code class="language-python">import pandas as pd
import numpy as np
import tushare as ts
import pyfolio as pf

pro = ts.pro_api()
df = ts.pro_bar(ts_code='000001.SZ', adj='hfq', start_date='20150101', end_date='20191231')
df.index = pd.to_datetime(df['trade_date'])
df.sort_index(inplace=True)
</code></pre>
<p>接下来生成策略信号</p>
<pre><code class="language-python">df['ma20'] = df['close'].rolling(20).mean()
df['ma40'] = df['close'].rolling(40).mean()
# 计算20日均线和40日均线的距离
df['diff'] = df['ma20'] - df['ma40']
# 当diff值大于0买入股票，当diff值小于0卖出股票
df['signal'] = np.where(df['diff'] &gt; 0, 1, 0)
df['signal'] = np.where(df['diff'] &lt; 0, 0, df['signal'])
# 计算策略每日收益，这里计算每日收益使用log函数，signal计算由于使用了当天的收盘价，所以需要shift 1天，否则会用到未来数据
df['strategy'] = np.log(df['close'] / df['close'].shift(1)) * df['signal'].shift(1)
# 计算资产收益率
df['equity'] = df['strategy'].cumsum() + 1
</code></pre>
<p>展示资产收益率曲线，这里对股价做了归一化处理以便数据展示，可以看到双均线策略不仅跑赢股价，并且资金曲线回撤相对较小。</p>
<pre><code class="language-python">df['close_norm'] = df['close'] / float(df['close'][0])
df[['close_norm','equity']].plot(figsize=(12,6))
</code></pre>
<p>![image-20201129145038824](/Users/eryk/Library/Application Support/typora-user-images/image-20201129145038824.png)</p>
<p>上图看到的信息有限，接下来是使用pyfolio工具对投资回报进一步分析，代码如下:</p>
<pre><code class="language-python">pf.create_full_tear_sheet(df['strategy'], benchmark_rets=np.log(df['close'] / df['close'].shift(1)))
</code></pre>
<p>首先是返回汇总信息：</p>
<p>![image-20201129153825862](/Users/eryk/Library/Application Support/typora-user-images/image-20201129153825862.png)</p>
<p>介绍常用的几个指标：</p>
<ul>
<li>Annual return：年化回报率</li>
<li>Cumulative returns: 累计收益率，是策略从开始执行到结束的总资产收益率。</li>
<li>Annual volatility：年化波动率</li>
<li>Sharpe ratio：夏普比率，一种非常流行的风险指标。它表示每单位风险（通过标准差衡量）的超额收益（超过无风险利率）。</li>
<li>Sortino ratio: 索提诺比率，Sharpe比率的修改版本，其中标准偏差由下行偏差代替。下行偏差仅衡量该系列的负波动性，严格来说是在称为最低可接受收益的预定水平以下。</li>
<li>Maximum drawdown ：最大跌幅—指示峰和谷之间的最大跌幅（以％表示）</li>
<li>Tail ratio：对daily return的分布选取95分位和5分位，然后相除取绝对值。本质的含义就是赚取的return比亏钱的大多少倍。</li>
<li>Daily value at risk（daily Value-at-Risk ）<br>
每日风险价值-另一个非常流行的风险指标。在这种情况下，这表明在95％的情况下，将头寸（投资组合）再保留1天，损失不会超过2.3％。</li>
</ul>
<p>下图从各个角度对资产回报进行分析</p>
<p>![image-20201129154756841](/Users/eryk/Library/Application Support/typora-user-images/image-20201129154756841.png)</p>
<h3 id="参考">参考</h3>
<p><a href="https://quantopian.github.io/pyfolio/" target="_blank" rel="noopener">https://quantopian.github.io/pyfolio/</a><br>
<a href="https://zhuanlan.zhihu.com/p/118108419" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/118108419</a><br>
<a href="https://towardsdatascience.com/the-easiest-way-to-evaluate-the-performance-of-trading-strategies-in-python-4959fd798bb3" target="_blank" rel="noopener">https://towardsdatascience.com/the-easiest-way-to-evaluate-the-performance-of-trading-strategies-in-python-4959fd798bb3</a></p>
]]></content>
  </entry>
  <entry>
    <title>Quantopian单因子分析工具：Alphalens</title>
    <url>/2020/11/20/2020-11-20%20Quantopian%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90%E5%88%A9%E5%99%A8_Alphalens/</url>
    <content><![CDATA[<p>Quantopian是国外著名的量化交易平台，早期聚宽就是仿照这个网站开发的，算是这类平台的鼻祖了，可惜Quantopian最近刚宣布要停止运营了。Quantopian开发了许多优秀的开源项目，其中比较著名的有zipline、pyfolio和alphalens，zipline是事件驱动的回测引擎，Alphalens与Zipline开源回溯测试库以及Pyfolio配合使用，Pyfolio提供金融投资组合的绩效和风险分析。</p>
<p>Alphalens主要功能是alpha因子的相关性统计数据和图表展示，包括：</p>
<ul>
<li>Returns Analysis</li>
<li>Information Coefficient Analysis</li>
<li>Turnover Analysis</li>
<li>Grouped Analysis</li>
</ul>
<p>下面通过一个例子来了解下Alphalens的主要用法，最重要的函数有两个:</p>
<ul>
<li>
<p>get_clean_factor_and_forward_returns：数据预处理，将因子数据，价格数据和组映射格式化为包含对齐的时间戳和资产代码的MultiIndex索引的DataFrame。返回的数据将被格式化为适合Alphalens函数的格式。因子数据格式是MultiIndex索引，level0是时间，level1是资产代码，数据值只有一列为因子值，数据格式如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20201121235400.png" alt=""></p>
</li>
<li>
<p>create_full_tear_sheet: 生成全面的单因子分析和评估数据。</p>
</li>
</ul>
<p>通过tushare获取A股股票数据，并将结果处理成get_clean_factor_and_forward_returns参数要求的格式</p>
<pre><code class="language-python">import pandas as pd
import tushare as ts

pro = ts.pro_api()
# 此接口获取的数据为未复权数据，回测建议使用后复权数据，这里为批量获取股票数据做了简化
df = pro.daily(ts_code='000001.SZ,600000.SH', start_date='20200101', end_date='20201231')
df.index = pd.to_datetime(df['trade_date'])
df.index.name = None
df.sort_index(inplace=True)
# MultiIndex，level0为日期，level1为股票代码，assets为get_clean_factor_and_forward_returns所需的因子数据格式
assets = df.set_index([df.index, df['ts_code']], drop=True)
# column为股票代码，index为日期，值为股票收盘价
close = df.pivot_table(index='trade_date',columns='ts_code',values='close')
close.index = pd.to_datetime(close.index)
</code></pre>
<p>生成的assets格式入下图所示，红框为index：</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20201122003628.png" alt=""></p>
<p>生成的close格式如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20201122003811.png" alt=""></p>
<p>接下来使用alphalens工具对数据进行分析，这里我们使用股票涨跌幅(字段名为pct_chg)作为因子数据</p>
<pre><code class="language-python">from alphalens.utils import get_clean_factor_and_forward_returns
from alphalens.tears import create_full_tear_sheet
# 需要将pct_chg做shift处理，否则将使用未来数据
ret = get_clean_factor_and_forward_returns(assets[['pct_chg']].shift(2),close)
create_full_tear_sheet(ret, long_short=False)
</code></pre>
<p>使用默认参数的情况下，ret将包含未来1、5、10日收益率，factor因子值，这里对应pct_chg列，factor_quantile为因子分组结果，默认会将因子分成5组，ret结果如图所示:</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20201122004722.png" alt=""></p>
<p>调用create_full_tear_sheet会生成因子分析结果，包含分位数统计信息、收益率信息、分组平均收益率柱状图、所有收益率分布图、单信号组合构建收益率图等，截取部分数据图如下：</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20201122005223.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20201122005156.png" alt=""></p>
<p>以上就是样例全部内容，可以看到alphalens功能非常丰富，还需要继续深入学习了解。</p>
<h3 id="参考">参考</h3>
<p><a href="http://quantopian.github.io/alphalens/" target="_blank" rel="noopener">http://quantopian.github.io/alphalens/</a></p>
<p><a href="https://www.quantopian.com/posts/alphalens-a-new-tool-for-analyzing-alpha-factors" target="_blank" rel="noopener">https://www.quantopian.com/posts/alphalens-a-new-tool-for-analyzing-alpha-factors</a></p>
]]></content>
      <categories>
        <category>量化交易系统</category>
      </categories>
      <tags>
        <tag>Alphalens</tag>
      </tags>
  </entry>
  <entry>
    <title>pandas-profiling 数据分析利器</title>
    <url>/2020/11/13/2020-11-13%20pandas-profiling-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%88%A9%E5%99%A8/</url>
    <content><![CDATA[<h3 id="介绍">介绍</h3>
<p>pandas-profiling可以为DataFrame生成一份报告，在pandas中 df.describe() 是比较基础的探索性数据分析函数，而pandas_profiling则是在DataFrame的基础上扩展，用于快速数据分析。</p>
<p>对于每个column，以下统计信息（与列类型相关）将显示在交互式HTML报告中：</p>
<ol>
<li>类型推断：检测DataFrame中列的类型。</li>
<li>概要：类型，唯一值，缺失值</li>
<li>分位数统计信息，例如最小值，Q1，中位数，Q3，最大值，范围，四分位数范围</li>
<li>描述性统计数据，例如均值，众数，标准偏差，和，中位数绝对偏差，变异系数，峰度，偏度</li>
<li>出现频率高的值</li>
<li>直方图</li>
<li>高度相关变量（Spearman，Pearson和Kendall矩阵）的相关性分析</li>
<li>缺失值：矩阵，计数（count），热图和缺失值树状图</li>
<li>重复行列出出现次数最多的重复行</li>
<li>文本分析：了解文本数据的类别（大写，空格），脚本（拉丁，西里尔字母）和块（ASCII）</li>
</ol>
<h3 id="安装">安装</h3>
<p>使用pip安装</p>
<blockquote>
<p>pip install pandas-profiling</p>
</blockquote>
<p>使用conda安装</p>
<blockquote>
<p>conda install -c anaconda pandas-profiling</p>
</blockquote>
<h3 id="一行代码生成报告">一行代码生成报告</h3>
<p>首先导入测试数据，这里我们使用tushare获取的股票数据来进行测试。</p>
<pre><code class="language-python">import pandas as pd
import tushare as ts
from pandas_profiling import ProfileReport

pro = ts.pro_api()
symbol = '000001.SZ'
df = ts.pro_bar(ts_code=symbol, adj='qfq', start_date='20200101', end_date='20201113')
df.index = pd.to_datetime(df['trade_date'])
df.index.name = None   # 这步不可缺少，否则生成报告时同名列会报错
df.sort_index(inplace=True)
</code></pre>
<p>接下来生成测试报告</p>
<pre><code class="language-python">report = ProfileReport(df.sample(frac=0.05), title='%s 股票分析' % symbol)
report.to_file(output_file='%s.html' % symbol)
</code></pre>
<p>报告汇总信息如下截图</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20201113162700.png" alt=""></p>
<h3 id="大数据问题解决方案">大数据问题解决方案</h3>
<p>当pandas-profiling应用在大数据量的DataFrame上运行速度会非常慢，这时候可以考虑使用以下办法解决。</p>
<h4 id="1-Minimal模式">1. Minimal模式</h4>
<p>在此模式下report会去掉一些耗时的计算操作，生成一份简略的数据分析报告。通过将参数minimal设置为True可以开启此模式。</p>
<pre><code class="language-python">profile = ProfileReport(large_dataset, minimal=True)
profile.to_file(&quot;output.html&quot;)
</code></pre>
<h4 id="2-采样">2. 采样</h4>
<p>采样方式可以有效降低数据量，但缺点是可能漏掉某些数量较小的错误情况。</p>
<pre><code class="language-python">tmp = df.sample(100) # 方法1，随机采样100条数据
tmp = df.sample(frac=0.01)   # 方法2，返回数据的比例，不可以跟上面的数值同时使用
</code></pre>
<h3 id="参考">参考</h3>
<p><a href="https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/" target="_blank" rel="noopener">https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>股票重大利好开盘封涨停买不到？试试这个办法</title>
    <url>/2020/03/01/2020-02-20%20%E8%82%A1%E7%A5%A8%E9%87%8D%E5%A4%A7%E5%88%A9%E5%A5%BD%E5%BC%80%E7%9B%98%E5%B0%81%E6%B6%A8%E5%81%9C%EF%BC%9F%E8%AF%95%E8%AF%95%E8%BF%99%E4%B8%AA%E5%8A%9E%E6%B3%95/</url>
    <content><![CDATA[<p>大家也许有过这种经历，关注的某只股票突发利好消息预判会连续涨停，赶紧打开炒股软件准备下单，发现这只股票已经涨停了，而且是几十万手的大单封死，根本没机会下手，随后几天只能看着股票一个涨停接一个涨停的一路上涨，后悔下手太慢。这种情况还有办法上车吗，散户一般能想到的办法都没戏，但是可以试试下面这种办法，吃不到肉但也许能喝口汤。</p>
<h3 id="ETF套利介绍">ETF套利介绍</h3>
<p>在介绍之前我们先了解下什么是ETF套利？ETF指的是交易型开放式指数基金，是一种在交易所上市交易，并且份额可以变动的一种开放式基金，它的手续与股票是完全一样的。由于一级市场和二级市场同时存在，不可避免会出现价格无法同步的显现，这种情况下就给一些机构跨市场套利提供了条件，而套利交易会让套利机会消失，让两个市场的价格差异得到控制，从而保证一级和二级市场价格的一致性。因为一级市场只能是机构投资者参与，所以我们一般的投资者是没办法进行ETF套利的。</p>
<h3 id="散户该如何操作呢">散户该如何操作呢</h3>
<p>那我们怎么参与涨停股票的交易呢，办法很简单，可以找出持有我们要买入的涨停股的ETF基金，再看看基金持有的股票数量占基金的比重，找持有股票占比大的基金买入。一般基金持仓比较分散，每只股票持有数量从百分之零点几到百分之十几不等，而且优质股票往往被上百只基金同时持有，如何快速找到持有股票的基金和比重呢？</p>
<h3 id="操作实战">操作实战</h3>
<p>以天齐锂业为例，我们从东方财富网上可以找到机构持仓明细 <a href="http://data.eastmoney.com/zlsj/detail/2019-12-31-0-002466.html%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E6%9C%89%E5%A4%9A%E7%A7%8D%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%9F%BA%E9%87%91%EF%BC%8C%E6%88%91%E4%BB%AC%E9%80%89%E6%8B%A9ETF%E5%9F%BA%E9%87%91%EF%BC%8C%E6%AF%94%E5%A6%82%E6%9C%80%E8%BF%91%E6%AF%94%E8%BE%83%E7%81%AB%E7%9A%84%E5%8D%8E%E5%A4%8F%E4%B8%AD%E8%AF%815G%E9%80%9A%E4%BF%A1%E4%B8%BB%E9%A2%98ETF" target="_blank" rel="noopener">http://data.eastmoney.com/zlsj/detail/2019-12-31-0-002466.html，可以看到有多种类型的基金，我们选择ETF基金，比如最近比较火的华夏中证5G通信主题ETF</a></p>
<p><img src="/uploads/image-20200301015233403.png" alt="image-20200301015233403"></p>
<p>进入到该基金的页面 <a href="http://fundact.eastmoney.com/fundinfo/515050.html?fund=515050%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%9F%A5%E7%9C%8B%E8%AF%A5%E5%9F%BA%E9%87%91%E6%8C%81%E6%9C%89%E7%9A%84%E5%89%8D%E5%8D%81%E5%A4%A7%E8%82%A1%E7%A5%A8%EF%BC%8C%E7%AC%AC%E4%B8%80%E5%90%8D%E5%B0%B1%E6%98%AF%E4%B8%AD%E5%85%B4%E9%80%9A%E4%BF%A1%EF%BC%8C%E5%8D%A0%E6%AF%949.90%25" target="_blank" rel="noopener">http://fundact.eastmoney.com/fundinfo/515050.html?fund=515050，可以查看该基金持有的前十大股票，第一名就是中兴通信，占比9.90%</a></p>
<p><img src="/uploads/image-20200301015411242.png" alt="image-20200301015411242"></p>
<p>了解以上的数据源之后，我们可以写个python程序快速的找到某只股票的基金持仓及占比情况，源码如下：</p>
<pre><code class="language-python">import requests
import execjs
from bs4 import BeautifulSoup

REQUEST_HEADER = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}


def get_stock_fundlist(symbol, date='2019-12-31'):
    &quot;&quot;&quot;
        查询股票被持有的基金及持仓占比
    :param symbol: 股票代码，例如: SZ000001
    :param date: 报告日期，例如：2019-12-31，2019-03-31
    :return:
    &quot;&quot;&quot;
    stock_url = 'http://data.eastmoney.com/zlsj/detail.aspx?type=ajax&amp;sr=-1&amp;p=1&amp;ps=1000&amp;stat=0&amp;code=%s&amp;date=%s&amp;rt=52763434'
    fund_url = 'http://fund.eastmoney.com/f10/FundArchivesDatas.aspx?type=jjcc&amp;code=%s&amp;topline=15'

    web_source = requests.get(stock_url % (symbol[2:], date), headers=REQUEST_HEADER, timeout=5)
    js_obj = execjs.compile(web_source.content.decode('gbk'))
    results = js_obj.eval('jsname')
    if 'data' not in results:
        return
    etf_list = [record['SHCode'] for record in results['data'] if record['SHCode'].startswith('5')]
    results = {}
    for code in etf_list[:]:
        web_source = requests.get(fund_url % code, headers=REQUEST_HEADER, timeout=5)
        html_source = web_source.content.decode()
        html_source = html_source.split(&quot;\&quot;&quot;)[1]
        soup = BeautifulSoup(html_source, 'lxml')
        items = soup.select(&quot;.tzxq&quot;)[0].select('tr')
        for item in items[1:]:
            if symbol[2:] not in item.text:
                continue
            fields = item.select('td')
            record = [field.text.strip() for field in fields if
                      field.text.strip() != '' and '变动' not in field.text]
            results[code] = record[3][:-1]
            break
    return sorted(results.items(), key=lambda kv: kv[1], reverse=True)


if __name__ == '__main__':
    print(get_stock_fundlist('SZ000063', '2019-12-31'))

</code></pre>
<p>执行代码输出结果如下：</p>
<pre><code class="language-shell">[('515050', '9.90'), ('570007', '6.87'), ('519668', '6.52'), ('501062', '5.37'), ('550002', '5.13'), ('515000', '5.10'), ('570006', '5.08'), ('501028', '4.81'), ('502013', '4.33'), ('501015', '4.26'), ('550015', '4.22'), ('515580', '4.19'), ('501026', '4.19'), ('512970', '3.94'), ('519929', '3.69'), ('515200', '3.32'), ('550001', '3.06'), ('550008', '3.05'), ('501081', '3.05'), ('550009', '2.99'), ('512220', '2.95'), ('501076', '2.26'), ('519013', '2.09'), ('515880', '10.75'), ('510080', '1.60'), ('590007', '0.99'), ('519676', '0.71')]

</code></pre>
<p>可以看到所有基金中持有中兴通讯最多份额的基金是515050，该基金持仓里中兴通讯占基金的比例为9.9%，意味着中兴通讯每涨停一天对基金会有0.99%的贡献。</p>
<p>当然，这个办法有很多的局限性，比如基金持有的股票多数是优质股，这种机会比较难碰到，而且指数型基金往往持仓非常分散，也不适用这种办法。如果基金中其他股票下跌也会造成基金下跌。</p>
<p>515050 5GETF这种主题基金比较适合这种个股利好涨停的，遇到针对整个行业的利好消息，这种主题型的ETF往往同时持有多只股票出现大幅上涨，2月24日当天，515050 这只基金除了中兴通讯涨停外，信维通信和沪电股份也出现了涨停，这三只股票基金持仓占比高达17.18%，如果之后出现了连续涨停的走势，对基金影响将非常明显。</p>
<p>除了515050 5GETF还有其他几个比较适合的，比如159995 芯片ETF，515700 新能车，512760 半导体50等，可以都关注着，没准哪天掉下来个利好呢。</p>
]]></content>
      <categories>
        <category>量化交易系统</category>
      </categories>
      <tags>
        <tag>ETF</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Python抓取同花顺资金流数据</title>
    <url>/2020/02/16/2020-02-16%20%E4%BD%BF%E7%94%A8Python%E6%8A%93%E5%8F%96%E5%90%8C%E8%8A%B1%E9%A1%BA%E8%B5%84%E9%87%91%E6%B5%81%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<p>今天我们通过一个例子来介绍python爬取数据的一般步骤，用到的工具包括python的经典模块requests和BeautifulSoup，另外结合刚学习的任务流工具TaskFlow来完成代码开发。</p>
<p>我们先来看一下要爬取的数据，网址是http://data.10jqka.com.cn/funds/gnzjl/，通过chrome的开发者工具分析我们可以比较容易找到后台数据加载网址为</p>
<blockquote>
<p><a href="http://data.10jqka.com.cn/funds/gnzjl/field/tradezdf/order/desc/page/%7Bpage_num%7D/ajax/1/free/1/" target="_blank" rel="noopener">http://data.10jqka.com.cn/funds/gnzjl/field/tradezdf/order/desc/page/{page_num}/ajax/1/free/1/</a></p>
</blockquote>
<p>其中page_num的位置为要查询第几页的数据，在网页上看到概念一共有6页数据，所以page_num取值为1-6</p>
<p><img src="/uploads/WechatIMG109.png" alt="WechatIMG109"></p>
<p>这里有个小技巧，可以先点击图片左上角的清空按钮，把已经加载的网址先清理掉，然后在原始网页上点第二页，就能看到图片左下角新加载的网址，点开右边“Preview” 看到资金流数据相关的内容，就能确定这个网址是用来加载数据的。</p>
<p>在chrome浏览器中输入 <a href="http://data.10jqka.com.cn/funds/gnzjl/field/tradezdf/order/desc/page/1/ajax/1/free/1/%EF%BC%8C%E5%B9%B6%E6%89%93%E5%BC%80chrome%E5%BC%80%E5%8F%91%E8%80%85%E5%B7%A5%E5%85%B7%EF%BC%8C%E5%9C%A8%E7%BD%91%E9%A1%B5%E6%BA%90%E7%A0%81%E4%B8%AD%E6%89%BE%E5%88%B0%E6%95%B0%E6%8D%AE%E6%89%80%E5%9C%A8table%E6%A0%87%E7%AD%BE%E4%B8%BA" target="_blank" rel="noopener">http://data.10jqka.com.cn/funds/gnzjl/field/tradezdf/order/desc/page/1/ajax/1/free/1/，并打开chrome开发者工具，在网页源码中找到数据所在table标签为</a></p>
<pre><code class="language-html">&lt;table class=&quot;m-table J-ajax-table&quot;&gt;
	...
&lt;/table&gt;
</code></pre>
<p>抓取数据的完整源码如下</p>
<pre><code class="language-python">import time

import requests
from bs4 import BeautifulSoup
from taskflow import engines
from taskflow.patterns import linear_flow
from taskflow.task import Task

REQUEST_HEADER = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}


class MoneyFlowDownload(Task):
    &quot;&quot;&quot;
    下载资金流数据
    数据源地址：http://data.10jqka.com.cn/funds/gnzjl/

    &quot;&quot;&quot;
    BASE_URl = {
        &quot;concept&quot;: 'http://data.10jqka.com.cn/funds/gnzjl/field/tradezdf/order/desc/page/%s/ajax/1/free/1/',
    }

    def execute(self, bizdate, *args, **kwargs):

        for name, base_url in self.BASE_URl.items():
            # 爬取数据的存储路径
            dt_path = '/data/%s_%s.csv' % (bizdate, name)

            with open(dt_path, &quot;a+&quot;) as f:
                # 记录数据文件的当前位置
                pos = f.tell()
                f.seek(0)
                lines = f.readlines()
                # 读取文件中的全部数据并将第一列存储下来作为去重依据，防止爬虫意外中断后重启程序时，重复写入相同
                crawled_list = list(map(lambda line: line.split(&quot;,&quot;)[0], lines))
                f.seek(pos)
                # 循环500次，从第一页开始爬取数据，当页面没有数据时终端退出循环
                for i in range(1, 500):
                    print(&quot;start crawl %s, %s&quot; % (name, base_url % i))
                    web_source = requests.get(base_url % i, headers=REQUEST_HEADER)
                    soup = BeautifulSoup(web_source.content.decode(&quot;gbk&quot;), 'lxml')
                    table = soup.select('.J-ajax-table')[0]
                    tbody = table.select('tbody tr')
                    # 当tbody为空时，则说明当前页已经没有数据了，此时终止循环
                    if len(tbody) == 0:
                        break
                    for tr in tbody:
                        fields = tr.select('td')
                        # 将每行记录第一列去掉，第一列为序号，没有存储必要
                        record = [field.text.strip() for field in fields[1:]]
                        # 如果记录还没有写入文件中，则执行写入操作，否则跳过这行写入
                        if record[0] not in crawled_list:
                            f.writelines([','.join(record) + '\n'])
                    # 同花顺网站有反爬虫的机制，爬取速度过快很可能被封
                    time.sleep(1)


if __name__ == '__main__':
    bizdate = '20200214'
    tasks = [
        MoneyFlowDownload('moneyflow data download')
    ]
    flow = linear_flow.Flow('ths data download').add(*tasks)
    e = engines.load(flow, store={'bizdate': bizdate})
    e.run()

</code></pre>
<p>执行程序后，在dt_path位置已经存储了概念的资金流数据，文件名为20200214_concept.csv，内容大致如下：</p>
<pre><code class="language-shell">钛白粉,1008.88,6.29%,7.68,6.21,1.47,7,金浦钛业,10.04%,2.96
磷化工,916.833,2.42%,37.53,34.78,2.75,28,六国化工,9.97%,4.08
光刻胶,1435.68,2.40%,43.51,44.31,-0.80,20,晶瑞股份,10.01%,42.99
</code></pre>
<p>此时就完成了同花顺概念分类的资金流数据的爬取，之后可以每天定时启动任务抓取数据进行分析。</p>
]]></content>
      <categories>
        <category>量化交易系统</category>
      </categories>
      <tags>
        <tag>TaskFlow</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack公共组件TaskFlow介绍</title>
    <url>/2020/02/08/2020-02-08%20OpenStack%E5%85%AC%E5%85%B1%E7%BB%84%E4%BB%B6TaskFlow%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<p>TaskFlow 是一个以高度可用，易于理解和声明试方式来执行[作业，任务，流程]的库，可与OpenStack和其他项目一起使用。</p>
<h1>基本概念</h1>
<p>taskflow库在oslo项目中是一个实现比较复杂的项目，要弄清楚其实现原理，首先需要对其中的相关概念有所了解。所以，本文首先总结了taskflow中常用的一些基本概念，这些概念主要包括如下几个：</p>
<h2 id="Atom">Atom</h2>
<p>Atom类是taskflow的最小单位，taskflow中其他类，包括Task等都需要继承这个类。一个Atom对象是一个命名对象，通过操作输入数据以执行一些促进整个流程发展的动作，或者产生一个处理结果等。它是一个抽象类，提供了两个抽象方法：execute()用于执行一个动作，revert()用于根据execute()执行结果和失败信息还原到任务执行之前的状态；除此之外，还分别为这两个方法提供了pre_execute()/post_execute()、pre_revert()/post_revert()方法用于定义在执行execute或revert操作前后执行的操作。</p>
<h2 id="Task">Task</h2>
<p>Task类是一个拥有执行和回滚操作的最小工作单元，表示一个任务流中的某一个任务。它是一个继承自Atom类的表示一个任务的父类，开发者可以执行定义一个继承自Task类的任务类，并重写execute()和revert()方法分别表示执行和回滚的操作。</p>
<p><img src="https://docs.openstack.org/taskflow/latest/_images/tasks.png" alt="Task outline."></p>
<h4 id="Task的两种类型">Task的两种类型:</h4>
<ul>
<li>Task: 对于继承和创建自己的子类很有用。</li>
<li>FunctorTask: 对于将现有function包装到任务对象中很有用，但是不能应用在engine中</li>
</ul>
<h2 id="Retry">Retry</h2>
<p>Retry类也是一个继承自Atom的抽象类，它主要定义了当有错误发生时，如何进行重试操作。其也包含也不同的类型，将会在接下来的部分进行详细介绍。继承重试的子类必须提供on_failure()函数来对故障进行处理。</p>
<h4 id="为避免重复创建常见的重试模式，提供了以下常见的重试子类：">为避免重复创建常见的重试模式，提供了以下常见的重试子类：</h4>
<ul>
<li>
<p>AlwaysRevert: 始终还原subflow.</p>
</li>
<li>
<p>AlwaysRevertAll: 始终还原整个flow</p>
</li>
<li>
<p>Times: 对subflow重试指定次数</p>
</li>
<li>
<p>ForEach: 允许在每次发生故障时为subflow提供不同的值（使其有可能通过更改subflow输入来解决故障）</p>
</li>
<li>
<p>ParameterizedForEach: 和ForEach类似，但是从存储中获取值.</p>
<p><img src="https://docs.openstack.org/taskflow/latest/_images/inheritance-18bf8f4505f8b8f3ecd1914b3ff8965622138a35.png" alt="Inheritance diagram of taskflow.atom, taskflow.task, taskflow.retry.Retry, taskflow.retry.AlwaysRevert, taskflow.retry.AlwaysRevertAll, taskflow.retry.Times, taskflow.retry.ForEach, taskflow.retry.ParameterizedForEach"></p>
</li>
</ul>
<p>关于重试的策略，taskflow通过一个枚举类型的Decision定义了三种策略：</p>
<ul>
<li>REVERT：仅回滚失败Flow对象周围或关联的子流Flow对象。该策略在回滚子流Flow对象之前，会首先咨询其父Atom对象以确定父Atom对象是否使用不同的重试策略。该策略允许安全的嵌套具有不同重试策略的Flow对象。如果父Atom对象中没有定义重试策略，则默认只回滚关联子流Flow对象中的Atom对象。当然，你可以通过defer_revert参数改变默认行为，当其设置为True，表示REVERT策略将继承父Atom的策略，如果父Atom对象没有重试策略，则它也将被回滚。</li>
<li>REVERT_ALL：不管失败Flow对象的父Atom对象的策略如何，都将回滚整个流程。</li>
<li>RETRY：重试该失败的Flow/Task对象。</li>
</ul>
<h2 id="Flow">Flow</h2>
<p>Flow类是一个用来关联所有相关Task类，并规定这些Task类的执行和回滚顺序的抽象类。而oslo中为Flow提供了三种实现方式：graph_flow表示图流，linear_flow表示线性流，unordered_flow表示无序流。关于这三种类型的流实现会在之后进行详细分析。</p>
<p><img src="https://docs.openstack.org/taskflow/latest/_images/inheritance-d843124115abb8d565dc2aea882f408d4b57072b.png" alt="Inheritance diagram of taskflow.flow, taskflow.patterns.linear_flow, taskflow.patterns.unordered_flow, taskflow.patterns.graph_flow"></p>
<ul>
<li>linear_flow：线性流，该类型的Flow对象将按照Task/Flow加入的顺序来依次执行，按照加入的倒序依次回滚。</li>
<li>graph_flow：图流，该类型的Flow对象会按照给加入的Task/Flow显示指定的依赖关系或通过其间的provides/requires属性隐含的依赖关系执行和回滚。</li>
<li>unordered_flow：无序流，该类型的Flow对象所加入的Task/Flow会按照任意顺序执行或回滚。</li>
</ul>
<p>要弄清楚这三种类型的Flow对象，首先需要了解oslo定义的Flow基类的构成。在oslo定义的Flow基类中，主要包含以下几个重要的属性和方法：</p>
<ul>
<li>name：表示初始化Flow对象时，为其指定的名称，并不能唯一表示一个Flow对象。</li>
<li>retry：表示与该Flow对象关联的重试控制器。</li>
<li>provides：表示该Flow对象提供的一组符号名称。</li>
<li>requires：表示该Flow对象所需要的一组&quot;unsatisfied&quot;符号名称。</li>
<li>add(*items)：该方法用于为该Flow对象添加一个或一组Task/Flow对象。</li>
<li>iter_links()：迭代Flow对象的子节点之间的依赖关系链接。例如在迭代一个三元组(A, B, meta)时，就是迭代一个从子节点A（一个Atom对象或一个Subflow）指向子节点B（一个Atom对象或一个Subflow）的链接；换句话说，也就代表了子流B依赖于子流A，或者子流B需要子流A；而meta代表了这个依赖关系链接的元数据，是一个字典。</li>
<li>iter_nodes()：迭代Flow对象中的所有节点。例如在迭代一个二元组（A, meta）时，A（一个Atom对象或一个Subflow）是当前Flow对象的子流或子任务；meta同样代表了这个链接的元数据，是一个字典。</li>
</ul>
<h2 id="Engine">Engine</h2>
<p>Engine类是一个表示真正运行Atom对象的抽象类，它的实现类主要用于载入（load）一个Flow对象，然后驱动这个Flow对象的Task对象开始运行。Engine的实现也有多种不同的形式，这也会在接下来的部分进行详细介绍。</p>
<p>taskflow在具体实现Task/Flow管理时，首先定义了一个Engine抽象类，所有实现都需要继承这个抽象类。这个抽象类定义了如下重要属性和方法：</p>
<ul>
<li>notifier：一个通知对象，它会分发与Engine对象中包含的Flow对象相关的事件通知。</li>
<li>atom_notifier：一个通知对象，它会分发与Engine对象中包含的Atom对象相关的事件通知。</li>
<li>options：相关数据结构传递给Engine对象的选项。</li>
<li>storage：Engine对象的存储单元。</li>
<li>statistics：Engine对象收集的运行时统计数据字典。当Engine没有运行时，这个值为空；在Engine正在运行时或已经运行之前，它可能会存储一些对正在运行或运行完成时有用的或包含信息的键值对。</li>
<li>compile()：该方法可以将Engine对象中包含的Flow对象编译成Engine对象内部表示形式。这个内部表示形式就是Engine对象实际用于运行的流的形式。</li>
<li>reset()：将Engine对象重置为PENDING状态。如果一个Flow以FAILURE、SUCCESS、REVERTED状态结束运行（即调用Engine对象的run()方法之后），或由于某种状态使得其处于某种中间状态，此时可以调用reset()方法进行重置，然后进行重试操作。</li>
<li>prepare()：在Engine对象编译完所有包含的Flow对象之后，且在Flow运行之前执行该方法，为流程的执行进行一些准备操作。</li>
<li>validate()：在Engine对象编译完所有包含的Flow对象之后，且在Flow运行之前执行该方法，为流程的执行进行一些验证操作。</li>
<li>run()：运行Engine对象中的Flow流程。</li>
<li>suspend()：该方法尝试暂停Engine对象。如果一个Engine对象正在执行某个Atom对象，则执行该方法会将这个Atom对象之后的所有正要运行的工作都暂停，并将这个Engine对象的状态变为暂停状态，以便之后进行恢复操作。</li>
</ul>
<p>taskflow在具体实现Engine时，都需要给上述属性和方法重新赋值或进行覆写操作，以实现一个完整的管理流程Flow/Task对象的Engine类。在taskflow中，目前实现了三种策略的Engine类，而在这三种策略中，有两种是面向行为的action_egine类：SerialActionEngine、ParallelActionEngine；另一种是面向多进程的worker_base类：WorkerBaseActionEngine。这三种类型的Engine类的异同点如下所示：</p>
<ul>
<li>SerialActionEngine：这是一个以串行方式运行任务的Engine类，也就是说所有的任务都会在调用engine.run()方法的线程中顺序执行。</li>
<li>ParallelActionEngine：这是一个以并行方式运行任务的Engine类，即可以在多个线程中运行Engine对象中的任务。在这种策略中，taskflow定义了对应的多个ParallelThreadTaskExecutor创建运行任务的线程</li>
<li>WorkerBaseActionEngine：这是一个可以将任务调度到不同worker（即进程）中执行的Engine类。</li>
</ul>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>TaskFlow</tag>
      </tags>
  </entry>
  <entry>
    <title>cython使用入门</title>
    <url>/2019/12/11/2019-12-11%20cython%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<p>最近工作上遇到一个问题，某券商提供的文件单接口需要用其提供的c语言工具调用，由于我们的交易框架是python开发的，所以需要用到cython来调用c开发的工具包，学习了cython的官方入门教程顺便记录如下。</p>
<h3 id="cython介绍">cython介绍</h3>
<p>Cython是针对Python编程语言和扩展的Cython编程语言（基于Pyrex）的优化静态编译器。<br>
它使为Python编写C扩展与Python本身一样容易。</p>
<h3 id="编写样例代码">编写样例代码</h3>
<p>首先，创建一个后缀为pyx的文件cython_example.pyx，编写cython函数</p>
<pre><code class="language-python">def say_hello_to(name):
    print(&quot;Hello %s!&quot; % name)
</code></pre>
<p>然后编写相应的编译脚本文件:</p>
<pre><code class="language-python">from distutils.core import setup
from Cython.Build import cythonize

setup(name='Hello world app',
      ext_modules=cythonize(&quot;cython_example.pyx&quot;))
</code></pre>
<h3 id="编译代码">编译代码</h3>
<pre><code class="language-shell">python setup.py build_ext --inplace
</code></pre>
<p>报如下错误：</p>
<pre><code class="language-shell">running build_ext
building cython_example extension
error: Unable to find vcvarsall.bat
</code></pre>
<h4 id="Which-Microsoft-Visual-C-compiler-to-use-with-a-specific-Python-version">Which Microsoft Visual C++ compiler to use with a specific Python version ?</h4>
<table>
<thead>
<tr>
<th>visual c++</th>
<th>python</th>
</tr>
</thead>
<tbody>
<tr>
<td>14.x</td>
<td>3.5,3.6,3.7,3.8</td>
</tr>
<tr>
<td>10.0</td>
<td>3.3,3.4</td>
</tr>
<tr>
<td>9.0</td>
<td>2.6, 2.7, 3.0, 3.1, 3.2</td>
</tr>
</tbody>
</table>
<p>我使用的是python3.6，所以下载 Visual C++ 2015 Build Tools（包含Visual C++ 14.0）</p>
<p>下载地址：</p>
<p><a href="http://go.microsoft.com/fwlink/?LinkId=691126&amp;fixForIE=.exe" target="_blank" rel="noopener">http://go.microsoft.com/fwlink/?LinkId=691126&amp;fixForIE=.exe</a>.</p>
<p>安装之后重新执行编译命令输出如下最后两行说明编译通过:</p>
<pre><code class="language-shell">Generating code
Finished generating code
</code></pre>
<p>会在当前目录下生成build目录和cython_example.cp36-win32.pyd</p>
<p>接下来做个测试，<a href="http://xn--test-k84fuit3ty95h.py" target="_blank" rel="noopener">编写一个test.py</a>，内容如下</p>
<pre><code class="language-python">import cython_example

cython_example.say_hello_to('eryk')
</code></pre>
<p>执行命令后输出如下结果说明调用cython函数成功了</p>
<pre><code class="language-shell">Hello eryk!
</code></pre>
<h3 id="参考">参考</h3>
<p><a href="http://docs.cython.org/en/latest/src/quickstart/build.html" target="_blank" rel="noopener">http://docs.cython.org/en/latest/src/quickstart/build.html</a></p>
<p><a href="https://wiki.python.org/moin/WindowsCompilers" target="_blank" rel="noopener">https://wiki.python.org/moin/WindowsCompilers</a></p>
<p><a href="https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat" target="_blank" rel="noopener">https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat</a></p>
<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
]]></content>
      <categories>
        <category>量化交易系统</category>
      </categories>
      <tags>
        <tag>cython</tag>
      </tags>
  </entry>
  <entry>
    <title>Python调用C/C++入门</title>
    <url>/2019/08/23/2019-08-23%20Python%E8%B0%83%E7%94%A8C:C++%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h3 id="1-背景">1. 背景</h3>
<p>最近公司在某券商募集了一笔资金，需要对接其提供的程序化接口方便以后进行交易，对方只提供了c++版本程序，我们系统是python开发的，所以需要用python调用c++，大致了解下了python调用c++的几种方式，下面根据网上的资料介绍下几种方式优缺点，最后给个mac环境下python调用c++的例子。</p>
<h3 id="2-Python调用C-C-程序方法">2. Python调用C/C++程序方法</h3>
<ol>
<li>
<p>ctypes</p>
<ul>
<li>如果是 C 函数库，则直接 load 这个库，然后调用即可；</li>
<li>如果是 C++ 函数库，则需要用extern关键字封装一个供 C 使用的函数，即把类隐藏到一些 C 风格的函数里，然后用 extern 标明这些函数，以方便外部调用。</li>
</ul>
</li>
<li>
<p>SWIG</p>
<p>SWIG完整支持ANSI C，支持除嵌套类外的所有C++特性。SWIG是一个接口编译器，旨在为C/C++方便地提供脚本语言接口。SWIG不仅可以为C/C++程序生成 Python接口，目前可以生成CLISP,Java,Lua,PHP,Ruby,Tcl等19种语言的接口。SWIG被Subversion, wxPython, Xapian等项目使用。值得一提的是，Google也使用SWIG。</p>
</li>
<li>
<p>SIP</p>
<p>SIP是一种Python工具，用于自动生成Python与C、C++库的绑定。SIP最初是在1998年用PyQt开发的，用于Python与Qt GUI toolkit的绑定，但适用于生成任何C或C++库的绑定。</p>
</li>
<li>
<p>Cython</p>
<p>Cython是让Python脚本支持C语言扩展的编译器，Cython能够将Python+C混合编码的.pyx脚本转换为C代码，主要用于优化Python脚本性能或Python调用C函数库。由于Python固有的性能差的问题，用C扩展Python成为提高Python性能常用方法，Cython算是较为常见的一种扩展方式。</p>
</li>
<li>
<p>Boost.Python</p>
<p>Boost.Python是Boost提供的一个C++的模板库，用以支持Python和C++的无缝互操作。相对SWIG来说，这个库的优势是功能通过C++ API完成，不用学习写新的接口文件。对C++的支持更自然、完整。</p>
</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>ctypes</th>
<th>SWIG</th>
<th>SIP</th>
<th>Cython</th>
<th>Boost.Python</th>
</tr>
</thead>
<tbody>
<tr>
<td>是否支持Python3</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>对接难易程度</td>
<td>简单</td>
<td>中等</td>
<td>中等</td>
<td>困难</td>
<td>困难</td>
</tr>
<tr>
<td>是否需开发封装代码</td>
<td>c++需要,c不需要</td>
<td>需要</td>
<td>需要</td>
<td>需要</td>
<td>需要</td>
</tr>
</tbody>
</table>
<h3 id="3-使用ctypes调用C-C-例子">3. 使用ctypes调用C/C++ 例子</h3>
<h4 id="3-1-安装-GNU-的-C-C-编译器">3.1 安装 GNU 的 C/C++ 编译器</h4>
<ul>
<li>
<p>UNIX/Linux: <a href="http://gcc.gnu.org/install/" target="_blank" rel="noopener">http://gcc.gnu.org/install/</a></p>
</li>
<li>
<p>Mac OS X:  安装 Xcode就能使用编译器</p>
</li>
<li>
<p>Windows: <a href="http://www.mingw.org/" target="_blank" rel="noopener">www.mingw.org</a></p>
</li>
</ul>
<p>以mac为例，安装之后命令行输入 g++ -v 查看是否安装成功</p>
<pre><code class="language-shell"> ~/ g++ -v
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/c++/4.2.1
Apple LLVM version 10.0.0 (clang-1000.11.45.5)
Target: x86_64-apple-darwin18.2.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
</code></pre>
<p>3.2 开发c++例子程序:</p>
<pre><code class="language-c++">#include &lt;iostream&gt;     
class Test{     
    public:                  
        void print(){             
            std::cout &lt;&lt; &quot;Hello world!&quot; &lt;&lt; std::endl;
        }
};

extern &quot;C&quot; {     
    Test* Test_new(){         
        return new Test(); 
    }     
    void Test_print(Test* test){ 
        test-&gt;print(); 
    }
}
</code></pre>
<p>保存文件未test.cpp，编译代码生成动态链接库:</p>
<pre><code class="language-shell">g++ -o test.so -shared -fPIC test.cpp
</code></pre>
<p><a href="http://xn--test-494f49c2xku1dhpjc9l9nkza591g08a838pubgj16fm21a.so" target="_blank" rel="noopener">执行完成后会在当前目录下生辰test.so</a> 文件</p>
<p>3.3 Python中调用so</p>
<pre><code class="language-python">from ctypes import cdll
lib = cdll.LoadLibrary('./test.so')

class Test(object):
    def __init__(self):
        self.obj = lib.Test_new()

    def print(self):
        lib.Test_print(self.obj)

test = Test()
test.print()

</code></pre>
<p>执行Python代码会输出 Hello world!，说明执行成功</p>
<h1>参考</h1>
<p><a href="https://stackoverflow.com/questions/145270/calling-c-c-from-python" target="_blank" rel="noopener">https://stackoverflow.com/questions/145270/calling-c-c-from-python</a></p>
<p>关于python对接c/c++各种方案的优缺点，这篇文章说的比较清楚: <a href="https://www.jb51.net/article/63623.htm" target="_blank" rel="noopener">https://www.jb51.net/article/63623.htm</a></p>
<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
]]></content>
      <categories>
        <category>量化交易系统</category>
      </categories>
      <tags>
        <tag>ctypes</tag>
      </tags>
  </entry>
  <entry>
    <title>FIX协议介绍与QuickFIX使用入门(上)</title>
    <url>/2019/07/16/2019-07-16%20%E9%87%91%E8%9E%8D%E4%BF%A1%E6%81%AF%E4%BA%A4%E6%8D%A2%E5%8D%8F%E8%AE%AE(FIX)%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h1>定义</h1>
<p>FIX协议是由国际FIX协会组织提供的一个开放式协议，目的是推动国际贸易电子化的进程，在各类参与者之间，包括投资经理、经纪人，买方、卖方建立起实时的电子化通讯协议。</p>
<p><strong>FIX协议的目标是把各类证券金融业务需求流程格式化，使之成为一个个可用计算机语言描述的功能流程，并在每个业务功能接口上统一交换格式，方便各个功能模块的连接。</strong></p>
<p>FIX协议各个版本对股票、期权和期货的支持程度，目前市场上使用FIX4.4的较多。</p>
<p><img src="/Users/eryk/Desktop/20190716213709.png" alt=""></p>
<h1>FIX通信模型</h1>
<ul>
<li>Initiator：发起者，建立通信连路，通过发送初始Logon消息发起会话的参与方。</li>
<li>Acceptor：接收方 FIX会话的接收方。负责执行第一层次的认证和通过传输Logon消息的确认正式声明连接请求被接受。</li>
<li>原则：先发起者为Initiator ，接受者为Acceptor 。</li>
<li>标准模式以网关为Acceptor，客户端为Initiator做为常用模式。</li>
</ul>
<h1>基本概念</h1>
<h3 id="FIX-Connection">FIX Connection</h3>
<p>FIX连接 由3部分组成：logon登录，message exchange消息传输，和logout注销.</p>
<h3 id="FIX-Session">FIX Session</h3>
<p>FIX会话由一个或多个FIX Connection FIX连接组成。一个FIX会话可以有多次登录。一个FIX会话定义为一个在连接双方间的的带有连续序列号的有序消息双向传输流。 单个FIX会话能够跨越多个连续（不是并行的）的物理连接。在一个维持的，单独的FIX会话中，参与方能够多次连接和断开连接。连接的参与方必须根据单个系统及时间区域需求，公共协商会话的开始和结束。无论什么原因，重新设置接收和发送序列号为1，意味着一个新的FIX会话的开始。</p>
<p>建议一个新的FIX会话在每24小时期间建立一次。可以维持24小时的连接和通过设置在Logon消息中的ResetSeqNumFlag建立一套新的序列号。</p>
<h3 id="Sequence-Num">Sequence Num</h3>
<p>所有的FIX消息都由一个唯一的序列号进行标示。序列号在每一个FIX会话开始时被初始化为1，并在整个会话期间递增。监控序列号可以使会话参与者识别和处理丢失的消息，当在一个FIX会话中重新连接时能够优雅地进行应用程序同步。每个会话将建立一组互不依赖的接受和发送序列。会话参与者将维护一个赋予发送消息的序列和一个监控接受消息的消息块间隙序列号。</p>
<h4 id="心跳-Heartbeats">心跳 Heartbeats</h4>
<p>在消息交互期间，FIX应用程序将周期性产生Heartbeat心跳消息。该心跳消息可以监控通信链路状态及识别接受序列号间隙。发送Heartbeat的周期间隔由会话发起者使用在Logon消息中HeartBtInt域进行定义。Heartbeat心跳消息的时间间隔应当在每一个消息发送后复位，即发送一个消息后，在间隔给定的时间内无其它消息发送则发送一个Heartbeat心跳消息。HeartBtInt的值应当被会话双方认同，由会话发起方定义并由会话接收者通过Logon消息进行确认。同一个HeartBtInt被会话双方——登录的发起者和登录的接受者共同使用。</p>
<h3 id="Ordered-Message-Processing">Ordered Message Processing</h3>
<p>FIX协议假设消息在所有参与者间完全按照顺序进行传输。协议的实现者在设计消息间隙填充处理时应当考虑这个假设。有两种方式处理消息间隙。每一个都要求所有的消息时最后一个接收消息的后续消息或在维护一个所有新消息有序序列时，请求特定丢失消息。比如：接收方丢失了5个消息块中的第二个，程序能忽略第3到第5个消息，产生一个对消息2到消息5的重传请求，或者从消息2到无穷大消息编号的重传请求。另外的方式是暂时存储消息3到消息5，仅要求重传消息2。对于这两种方式，消息3到消息5都不应该先于消息2进行处理。</p>
<h3 id="Possible-Duplicate">Possible Duplicate</h3>
<p>当一个FIX引擎对一个消息是否成功地被指定的目标接收或者当对一个重传请求进行响应时，将会产生一个可能的消息复制。这个消息将用同样的序列进行重新传送，此时在头部的PossDupFlag域将会被设置为‘Y’。接收端程序负责处理该重发消息，可以作为一个新消息进行处理，或者根据实际情况忽略该消息。所有重传请求的响应消息都将包含其值为‘Y’的PossDupFlag域。没有PossDupFlag域或者PossDupFlag域为‘N’的消息应被当作初始传送消息。注意，一个PossDupFlag值为‘Y’的重传消息需要重新计算其CheckSum值。一个可能的复制消息里发生变化的域包括：CheckSum，OrigSendingTime，SendingTime，BodyLength和PossDupFlag。加密相关域（SecureDataLen和SecureData）也必须被重新构造。</p>
<h3 id="Possible-Resends">Possible Resends</h3>
<p>模糊的应用层消息可能随同PossResend标志被重传。当一个指令没有在规定时间长度内进行确认或者终端用户挂起该指令没有进行传送时这种方法非常有用。接收程序必须识别此标志，并质疑其内部域以确定该指令是否在之前已经被接收过。注意，可能的重传消息将包含与原始消息相同的数据体，但包含PossResend标志和一个新的序列号。此外，CheckSum和与加密相关的域值需要重构。</p>
<h4 id="数据完整校验-Data-Integrity">数据完整校验 Data Integrity</h4>
<p>消息数据内容的完整性可以参用两种方式来验证：消息长度和效验码检查。程序通过计算BodyLength域到（并包含）在CheckSum标记（“10=”）后的分界符的字符数与在BodyLength中标示的消息长度进行比较来完成完整性效验。ChekSum完整性检查，通过计算从域“8=”中“8”开始，包括紧跟在CheckSum标记域的分界符<SOH>每个字符的2进制和同CheckSum进行比较得到。</p>
<h4 id="消息确认-Message-Acknowledgements">消息确认 Message Acknowledgements</h4>
<p>消息数据内容的完整性可以参用两种方式来验证：消息长度和效验码检查。程序通过计算BodyLength域到（并包含）在CheckSum标记（“10=”）后的分界符的字符数与在BodyLength中标示的消息长度进行比较来完成完整性效验。ChekSum完整性检查，通过计算从域“8=”中“8”开始，包括紧跟在CheckSum标记域的分界符<SOH>每个字符的2进制和同CheckSum进行比较得到。</p>
<h3 id="加密-Encryption">加密 Encryption</h3>
<p>敏感数据在公众网络上的传输建议采用数据加密技术来掩饰应用消息。<br>
加密算法由连接双方共同协商。<br>
一个消息的任何一个域可以被加密并放在SecureData域中。然而，一些显示的标志域必须采用明文进行传输。为确保完整性，明文域可以在SecureData域中重复。<br>
当使用加密时，建议但不是必须，所有的消息体都进行加密。如果一个消息中的重复组数据中的部分数据要加密，这个重复组必须全部进行加密。<br>
预先协商好的加密算法在Logon消息中进行声明。</p>
<h4 id="自定义域">自定义域</h4>
<ul>
<li>FIX为给用户提供最大的灵活性，FIX协议允许用户自定义域。这些域在认同的参与者之间实现、应用，并且应注意避免冲突。</li>
<li>Tag数在5000 到9999保留用于用户自定义域。这些tag值用于企业联盟的信息交换。可以通过FIX网站进行注册。</li>
<li>10000以上保留用于单一企业内部使用。不用注册。</li>
</ul>
<h1>消息类型</h1>
<p>初始化过程之后，正常的消息交换将开始。所有有效的消息格式的细节将在“Adminitrative Message ”管理消息和“Application Messages”应用消息部分介绍。</p>
<h3 id="1-管理信息">1. 管理信息</h3>
<p>它是为了信息交换过程更加顺畅一致而使用的控制,包括:登录、心跳、检验请求、重新发送请求、拒绝(交换过程)顺序重设及注销等。</p>
<h3 id="2-应用消息">2. 应用消息</h3>
<p>也就是交易的数据,它包括:</p>
<ul>
<li>公告 宣布已完成的交易信息。</li>
<li>重要提示 告知由经纪人买卖的证券是由私人股份有限公司所有,还是由代理持有,以及持有量。</li>
<li>消息 是经纪人和机构之间传送的一般自由格式信息,带有识别信息紧急性和商号主题词分类标志。</li>
<li>电子邮件 其格式和用途与消息信息相同,但更倾向于双方非公开的用途。</li>
<li>报价请求 有些市场,要求经纪人在每次订单前提出报价。</li>
<li>报价与多宗报价 回应报价请求的信息,并用于发表主动的报价。</li>
<li>请求对多宗报价的确认 使用报价回应水平标记,有选择地支持对报价的确认。</li>
<li>报价撤销 报价发起人用于撤销报价。</li>
<li>报价状况请求 机构用来生成执行报告。</li>
<li>报价确认 针对报价、多宗报价、报价撤销和报价请求,作出回应。</li>
<li>行情数据请求 通过此请求得到所指定的证券和外汇交易报价的行情数据。</li>
<li>行情数据—快照/完全刷新 该信息用于发送双方的订单登记簿、报价清单、交易清单、指数值、开盘价、收盘价、成交单价、最高价、最低价和变动加权平均价等。</li>
<li>行情数据—添加刷新 用于添加刷新请求。</li>
<li>行情数据请求拒绝 用于经纪人因交易或技术上的原因不承兑行情数据请求的情况。</li>
<li>证券定义请求 用于某一指定证券与第二方交易。</li>
<li>证券定义 接受或拒绝证券定义信息中请求的证券,发回证券及类型清单。</li>
<li>证券状况请求 用于提出有关证券状况的请求。</li>
<li>证券状况 提供有关证券状况改变的报告。</li>
<li>交易盘状况请求 请求有关市面状况的信息。</li>
<li>交易盘状况 提供有关市场状况的信息。</li>
<li>新订单—单一 机构向经纪人提供有关证券或外汇的订单。</li>
<li>执行报告 确认收到订单或订单改变信息,传递订单状况或订单成交信息,报告交易的费用。</li>
<li>未知交易 通知交易方,收到的订单已被执行。</li>
<li>订单撤销/替换请求 改变订单的参数。</li>
<li>订单撤销拒绝 是经纪人在不能承兑所收到的撤销请求信息时发出的信息。</li>
<li>订单状况请求 机构要求经纪人生成并发挥有关订单状况的信息。</li>
<li>划拨 指定如何将一个订单或一组订单细分为一个或多个账户。</li>
<li>划拨确认 确认收到机构发送的划拨信息及状态。</li>
<li>结算指令 经纪人或机构交易结算的指令。</li>
<li>出价请求 在“非公开”市场与“公开”市场,因市场规则不同,该信息的用法也不同</li>
<li>出价回应 因两个市场规则不同,有不同的用法。</li>
<li>新订单—清单 因两种市场规则的不同而不同。</li>
<li>敲定价 交换本金交易的敲定价。</li>
<li>状况清单 卖方以主动方式发送回应状况清单请求信息。</li>
<li>清单执行 机构用于指示经纪人开始执行已被提交的证券订单信息。</li>
<li>清单撤销执请求 用于机构希望在执行交易盘之前或之中,撤销已被提交的证券订单消息。</li>
<li>状况清单请求 用于机构指示经纪人生成有关某一状况清单的信息。</li>
<li>清单订单信息的分解 使用与其它FIX信息相同的方法,支持程序交易中的信息分解。</li>
<li>交易信息拒绝 拒绝因遵循了交易盘规则而不能以其它方式进行拒绝的应用层面的信息。</li>
</ul>
<h1>消息格式</h1>
<h3 id="数据类型">数据类型</h3>
<p>整数int,浮点数float,单个字符char,布尔Boolean,字符串String,数据data</p>
<p>每条FIX信息都是由一系列带有〈标记〉=〈值〉的域组成。每个标记代表不同的含义,可以是信息的类型,目标商务名称,证券买入价等。FIX协议规定了0～5000的标记含义（fix信息字典）,5000以上可由使用者自己定义,以适用特定的应用。</p>
<h1>参考</h1>
<p><a href="https://www.fix-events.com/Archives/asianfix2008/cn/pdf/AlanDean_Chi.pdf" target="_blank" rel="noopener">https://www.fix-events.com/Archives/asianfix2008/cn/pdf/AlanDean_Chi.pdf</a></p>
<p><a href="https://l297.oschina.io/15034517662312.html" target="_blank" rel="noopener">https://l297.oschina.io/15034517662312.html</a></p>
<p><a href="https://juejin.im/post/5bf7c4ae51882528c4467649" target="_blank" rel="noopener">https://juejin.im/post/5bf7c4ae51882528c4467649</a></p>
<p><a href="https://www.huiyep.com/knowledge/155062.html" target="_blank" rel="noopener">https://www.huiyep.com/knowledge/155062.html</a></p>
<p><a href="https://github.com/quickfix/quickfix/blob/master/examples/executor/python/executor.py" target="_blank" rel="noopener">https://github.com/quickfix/quickfix/blob/master/examples/executor/python/executor.py</a></p>
<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
]]></content>
      <categories>
        <category>量化交易系统</category>
      </categories>
      <tags>
        <tag>FIX</tag>
      </tags>
  </entry>
  <entry>
    <title>读《期货市场计算机分析指南》笔记</title>
    <url>/2019/06/19/2019-06-19%20%E8%AF%BB%E3%80%8A%E6%9C%9F%E8%B4%A7%E5%B8%82%E5%9C%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%88%86%E6%9E%90%E6%8C%87%E5%8D%97%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1>第一章 系统的建立</h1>
<h2 id="1-鉴定可交易的市场">1. 鉴定可交易的市场</h2>
<ul>
<li>流动性<br>
流动性的最佳度量是交易量和未平仓合约数，观察一段时间的平均值优于观察单日</li>
<li>历史波动性<br>
历史上趋势变化范围宽的市场优于平静的趋势变化范围窄的市场</li>
<li>准确的基本面和技术面数据</li>
<li>避免新市场</li>
</ul>
<h2 id="2-鉴别走势">2. 鉴别走势</h2>
<ul>
<li>两条移动平均线，例如: 3和12，9和18，观察不到水平状态
<ul>
<li>3 &gt; 12，上升趋势</li>
<li>3 &lt; 12，下降趋势</li>
</ul>
</li>
<li>三条移动平均线，例如: 4、9和18
<ul>
<li>4 &gt; 9 &gt; 18, 上升趋势</li>
<li>4 &lt; 9 &lt; 18, 下降趋势</li>
<li>其他，水平状态</li>
</ul>
</li>
<li>移动平均线和其他技术指标组合<br>
当指标发出的信号不一致时，认为市场无趋势或呈横向趋势</li>
<li>简单化</li>
</ul>
<blockquote>
<p>不建议运用翻转策略，因为这不能鉴定横向趋势的市场，并且总是存在于从多头到空头或者空头到多头的市场。这些反转系统总是倾向于在横向趋势的市场中出现锯齿状波动，毫无成功的可能，除非市场趋势持续如此。</p>
</blockquote>
<h2 id="3-市场择时">3. 市场择时</h2>
<p>依赖单一的”神奇指标“不现实，要设计一个灵活的动态系统，在真实的不断变化的市场条件也能管用。</p>
<h4 id="市场的三种走势">市场的三种走势</h4>
<ul>
<li>长期走势：数周或数月</li>
<li>中期走势：最近几天</li>
<li>短期价格变化：前一天和当天</li>
</ul>
<blockquote>
<p>短期信号最先出现，其次是中期信号，最后是长期信号，当我们鉴别出了长期走势时，第一个中期和短期信号已经出现过了，因子，我们要利用会在长期走势中反复出现的中期和短期信号。</p>
</blockquote>
<h4 id="耐心">耐心</h4>
<p>等到市场时机成熟时进入，增加了每笔交易的利润，减少了必要的资本，减少了交易数量，大大提高了净利润额</p>
<h2 id="4-建立止损">4. 建立止损</h2>
<h4 id="止损过近或过远">止损过近或过远</h4>
<ul>
<li>近止损，损失小、风险低、过早离场</li>
<li>远止损，胜率高、单笔损失大、风险高</li>
</ul>
<h4 id="理想的止损">理想的止损</h4>
<p>建立可接受的止损程序可以通过将止损设立在随机价格波动范围外一点点的位置。</p>
<ol>
<li>一种可行的办法是算出价格移动平均线的标准差,在偏离移动平均线的最高点处建立止损。(布林带)</li>
<li>把每日价格变化的平均值作为建立止损的最小距离,这样可以避免大部分会产生小型的锯齿状波动的价格波动。<br>
例如：建立5或10日移动平均线，将原始止损点设置于移动平均线之间的区间相等的最小距离处。</li>
</ol>
<h4 id="止损方法要保持一致">止损方法要保持一致</h4>
<h2 id="5-退市择时">5. 退市择时</h2>
<ul>
<li>跟踪止损法</li>
<li>相对强弱指标（RSI）</li>
</ul>
<p>退市策略绩效可使用随机入市的方法验证效果</p>
<h2 id="6-再入市择时">6. 再入市择时</h2>
<p>退市策略是更为重要，所以使用可能的最佳的退市策略，然后调节退市后会被触发的再入市指标的敏感度。</p>
<h2 id="7-监控系统">7. 监控系统</h2>
<ul>
<li>每周期交易频率，比如每月1.5笔</li>
<li>盈利交易笔数与亏损交易笔数的百分比</li>
<li>最糟糕的周期中盈利笔数</li>
<li>最佳周期中盈利笔数</li>
<li>最长连续亏损</li>
<li>连续盈利交易</li>
<li>每笔盈利交易的平均收益</li>
<li>平均亏损交易额</li>
<li>最大回吐</li>
<li>最大回吐恢复时长</li>
</ul>
<h1>第二章 技术研究</h1>
<h4 id="方向性运动指标DMI和平均方向性运动指数ADX">方向性运动指标DMI和平均方向性运动指数ADX</h4>
<pre><code>* 下降的ADX预示着市场不呈现任何趋势，应该采取逆势策略，而不是顺势策略。
* ADX滞后性
</code></pre>
<h4 id="布林带、包络线和通道">布林带、包络线和通道</h4>
<p>通道突破作为确认方法</p>
<h4 id="商品通道指数CCI">商品通道指数CCI</h4>
<h4 id="背离">背离</h4>
<ul>
<li>趋势性市场和非趋势性市场<br>
非趋势性市场偏离交易朝两个方向都可以进行，而在趋势性市场逆势的偏离信号一般应该被忽略（视图抓住大的顶部和底部除外）</li>
<li>连续偏离<br>
连续三次偏离</li>
<li>相关市场偏离</li>
</ul>
<h4 id="动力指标和变化率">动力指标和变化率</h4>
<p>动力指标精确测量了市场的运转速度,从某种程度上说,测量了一种趋势完好存在的程度。</p>
<p>计算过程：用当日的收盘价减去n天前的收盘价,结果是一个位于零点或零线附近的正数或负数。</p>
<p>公式：</p>
<blockquote>
<p>M = Pt - Pt-n</p>
</blockquote>
<p>M是动力指标,Pt是当日的收盘价,Pt-n是Pt时间段(通常是天)前的收盘价。</p>
<p>变化率的公式是:</p>
<blockquote>
<p>ROC=100(Pt/Pt-n)</p>
</blockquote>
<p>动力线和零线交叉次数随着动力线指标计算中使用的时间周期的不同而变化。时间周期短，动力线与零线交叉得约频繁，指标发出信号的速度越快。</p>
<p>动力线最有效的用途之一是界定长期趋势。25周期的动力周线图是个非常可靠的长期走势指标。当动力线迅速离开零线时，顺势交易会带来丰厚的回报。</p>
<p>其他指标的动力指标量化倾斜度</p>
<h4 id="移动平均线">移动平均线</h4>
<ul>
<li>
<p>简单移动平均线</p>
</li>
<li>
<p>加权移动平均线</p>
</li>
<li>
<p>指数移动平均线</p>
</li>
<li>
<p>三条移动平均线: 4-9-18均线法</p>
</li>
<li>
<p>四条移动平均线</p>
</li>
<li>
<p>移位后的移动平均线</p>
</li>
<li>
<p>发现过滤器</p>
</li>
</ul>
<h4 id="MACD">MACD</h4>
<h4 id="抛物线指标SAR">抛物线指标SAR</h4>
<p>最大的价值是用来建立止损点</p>
<h4 id="相对强弱指标RSI">相对强弱指标RSI</h4>
<p>RSI &gt; 75 or RSI &lt; 25，推迟入市</p>
<h4 id="慢速随机指标KDJ">慢速随机指标KDJ</h4>
<p>随机指标最不适合用于只有持续的微小变动的趋势性市场</p>
<ul>
<li>左右交点</li>
</ul>
<h4 id="波动性">波动性</h4>
<ul>
<li>平均真实区间（ATR）</li>
<li>突破或价格峰值超出近期区间或平均真实区间是十分重要的信号,应作为入市点。</li>
</ul>
<h1>第三章 系统测试</h1>
<p>避免最优化</p>
<p>从统计学的角度而言,少于30笔交易,产生的结果就不可靠。交易笔数大于30的程度越多</p>
<p>积累的前进测试，滚动前进最优化处理</p>
<h2 id="衡量绩效">衡量绩效</h2>
<h4 id="夏普比率-Sharpe-Ratio">夏普比率(Sharpe Ratio)</h4>
<p>其定义为年度化的收益(一种盈利性度量形式)与无风险收益率的差除以年度化的收益标准差(一种波动度量形式)。</p>
<h4 id="英镑比率-Sterling-Ratio">英镑比率(Sterling Ratio)</h4>
<p>英镑比率=年平均收益比率/[(1×3年平均最大亏损) + 10]</p>
<h4 id="卡尔玛比率-Calmar-Ratio">卡尔玛比率(Calmar Ratio)</h4>
<h4 id="几何平均数">几何平均数</h4>
<p>几何平均数衡量的是你的交易系统的增长因子。几何平均数越高,你的系统再投资时创造高收益的潜力就越大。</p>
<h4 id="净盈利">净盈利</h4>
<h4 id="测试样例中的交易数">测试样例中的交易数</h4>
<p>总交易数必须大于30，这是为了确保统计上的重要结果的可靠性。</p>
<h4 id="最大盈利及最大的亏损交易">最大盈利及最大的亏损交易</h4>
<p>倘若最大的盈利交易不合理地歪曲了净盈利额，它就很重要。许多保守的系统测试员会剔除每种商品中的最大盈利交易,然后再次评价结果。</p>
<h4 id="最大的连续盈利交易和亏损交易">最大的连续盈利交易和亏损交易</h4>
<h4 id="峰到谷式的亏损">峰到谷式的亏损</h4>
<p>计算最大净资产额最为准确的方法是取日总净资产额的最高值与随后的日总净资产额的最低值之差值。</p>
<h4 id="盈利交易百分比">盈利交易百分比</h4>
<p>大部分成功的顺势交易商拥有35%到45%的盈利交易。要达到55%以上是很困难的</p>
<h4 id="平均盈利与平均亏损比率">平均盈利与平均亏损比率</h4>
<h4 id="总收益的最大亏损">总收益的最大亏损</h4>
<h4 id="波动性和破产的概率">波动性和破产的概率</h4>
<h2 id="测试入市、退市及止损方法">测试入市、退市及止损方法</h2>
<p>如果你的风险控制由两种类型的止损方法组成,一个是简单的定额止损法,另一个是将止损位设置为近期高价或低价，如果你知道每种止损价位被触及的频率,这对设计和测试过程会有帮助的。</p>
<h2 id="测试入市方法">测试入市方法</h2>
<p>在整体方案中,退市方法确实要比入市方法重要,毕竟,交易的结果最终由退市决定,当入市做对了后，找到良好的退市方法就要容易很多。</p>
<blockquote>
<p>有效测试一个交易系统的任何单个的要素的最佳方法就是尽量将它分离开来。建立你自己的交易系统，然后删去通常的退出方法。用一种可以在进入每笔交易特定天数后自动退出市场的方法取代原先的退市方法。</p>
</blockquote>
<h2 id="测试退市策略">测试退市策略</h2>
<p>选择一种结果合理的入市方法作为反转系统，然后用相同的数据和入市方法对每种退市策略一一进行测试。</p>
<p>从理论上讲，比入市方法更敏感的退市方法应该捕捉到每个市场变动的更多的信息。以下是对我们测试的退市策略的一个描述。</p>
<h4 id="跟踪止损">跟踪止损</h4>
<p>初始风险是指进入市场点与控制风险的止损点之间的差距。净资产额风险是指开立的头寸的市场价格与你的退市策略暗示的价格之间的差值。</p>
<h2 id="测试止损策略">测试止损策略</h2>
<h4 id="初始风险止损">初始风险止损</h4>
<p>初始风险止损可定义为一种以某种方式限制一笔交易从入市点就可能累积的亏损的止损。当一笔交易对我们不利时，初始风险止损通常先于任何其它类型的退市策略被触发。它是你最基本的“止损”指令。</p>
<ul>
<li>定额止损</li>
<li>支撑/阻力</li>
<li>无利退出, 如果交易在一定天数后无利可获则退出</li>
</ul>
<h4 id="保本止损">保本止损</h4>
<p>保本止损被定义为一旦交易达到一定的利润额，在入市点建立的止损。这种止损的目的明显是要防止合理的利润变为亏损。</p>
<h4 id="跟踪止损-2">跟踪止损</h4>
<p>跟踪止损是指达到一些合乎逻辑的价格点后，不断计算得出的止损价。跟踪止损可以用作初始风险止损或取利退市策略，或者兼任两者功能。</p>
<ul>
<li>从收盘价开始跟踪的定额止损<br>
这种止损是从交易方向的最高收盘价或最低收盘价开始计算止损点。</li>
<li>从高价或低价开始跟踪的定额止损<br>
一旦达到某一盈利高度，就应该跟踪止损保护一定数目的收益。交易的损失将会被限制在交易所达到的高价和低价以及跟踪止损的高价和低价的差额范围内。这种止损可即刻跟踪，并且可以用作初始风险止损，也可以用作跟踪止损。</li>
</ul>
<h2 id="创建一个简单的交易系统">创建一个简单的交易系统</h2>
<h4 id="交易系统的目标">交易系统的目标</h4>
<p>年回报率20% ~ 30%，盈利交易百分比大于40%，平均盈利与平均亏损的比率至少为2:1</p>
<h4 id="风险控制">风险控制</h4>
<ul>
<li>初始风险<br>
即入市点与保护性止损点之间的差距</li>
<li>资产风险<br>
即投入市场的净资产额与跟踪止损价位之间的差额。这两类风险还可以进一步分为单笔交易中的初始风险和资产风险，以及跨投资组合同时交易的初始风险和资产风险。</li>
</ul>
<h1>第四章 日交易</h1>
<h2 id="交易成本">交易成本</h2>
<p>手续费和点差</p>
<h2 id="市场选择">市场选择</h2>
<p>当日high和low价差的绝对值高，或者更高的时间比率。持续的高波动性是日内交易市场或标的选择的重要指标。</p>
<h3 id="考虑最小变动价位的大小">考虑最小变动价位的大小</h3>
<p>流动性及最小价差的大小也是选择日交易市场时应该考虑的因素</p>
<p>日交易商不断地面临着从相对小的价格变化幅度中获取最大利润的问题。这种情况自然使得交易商采取回调时买进、反弹时卖出的策略,而不是试图去顺应走势。大部分的顺势策略对于日交易而言往往太慢。逆势策略提供了从一个小的价格变化幅度中获取最大利润的可能性。然而，逆势策略往往不如顺势策略那么可靠，因为快速地识别出价格的转轨点比简单的顺势交易要难得多。</p>
<p>成功的日交易商试图在上升趋势阶段中的回调时买进，在下降趋势阶段在反弹时卖出。想持续赚钱的日交易商必须善于顺应趋势，又要善于发现短期的转折点。许多交易商亏钱是因为他们两者都不擅长。看过一些可能的日交易策略的例子后，请记住两个步骤：首先找出中期走势，然后找出短期转折点。要想获得盈利的日交易，两步都要进行得快而准。</p>
<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次坑爹的OTC交易经历</title>
    <url>/2019/06/13/2019-06-13%20%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%9D%91%E7%88%B9%E7%9A%84OTC%E4%BA%A4%E6%98%93%E7%BB%8F%E5%8E%86/</url>
    <content><![CDATA[<p>6月11号在火币OTC上卖了一点BTC给朋友还钱，结果今天朋友告诉我他的银行卡被冻结了，我看了下自己的银行卡，发现我的银行卡也被冻结了，只能转入不能转出。</p>
<p><img src="/Users/eryk/Desktop/20190613164831.png" alt=""></p>
<p>给银行打电话询问，答复是司法冻结的，银行看不到原因和无权解冻。银行告诉我冻结的是哪个公安局和案件号(这两个信息非常重要)。之后打当地114查询到公安局的电话号码。</p>
<p>我又联系火币网，客服给了我一个链接，一看就懂了，链接和截图附在文后。。。看来有不少人被坑过，大概意思是司法冻结的原因是可能涉及到赃款，看严重程度不同账号被冻结的时间长度也不同，短的会被冻结48-72小时，长的可以冻结半年。之后给公安局打电话询问了我的账户的情况，大致意思是说给我转账的银行卡涉及电信诈骗，所以我的卡被冻结48小时，之后就没事了。</p>
<p>小建议：</p>
<blockquote>
<p>OTC交易尽量选择交易量大的ID进行交易</p>
</blockquote>
<p><a href="https://huobiglobal.zendesk.com/hc/zh-cn/articles/360000159321-%E5%85%B3%E4%BA%8E%E9%93%B6%E8%A1%8C%E5%8D%A1%E5%86%BB%E7%BB%93%E5%8F%8A%E5%A4%84%E7%90%86%E5%8A%9E%E6%B3%95" target="_blank" rel="noopener">关于银行卡冻结及处理办法</a>  (火币官网链接需要翻墙)，重要内容截图如下</p>
<p><img src="/Users/eryk/Desktop/20190613165715.png" alt=""></p>
<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>otc</tag>
      </tags>
  </entry>
  <entry>
    <title>将DataFrame内存大小减少约65％</title>
    <url>/2019/06/05/2019-06-05%20%E5%B0%86DataFrame%E5%86%85%E5%AD%98%E5%A4%A7%E5%B0%8F%E5%87%8F%E5%B0%91%E7%BA%A665%EF%BC%85/</url>
    <content><![CDATA[<p>这篇文章原文出自kaggle，我大致翻译翻一下，文中给出了reduce_mem_usage方法可以用来自动缩减dataframe占用空间</p>
<p>这篇notebook展示了通过使用更合理的数据类型来减少dataframe的内存使用量</p>
<p>方法如下：</p>
<ol>
<li>迭代每一个column</li>
<li>检查column是否为数字型</li>
<li>检查column是否可以用integer表示</li>
<li>找出column下的最大值和最小值</li>
<li>选择适用于数据范围的最合适的数据类型</li>
</ol>
<p>通过以上步骤处理后将一份测试数据从1.3GB减少到466MB</p>
<p>源码如下:</p>
<pre><code class="language-python">import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

def reduce_mem_usage(props):
    start_mem_usg = props.memory_usage().sum() / 1024**2 
    print(&quot;Memory usage of properties dataframe is :&quot;,start_mem_usg,&quot; MB&quot;)
    NAlist = [] # Keeps track of columns that have missing values filled in. 
    for col in props.columns:
        if props[col].dtype != object:  # Exclude strings
            
            # Print current column type
            print(&quot;******************************&quot;)
            print(&quot;Column: &quot;,col)
            print(&quot;dtype before: &quot;,props[col].dtype)
            
            # make variables for Int, max and min
            IsInt = False
            mx = props[col].max()
            mn = props[col].min()
            
            # Integer does not support NA, therefore, NA needs to be filled
            if not np.isfinite(props[col]).all(): 
                NAlist.append(col)
                props[col].fillna(mn-1,inplace=True)  
                   
            # test if column can be converted to an integer
            asint = props[col].fillna(0).astype(np.int64)
            result = (props[col] - asint)
            result = result.sum()
            if result &gt; -0.01 and result &lt; 0.01:
                IsInt = True

            
            # Make Integer/unsigned Integer datatypes
            if IsInt:
                if mn &gt;= 0:
                    if mx &lt; 255:
                        props[col] = props[col].astype(np.uint8)
                    elif mx &lt; 65535:
                        props[col] = props[col].astype(np.uint16)
                    elif mx &lt; 4294967295:
                        props[col] = props[col].astype(np.uint32)
                    else:
                        props[col] = props[col].astype(np.uint64)
                else:
                    if mn &gt; np.iinfo(np.int8).min and mx &lt; np.iinfo(np.int8).max:
                        props[col] = props[col].astype(np.int8)
                    elif mn &gt; np.iinfo(np.int16).min and mx &lt; np.iinfo(np.int16).max:
                        props[col] = props[col].astype(np.int16)
                    elif mn &gt; np.iinfo(np.int32).min and mx &lt; np.iinfo(np.int32).max:
                        props[col] = props[col].astype(np.int32)
                    elif mn &gt; np.iinfo(np.int64).min and mx &lt; np.iinfo(np.int64).max:
                        props[col] = props[col].astype(np.int64)    
            
            # Make float datatypes 32 bit
            else:
                props[col] = props[col].astype(np.float32)
            
            # Print new column type
            print(&quot;dtype after: &quot;,props[col].dtype)
            print(&quot;******************************&quot;)
    
    # Print final result
    print(&quot;___MEMORY USAGE AFTER COMPLETION:___&quot;)
    mem_usg = props.memory_usage().sum() / 1024**2 
    print(&quot;Memory usage is: &quot;,mem_usg,&quot; MB&quot;)
    print(&quot;This is &quot;,100*mem_usg/start_mem_usg,&quot;% of the initial size&quot;)
    return props, NAlist
</code></pre>
<p>原文链接：</p>
<p><a href="https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65" target="_blank" rel="noopener">https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65</a></p>
<hr>
<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas hdf5使用指南翻译</title>
    <url>/2019/05/08/2019-05-08%20Pandas%20hdf5%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%E7%BF%BB%E8%AF%91/</url>
    <content><![CDATA[<h1>读写API</h1>
<p>HDFStore支持使用read_hdf进行读取和使用to_hdf进行写入的top-level API，类似于read_csv和to_csv的工作方式。</p>
<p>默认情况下，HDFStore不会丢弃全部为na的行。可以通过设置dropna = True来更改此行为。</p>
<pre><code class="language-python">import pandas as pd
import h5py
df_tl = pd.DataFrame({'A': list(range(5)), 'B': list(range(5))})
df_tl.to_hdf('store_tl.h5', 'table', append=True)
pd.read_hdf('store_tl.h5', 'table', where=['index&gt;2'])
</code></pre>
<h1>HDF数据类型</h1>
<ul>
<li>Fixed Format
<ul>
<li>一次写入，重复读取，不可追加</li>
<li>不可以使用where查询，比如每次获取指定key的全部内容</li>
<li>不支持dataframe有非唯一的column</li>
<li>相比于table格式更快的读写速度</li>
<li>使用put或者to_hdf时的默认类型，也可以通过format='fixed’或format='f’指定类型</li>
</ul>
</li>
<li>Table Format
<ul>
<li>支持append操作</li>
<li>支持删除和查询类型操作</li>
<li>执行put或者to_hdf操作时通过设置format='table’或format='t’指定table格式</li>
<li>pd.set_option(‘io.hdf.default_format’,‘table’) 设置默认hdf format类型</li>
</ul>
</li>
</ul>
<blockquote>
<p>在第一次append/put操作之后，您无法更改数据列（也不能转换索引）（当然，您只需读取数据并创建新表！）。</p>
</blockquote>
<blockquote>
<p>警告HDFStore对于写入不是线程安全的。底层PyTables仅支持并发读取（通过线程或进程）。如果您需要同时进行读写，则需要在单个进程中在单个线程中序列化这些操作。否则你将破坏你的数据。</p>
</blockquote>
<p>TODO 验证append是否会按照index排序的例子</p>
<h1>Hierarchical Keys</h1>
<p>key可以包含路径，例如’/food/apple’, 存储时会自动创建sub-stores(在pytables中是groups)，可以省略路径开头的’/’，’/food/apple’和’food/apple’表示相同的key。</p>
<blockquote>
<p>注意：删除操作会删除子路径下的所有内容，请小心使用</p>
</blockquote>
<pre><code class="language-python">df = pd.DataFrame({'A': list(range(2)), 'B': list(range(2))})
store = pd.HDFStore('hk_test.h5')
store.append('/food/apple', df)
store.append('food/orange', df)
store.append('df',df)
print(store.keys())

for (path, subgroups, subkeys) in store.walk():
    for subgroup in subgroups:
        print('GROUP: {}/{}'.format(path, subgroup))
    for subkey in subkeys:
        key = '/'.join([path, subkey])
        print('KEY: {}'.format(key))
        print(store.get(key))

print(store['food/orange'])
</code></pre>
<h1>查询</h1>
<p>select和delete操作可以通过查询语句对数据子集进行操作，好处是可以在非常大的数据集上只检索一小部分数据。</p>
<p>查询表达式:</p>
<ul>
<li>支持使用index和columns查询dataframe</li>
<li>支持使用major_axis、minor_axis和items查询Panel</li>
<li>如果指定data_columns，则它将被作为附加索引器</li>
</ul>
<p>有效的比较运算符是：</p>
<p>=, ==, !=, &gt;, &gt;=, &lt;, &lt;=</p>
<p>有效的布尔表达式包括：</p>
<ul>
<li>| : 或操作</li>
<li>&amp; : 与操作</li>
<li>( 和 ) : 分组</li>
</ul>
<p>例子：</p>
<ul>
<li>‘index &gt;= date’</li>
<li>“columns = [‘A’, ‘D’]”</li>
<li>“columns in [‘A’, ‘D’]”</li>
<li>‘columns = A’</li>
<li>‘columns == A’</li>
<li>“~(columns = [‘A’, ‘B’])”</li>
<li>‘index &gt; df.index[3] &amp; string = “bar”’</li>
<li>‘(index &gt; df.index[3] &amp; index &lt;= df.index[6]) | string = “bar”’</li>
<li>“ts &gt;= Timestamp(‘2012-02-01’)”</li>
<li>“major_axis&gt;=20130101”</li>
</ul>
<p>不建议通过将字符串插入查询表达式来将字符串传递给查询。只需将感兴趣的字符串分配给变量，并在表达式中使用该变量。<br>
例如：</p>
<pre><code class="language-python">string = &quot;HolyMoly'&quot;
store.select('df', 'index == string')
store.select('dfq', &quot;index&gt;pd.Timestamp('20130104') &amp; columns=['A', 'B']&quot;)
store.select('dfq', where=&quot;A&gt;0 or C&gt;0&quot;)
store.select('df', &quot;columns=['A', 'B']&quot;)
</code></pre>
<h1>删除</h1>
<pre><code class="language-python">store.remove('wp', 'major_axis &gt; 20000102')
</code></pre>
<blockquote>
<p>警告: 请注意HDF5不会自动回收h5文件中的空格。因此，反复删除（或删除节点）并再次添加，将趋于增加文件大小。</p>
</blockquote>
<h1>压缩</h1>
<ul>
<li>complevel指定压缩强度，complevel = 0和complevel = None禁用压缩，0 &lt;complevel &lt;10启用压缩。</li>
<li>complib 指定压缩库，默认使用zlib
<ul>
<li>zlib：默认的压缩库。压缩方面的经典之作可以实现良好的压缩率，但速度有些慢。</li>
<li>lzo：快速压缩和减压。</li>
<li>bzip2：良好的压缩率。</li>
<li>blosc：快速压缩和解压缩。</li>
<li>blosc：blosclz这是blosc的默认压缩器</li>
<li>blosc：lz4：紧凑，非常流行和快速的压缩机。</li>
<li>blosc：lz4hc：LZ4的调整版本，以牺牲速度为代价产生更好的压缩比。</li>
<li>blosc：snappy：在许多地方使用的流行压缩器。</li>
<li>blosc：zlib：经典;比以前慢一些，但实现了更好的压缩比。</li>
<li>blosc：zstd：非常平衡的编解码器;它提供了上述其他压缩比，并且速度相当快。</li>
</ul>
</li>
</ul>
<pre><code class="language-python">store_compressed = pd.HDFStore('store_compressed.h5', complevel=9,complib='blosc:blosclz')

store.append('df', df, complib='zlib', complevel=5)
</code></pre>
<h3 id="ptrepack">ptrepack</h3>
<p>重新生成压缩文件，重写文件将回收已删除的空间，也可以改变complevel</p>
<pre><code class="language-shell">ptrepack --chunkshape=auto --propindexes --complevel=9 --complib=blosc in.h5 out.h5

</code></pre>
<h1>性能</h1>
<ul>
<li>fixed stores 读写速度快于 tables 格式，但tables支持追加、删除和查询操作</li>
<li>可以设置chunksize=&lt; int &gt;来指定chunsize大小，这将会降低写入时的内存使用量</li>
<li>设置expectedrows 可以优化读写性能</li>
<li>Duplicate rows将会被写入tables，在select时会被过滤掉</li>
</ul>
<hr>
<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pandas</tag>
        <tag>hdf5</tag>
      </tags>
  </entry>
  <entry>
    <title>使用pyfolio对策略收益进行分析</title>
    <url>/2019/04/30/2019-04-30%20%E4%BD%BF%E7%94%A8pyfolio%E5%AF%B9%E7%AD%96%E7%95%A5%E6%94%B6%E7%9B%8A%E8%BF%9B%E8%A1%8C%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>之前写过一篇文章实现了一个简单的双均线策略，传送门：<a href="https://mp.weixin.qq.com/s?__biz=MjM5Njc1Mjg0Mw==&amp;mid=2247483716&amp;idx=1&amp;sn=678ac24a3d00cac08bb71a8d8546f113&amp;chksm=a6e53de09192b4f604fe8e91dff9bfef5ecfcfe5c2317b9d310318605e1d9b7ec7f96e07e1f3&amp;token=1630830994&amp;lang=zh_CN#rd" target="_blank" rel="noopener">使用Pandas开发一个双均线策略</a></p>
<p>文章最后一张图看到策略收益并没有跑赢中证500指数，想更深入的了解下具体的收益情况，可以使用pyfolio工具，这个工具是著名的量化研究平台quantopian开发的，主要用途就是对投资组合进行风险分析。</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190423225315.png" alt=""></p>
<p>pyfolio github地址：<a href="https://github.com/quantopian/pyfolio%EF%BC%8C%E5%AE%89%E8%A3%85%E9%9D%9E%E5%B8%B8%E7%AE%80%E5%8D%95:" target="_blank" rel="noopener">https://github.com/quantopian/pyfolio，安装非常简单:</a></p>
<pre><code class="language-shell">pip install pyfolio
</code></pre>
<p>安装之后导入模块</p>
<pre><code class="language-python">import pyfolio as pf
# silence warnings
import warnings
warnings.filterwarnings('ignore')
</code></pre>
<p>对上一篇文章中生成的策略回报和市场回报的series进行分析</p>
<pre><code class="language-python">pf.show_perf_stats(etf500['Strategy'],etf500['Market Returns'],live_start_date='2018-1-1')
</code></pre>
<p>live_start_date参数是模拟策略实盘开始交易的时间点，下图中 ‘2018-1-1’ 之前的样本内数据一共有55个月，'2018-1-1’之后的样本外数据一共15个月</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190430132342.png" alt=""></p>
<p>年化回报率为17.7%</p>
<p>从2013年3月15日开始累计投资回报率为161.6%</p>
<p>整体测试时间段内的最大回撤为59.1%，夏普值只有0.47</p>
<p>我们再来看下最大回测的时间段，下图显示最大回撤发生在2015年6月12日 - 2019年2月20日，累计最大回撤59.12%，2015年6月12日刚好是股灾开始的时候，惨痛的回忆。。。</p>
<pre><code class="language-python">pf.show_worst_drawdown_periods(etf500['Strategy'])
</code></pre>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190430133103.png" alt=""></p>
<p>其实这个策略还有优化的空间，下一篇文章介绍下如果对双均线策略进行参数优化。</p>
<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
]]></content>
      <categories>
        <category>策略研究</category>
      </categories>
      <tags>
        <tag>pyfolio</tag>
      </tags>
  </entry>
  <entry>
    <title>处理linux系统僵尸进程</title>
    <url>/2019/04/26/2019-04-26%20%E5%A4%84%E7%90%86linux%E7%B3%BB%E7%BB%9F%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B/</url>
    <content><![CDATA[<p>最近在使用jupyter运行多进程程序时，发现重启jupyter notebook偶尔会留下一些僵尸进程，应该是python父进程被终止之后子进程没有被正确释放造成的。僵尸进程依然会占用系统资源，如果不及时清理可能会严重影响系统性能。</p>
<p>先解释下什么是僵尸进程</p>
<blockquote>
<p>僵尸进程是当子进程比父进程先结束，而父进程又没有回收子进程，释放子进程占用的资源，此时子进程将成为一个僵尸进程。如果父进程先退出 ，子进程被init接管，子进程退出后init会回收其占用的相关资源。</p>
<p>在UNIX 系统中，一个进程结束了，但是他的父进程没有等待(调用wait / waitpid)他， 那么他将变成一个僵尸进程。<br>
— 百度百科</p>
</blockquote>
<p>在jupyter中使用多进程执行程序时，如果程序还没有执行完成就点击菜单栏的 Kernel -&gt; Restart xxx，就有可能会造成僵尸进程。</p>
<p>如何检查僵尸进程是否存在呢？在命令行中执行如下命令就可以返回僵尸进程状态、父进程ID、进程ID和执行的具体命令：</p>
<pre><code class="language-shell">ps -A -ostat,ppid,pid,cmd | grep -e '^[Zz]'
</code></pre>
<p>杀死僵尸进程也比较容易，执行如下命令就可以清理僵尸进程：</p>
<pre><code class="language-shell">kill -9 `ps -A -ostat,ppid,pid,cmd | grep -e '^[Zz]' | awk '{print $2}'`
</code></pre>
<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Queue</tag>
        <tag>Pipe</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Pandas开发一个均线策略</title>
    <url>/2019/04/24/%E4%BD%BF%E7%94%A8Pandas%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E5%9D%87%E7%BA%BF%E7%AD%96%E7%95%A5/</url>
    <content><![CDATA[<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
<p>大家好，这篇文章我将使用Pandas创建一个简单的均线交叉策略，以500ETF作为标的物进行回测</p>
<p>移动平均线可能是技术指标里的&quot;hello world&quot;了，常用的均线有5、10、20、60、120日均线，在其他时间周期上应用移动平均线指标也是类似方式。</p>
<p>移动平均线按时间周期长短分为：短期移动平均线，中期移动平均线，长期移动平均线；按计算方法分为：算术移动平均线，加权移动平均线，指数平滑移动平均线（EMA）</p>
<p>下面正式开始编写策略代码，我们使用jupyer作为研究环境，首先先导入依赖模块</p>
<pre><code class="language-python">import pandas as pd
import numpy as np
import tushare as ts

%matplotlib inline
</code></pre>
<p>接下来使用tushare下载500ETF的历史数据，500ETF是从2013年开始上市交易的，这里将start参数设置为2013，这样可以获取500ETF的全部历史数据。</p>
<pre><code class="language-python">etf500 = ts.get_k_data('510500',start='2013')
etf500.set_index(pd.to_datetime(etf500['date']),inplace=True) 
del etf500['date']
etf500.head()
</code></pre>
<p>输出结果如下，数据是从2013年3月15日开始的：</p>
<table>
<thead>
<tr>
<th style="text-align:right">date</th>
<th style="text-align:right">open</th>
<th style="text-align:right">close</th>
<th style="text-align:right">high</th>
<th style="text-align:right">low</th>
<th style="text-align:right">volume</th>
<th style="text-align:right">code</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">2013-03-15</td>
<td style="text-align:right">0.967</td>
<td style="text-align:right">0.970</td>
<td style="text-align:right">0.985</td>
<td style="text-align:right">0.955</td>
<td style="text-align:right">3259273.0</td>
<td style="text-align:right">510500</td>
</tr>
<tr>
<td style="text-align:right">2013-03-18</td>
<td style="text-align:right">0.955</td>
<td style="text-align:right">0.954</td>
<td style="text-align:right">0.972</td>
<td style="text-align:right">0.953</td>
<td style="text-align:right">936962.0</td>
<td style="text-align:right">510500</td>
</tr>
<tr>
<td style="text-align:right">2013-03-19</td>
<td style="text-align:right">0.956</td>
<td style="text-align:right">0.960</td>
<td style="text-align:right">0.960</td>
<td style="text-align:right">0.941</td>
<td style="text-align:right">1080499.0</td>
<td style="text-align:right">510500</td>
</tr>
<tr>
<td style="text-align:right">2013-03-20</td>
<td style="text-align:right">0.960</td>
<td style="text-align:right">0.985</td>
<td style="text-align:right">0.986</td>
<td style="text-align:right">0.958</td>
<td style="text-align:right">501195.0</td>
<td style="text-align:right">510500</td>
</tr>
<tr>
<td style="text-align:right">2013-03-21</td>
<td style="text-align:right">0.985</td>
<td style="text-align:right">0.995</td>
<td style="text-align:right">0.996</td>
<td style="text-align:right">0.981</td>
<td style="text-align:right">698243.0</td>
<td style="text-align:right">510500</td>
</tr>
</tbody>
</table>
<p>继续画出收盘价格曲线，对500ETF走势有个大概的了解。</p>
<pre><code class="language-python">etf500['close'].plot(grid=True, figsize=(8,5))
</code></pre>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190423172643.png" alt=""></p>
<p>接下来是双均线策略的实现，我们使用20日均线和60日均线作为短期和长期均线，下面先分别计算20日和60日均线序列</p>
<pre><code class="language-python">etf500['ma20'] = etf500['close'].rolling(20).mean()
etf500['ma60'] = etf500['close'].rolling(60).mean()
etf500[['close','ma20','ma60']].plot(grid=True, figsize=(14,5))
</code></pre>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190423174737.png" alt=""></p>
<p>我们已经获取了两条移动平均线序列，接下来是根据均线来生成交易信号</p>
<p>策略信号会有两种状态：</p>
<ol>
<li>
<p>买入信号，当20日均线向上穿过60日均线时持有多头仓位</p>
</li>
<li>
<p>卖出信号，当20日均线向下穿过60日均线时平仓</p>
</li>
</ol>
<pre><code class="language-python">etf500['Stance'] = np.where(etf500['ma20'] - etf500['ma60'] &gt; 0, 1, 0)
etf500['Stance'].value_counts()
</code></pre>
<p>最后一行统计持仓和空仓的天数，输出结果如下：</p>
<pre><code class="language-python">1    761
0    724
Name: Stance, dtype: int64
</code></pre>
<pre><code class="language-python">etf500['Stance'].plot(ylim=[-0.1,1.1])
</code></pre>
<p>下图显示持仓日期数据</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190423223738.png" alt=""></p>
<p>接下来，我们根据持仓数据来计算持仓的收益</p>
<pre><code class="language-python">etf500['Market Returns'] = np.log(etf500['close'] / etf500['close'].shift(1))
etf500['Strategy'] = etf500['Market Returns'] * etf500['Stance'].shift(1)
etf500[['Market Returns','Strategy']].cumsum().plot(grid=True,figsize=(8,5))
</code></pre>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190423225315.png" alt=""></p>
<p>以上图片展示了市场回报率与策略回报曲线，可以看到20和60日双均线策略并没有跑赢500ETF，不过我们也可以测试下其他均线组合，也许会有不错的效果。</p>
<h3 id="参考">参考</h3>
<p><a href="https://www.pythonforfinance.net/2016/09/01/moving-average-crossover-trading-strategy-backtest-in-python/#more-15498" target="_blank" rel="noopener">https://www.pythonforfinance.net/2016/09/01/moving-average-crossover-trading-strategy-backtest-in-python/#more-15498</a>&gt;</p>
]]></content>
      <categories>
        <category>策略研究</category>
      </categories>
      <tags>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>Multiprocessing Pipe和Queue性能测试</title>
    <url>/2019/04/22/2019-04-22%20Multiprocessing%20Pipe%E5%92%8CQueue%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
<h1>背景</h1>
<p>开发股票行情推送的引擎时遇到一个问题，在9:30开盘后的一段时间内行情消息总是堆积，尤其是开头15-20分钟，堆积的数据量会越来越多，经过debug发现是内部消息传输使用Queue性能问题导致了消息延迟，在stackoverflow上找到一个帖子对Queue的性能进行了测试和解释说明，下面先来介绍下Multiprocessing下的Queue和Pipe</p>
<h1>介绍</h1>
<p>当使用多个进程时，通常使用消息传递来进行进程之间的通信，为了不损耗性能也会尽量避免使用同步机制。对于消息传递：</p>
<pre><code>* Pipe适用于两个进程间的消息传递。
* Queue适用于多个进程间的消息传递，适用于多生产者和消费者的模式。
</code></pre>
<h1>Pipe VS Queue</h1>
<pre><code class="language-python">from multiprocessing import Process, Pipe
import time

def reader_proc(pipe):
    ## Read from the pipe; this will be spawned as a separate Process
    p_output, p_input = pipe
    p_input.close()  # We are only reading
    while True:
        msg = p_output.recv()  # Read from the output pipe and do nothing
        if msg == 'DONE':
            break

def writer(count, p_input):
    for ii in range(0, count):
        p_input.send(ii)  # Write 'count' numbers into the input pipe
    p_input.send('DONE')

if __name__ == '__main__':
    for count in [10 ** 4, 10 ** 5, 10 ** 6]:
        # Pipes are unidirectional with two endpoints:  p_input ------&gt; p_output
        p_output, p_input = Pipe()  # writer() writes to p_input from _this_ process
        reader_p = Process(target=reader_proc, args=((p_output, p_input),))
        reader_p.daemon = True
        reader_p.start()  # Launch the reader process

        p_output.close()  # We no longer need this part of the Pipe()
        _start = time.time()
        writer(count, p_input)  # Send a lot of stuff to reader_proc()
        p_input.close()
        reader_p.join()
        print(&quot;Sending {0} numbers to Pipe() took {1} seconds&quot;.format(count,
                                                                      (time.time() - _start)))

</code></pre>
<h3 id="Pipe输出结果">Pipe输出结果</h3>
<pre><code class="language-shell">Sending 10000 numbers to Pipe() took 0.0744009017944336 seconds
Sending 100000 numbers to Pipe() took 0.7794349193572998 seconds
Sending 1000000 numbers to Pipe() took 7.425454139709473 seconds
</code></pre>
<pre><code class="language-python">from multiprocessing import Process, Queue
import time
import sys

def reader_proc(queue):
    ## Read from the queue; this will be spawned as a separate Process
    while True:
        msg = queue.get()  # Read from the queue and do nothing
        if (msg == 'DONE'):
            break

def writer(count, queue):
    ## Write to the queue
    for ii in range(0, count):
        queue.put(ii)  # Write 'count' numbers into the queue
    queue.put('DONE')

if __name__ == '__main__':
    pqueue = Queue()  # writer() writes to pqueue from _this_ process
    for count in [10 ** 4, 10 ** 5, 10 ** 6]:
        ### reader_proc() reads from pqueue as a separate process
        reader_p = Process(target=reader_proc, args=((pqueue),))
        reader_p.daemon = True
        reader_p.start()  # Launch reader_proc() as a separate python process

        _start = time.time()
        writer(count, pqueue)  # Send a lot of stuff to reader()
        reader_p.join()  # Wait for the reader to finish
        print(&quot;Sending {0} numbers to Queue() took {1} seconds&quot;.format(count,
                                                                       (time.time() - _start)))

</code></pre>
<h4 id="Queue-输出结果">Queue 输出结果</h4>
<pre><code class="language-shell">Sending 10000 numbers to Queue() took 0.2558887004852295 seconds
Sending 100000 numbers to Queue() took 2.4320709705352783 seconds
Sending 1000000 numbers to Queue() took 23.602338075637817 seconds
</code></pre>
<p>让我们把结果整理成表格方便对比查看:</p>
<table>
<thead>
<tr>
<th style="text-align:right">循环次数</th>
<th style="text-align:right">Pipe</th>
<th style="text-align:right">Queue</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">10000</td>
<td style="text-align:right">0.0744</td>
<td style="text-align:right">0.2558</td>
</tr>
<tr>
<td style="text-align:right">100000</td>
<td style="text-align:right">0.7794</td>
<td style="text-align:right">2.4320</td>
</tr>
<tr>
<td style="text-align:right">1000000</td>
<td style="text-align:right">7.4254</td>
<td style="text-align:right">23.6023</td>
</tr>
</tbody>
</table>
<p>通过对比测试可以发现，Pipe性能大约为Queue的3倍，所以在仅有两端通信的情况下应该优先使用Pipe。</p>
<h1>源码分析</h1>
<p>通过阅读Queue的源码，我们可以发现，其实在Queue内部是用Lock来实现对Pipe的安全读写操作的。所以相比于Pipe会有额外的锁的开销。</p>
<pre><code class="language-python">class Queue(object):

    def __init__(self, maxsize=0, *, ctx):
        if maxsize &lt;= 0:
            # Can raise ImportError (see issues #3770 and #23400)
            from .synchronize import SEM_VALUE_MAX as maxsize
        self._maxsize = maxsize
        self._reader, self._writer = connection.Pipe(duplex=False) # 这里初始化了Pipe对象
        self._rlock = ctx.Lock()
        self._opid = os.getpid()
        if sys.platform == 'win32':
            self._wlock = None
        else:
            self._wlock = ctx.Lock()
        self._sem = ctx.BoundedSemaphore(maxsize)
        # For use by concurrent.futures
        self._ignore_epipe = False
        self._after_fork()
        if sys.platform != 'win32':
            register_after_fork(self, Queue._after_fork)

    def put(self, obj, block=True, timeout=None):
        if self._closed:
            raise ValueError(f&quot;Queue {self!r} is closed&quot;)
        if not self._sem.acquire(block, timeout):
            raise Full

        with self._notempty:
            if self._thread is None:
                self._start_thread()
            self._buffer.append(obj)
            self._notempty.notify()

    def get(self, block=True, timeout=None):
        if self._closed:
            raise ValueError(f&quot;Queue {self!r} is closed&quot;)
        if block and timeout is None:
            with self._rlock:
                res = self._recv_bytes()
            self._sem.release()
        else:
            if block:
                deadline = time.monotonic() + timeout
            if not self._rlock.acquire(block, timeout):
                raise Empty
            try:
                if block:
                    timeout = deadline - time.monotonic()
                    if not self._poll(timeout):
                        raise Empty
                elif not self._poll():
                    raise Empty
                res = self._recv_bytes()
                self._sem.release()
            finally:
                self._rlock.release()
        # unserialize the data after having released the lock
        return _ForkingPickler.loads(res)
</code></pre>
<h1>参考</h1>
<p><a href="https://stackoverflow.com/questions/8463008/multiprocessing-pipe-vs-queue" target="_blank" rel="noopener">https://stackoverflow.com/questions/8463008/multiprocessing-pipe-vs-queue</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Queue</tag>
        <tag>Pipe</tag>
      </tags>
  </entry>
  <entry>
    <title>virtualenv 使用教程</title>
    <url>/2019/04/19/2019-04-19/</url>
    <content><![CDATA[<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
<p>virtualenv是python虚拟软件环境的管理工具，用于创建和删除虚拟环境</p>
<h3 id="特性">特性</h3>
<ol>
<li>隔离性，将python软件环境打包安装到单独的目录下，可以以项目或者脚本为单位单独创建虚拟环境，防止项目间模块版本混乱和冲突的问题。</li>
<li>易用性，通过一行命令即可创建虚拟环境，在虚拟环境之间切换也非常简单</li>
</ol>
<h3 id="安装virtualenv">安装virtualenv</h3>
<pre><code>pip install virtualenv
</code></pre>
<h3 id="使用介绍">使用介绍</h3>
<pre><code>virtualenv --help
</code></pre>
<p>比较有用的几个参数：</p>
<ul>
<li>-p PYTHON_EXE, --python=PYTHON_EXE，指定虚拟环境中的python版本</li>
<li>–system-site-packages， 创建的虚拟环境将使用连接的方式，添加系统默认python环境中的site-packages</li>
<li>–always-copy，使用copy的方式代替连接来添加系统默认python已安装模块</li>
</ul>
<h3 id="创建虚拟环境">创建虚拟环境</h3>
<pre><code>mkdir myproject
cd myproject
virtualenv --p python3.6 venv
</code></pre>
<h3 id="激活和退出虚拟环境">激活和退出虚拟环境</h3>
<p>激活虚拟环境，系统激活之后，提示符前端有个(venv)的前缀，表示系统已经切换到venv虚拟环境目录下</p>
<pre><code>source venv/bin/activate
</code></pre>
<p>在venv环境下，安装模块可以使用pip来进行</p>
<p>退出虚拟环境，退出后系统将自动选择系统默认的Python解释器，提示符前缀的(venv)也会消失</p>
<pre><code>deactivate
</code></pre>
<h3 id="删除虚拟环境">删除虚拟环境</h3>
<p>由于每个虚拟环境是独立部署的，所以直接将虚拟环境目录rm就可以完成清理</p>
<h3 id="其他">其他</h3>
<p>virtualenvwrapper是virtualenv的扩展管理包，用于更方便管理虚拟环境，它可以做：</p>
<ul>
<li>将所有虚拟环境整合在一个目录下</li>
<li>管理（新增，删除，复制）虚拟环境</li>
<li>切换虚拟环境</li>
</ul>
<p>另外，从python3.3之后，virtualenv已经作为python模块venv提供使用，具体信息可以参考一下网址：</p>
<blockquote>
<p><a href="https://docs.python.org/3/library/venv.html" target="_blank" rel="noopener">https://docs.python.org/3/library/venv.html</a></p>
</blockquote>
<h3 id="参考">参考</h3>
<ul>
<li><a href="https://virtualenv.pypa.io/en/latest/" target="_blank" rel="noopener">https://virtualenv.pypa.io/en/latest/</a></li>
<li><a href="https://virtualenvwrapper.readthedocs.io/en/latest/" target="_blank" rel="noopener">https://virtualenvwrapper.readthedocs.io/en/latest/</a></li>
<li><a href="https://segmentfault.com/a/1190000012030061" target="_blank" rel="noopener">https://segmentfault.com/a/1190000012030061</a></li>
<li><a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001432712108300322c61f256c74803b43bfd65c6f8d0d0000" target="_blank" rel="noopener">https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001432712108300322c61f256c74803b43bfd65c6f8d0d0000</a></li>
</ul>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>virtualenv</tag>
      </tags>
  </entry>
  <entry>
    <title>创建docker ftp服务器</title>
    <url>/2019/03/22/2019-03-22/</url>
    <content><![CDATA[<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
<p>使用的docker镜像是 <a href="https://github.com/stilliard/docker-pure-ftpd" target="_blank" rel="noopener">https://github.com/stilliard/docker-pure-ftpd</a></p>
<p>创建步骤如下</p>
<pre><code class="language-shell">docker pull stilliard/pure-ftpd:hardened

docker run -d -e FTP_USER_NAME=test -e FTP_USER_PASS=test --name ftpd_server -p 21:21 -e FTP_PASSIVE_PORTS=45020:45100 --expose=45020-45100 -p 45020-45100:45020-45100 -v /home/test:/home/ftpusers -e &quot;PUBLICHOST=10.168.2.178&quot; -e FTP_USER_HOME=/home/ftpusers stilliard/pure-ftpd:hardened
</code></pre>
<p>注意：FileZilla传输模式需要选择“主动”</p>
<p>提供的参数解释说明</p>
<pre><code>/usr/sbin/pure-ftpd # path to pure-ftpd executable
-c 5 # --maxclientsnumber (no more than 5 people at once)
-C 5 # --maxclientsperip (no more than 5 requests from the same ip)
-l puredb:/etc/pure-ftpd/pureftpd.pdb # --login (login file for virtual users)
-E # --noanonymous (only real users)
-j # --createhomedir (auto create home directory if it doesnt already exist)
-R # --nochmod (prevent usage of the CHMOD command)
-P $PUBLICHOST # IP/Host setting for PASV support, passed in your the PUBLICHOST env var
-p 30000:30009 # PASV port range (10 ports for 5 max clients)
-tls 1 # Enables optional TLS support
</code></pre>
]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>ftp</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>ufw防火墙使用常用命令</title>
    <url>/2019/03/15/2019-03-15/</url>
    <content><![CDATA[<h3 id="开启-关闭ufw">开启/关闭ufw</h3>
<pre><code>ufw enable
ufw disable
</code></pre>
<h3 id="允许某端口被访问">允许某端口被访问</h3>
<pre><code>ufw allow 80
</code></pre>
<h3 id="禁止某端口被访问">禁止某端口被访问</h3>
<pre><code>ufw deny 8888
</code></pre>
<h3 id="添加规则">添加规则</h3>
<p>允许10.168.2.137访问30004端口</p>
<pre><code>ufw allow from 10.168.2.137 to any port 30004
</code></pre>
<h3 id="插入规则">插入规则</h3>
<p>在第二条位置插入规则，允许192.168.1.1访问8888端口</p>
<pre><code>ufw insert 2 allow from 192.168.1.1 to any port 8888
</code></pre>
<h3 id="按编号显示规则">按编号显示规则</h3>
<blockquote>
<p>ufw status numbered</p>
</blockquote>
<h3 id="按编号删除规则">按编号删除规则</h3>
<blockquote>
<p>ufw delete 编号</p>
</blockquote>
]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>uft</tag>
      </tags>
  </entry>
  <entry>
    <title>Python异常处理伴侣 -- tenacity模块使用介绍</title>
    <url>/2018/12/19/2018-12-18/</url>
    <content><![CDATA[<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
<p>在写代码时经常会遇到对抛出异常的代码进行重试，常见于网页爬虫的代码中，使用计数器 + 循环的方式对抛出异常的代码进行捕获和重试。tenacity是使用Python装饰器模式对方法异常进行捕获，通过灵活的参数实现简单优雅的异常重试。</p>
<h1>特性：</h1>
<ol>
<li>简单灵活的装饰模式api</li>
<li>可以指定重试停止条件（比如：设置重试次数）</li>
<li>也可以指定等待条件（比如：使用指数避让间隔重试）</li>
<li>自定义触发重试的Exception</li>
<li>自定义重试预期的返回结果</li>
<li>基于协程的重试</li>
</ol>
<h1>安装方式:</h1>
<blockquote>
<p>pip install tenacity</p>
</blockquote>
<h1>API使用介绍</h1>
<h3 id="1-retry">1. @retry</h3>
<p>给需要重试的方法加上@retry修饰器之后，方法抛出异常就会被装饰器捕获到并进行重试，异常抛出时会不断重试直到方法成功返回</p>
<pre><code class="language-python">@retry
def never_give_up_never_surrender():
    print(&quot;Retry forever ignoring Exceptions, don't wait between retries&quot;)
    raise Exception
</code></pre>
<h3 id="2-带终止条件的retry">2. 带终止条件的retry</h3>
<p>我们也可以给retry加一个参数设置重试n次后不再重试并抛出异常</p>
<pre><code class="language-python">@retry(stop=stop_after_attempt(7))
def stop_after_7_attempts():
    print(&quot;Stopping after 7 attempts&quot;)
    raise Exception
</code></pre>
<p>使用@stop_after_delay 可以指定重试间隔，比如如下的例子指定10秒后重试</p>
<pre><code class="language-python">@retry(stop=stop_after_delay(10))
def stop_after_10_s():
    print(&quot;Stopping after 10 seconds&quot;)
    raise Exception
</code></pre>
<p>可以使用 “|” 把多个条件组合起来</p>
<pre><code class="language-python">@retry(stop=(stop_after_delay(10) | stop_after_attempt(5)))
def stop_after_10_s_or_5_retries():
    print(&quot;Stopping after 10 seconds or 5 retries&quot;)
    raise Exception
</code></pre>
<h3 id="3-在重试前等待">3. 在重试前等待</h3>
<p>使用@wait_fixed 在重试前等待固定时间</p>
<pre><code class="language-python">@retry(wait=wait_fixed(2))
def wait_2_s():
    print(&quot;Wait 2 second between retries&quot;)
    raise Exception
</code></pre>
<p>随机等待1-2秒钟，这在爬虫爬网页时比较有用</p>
<pre><code class="language-python">@retry(wait=wait_random(min=1, max=2))
def wait_random_1_to_2_s():
    print(&quot;Randomly wait 1 to 2 seconds between retries&quot;)
    raise Exception
</code></pre>
<p>增加指数避让等待间</p>
<pre><code class="language-python">@retry(wait=wait_exponential(multiplier=1, min=4, max=10))
def wait_exponential_1():
    print(&quot;Wait 2^x * 1 second between each retry starting with 4 seconds, then up to 10 seconds, then 10 seconds afterwards&quot;)
    raise Exception
    
@retry(wait=wait_fixed(3) + wait_random(0, 2))
def wait_fixed_jitter():
    print(&quot;Wait at least 3 seconds, and add up to 2 seconds of random delay&quot;)
    raise Exception
</code></pre>
<p>看一个更复杂点的例子</p>
<pre><code class="language-python">@retry(wait=wait_chain(*[wait_fixed(3) for i in range(3)] +
                       [wait_fixed(7) for i in range(2)] +
                       [wait_fixed(9)]))
def wait_fixed_chained():
    print(&quot;Wait 3s for 3 attempts, 7s for the next 2 attempts and 9s for all attempts thereafter&quot;)
    raise Exception
</code></pre>
<h3 id="4-带触发条件的retry语句">4. 带触发条件的retry语句</h3>
<pre><code class="language-python">@retry(retry=retry_if_exception_type(IOError))
def might_io_error():
    print(&quot;Retry forever with no wait if an IOError occurs, raise any other errors&quot;)
    raise Exception

def is_none_p(value):
    &quot;&quot;&quot;Return True if value is None&quot;&quot;&quot;
    return value is None

@retry(retry=retry_if_result(is_none_p))
def might_return_none():
    print(&quot;Retry with no wait if return value is None&quot;)
    
@retry(retry=(retry_if_result(is_none_p) | retry_if_exception_type()))
def might_return_none():
    print(&quot;Retry forever ignoring Exceptions with no wait if return value is None&quot;)
</code></pre>
<h3 id="5-异常处理">5. 异常处理</h3>
<p>虽然tenacity会帮我们处理异常，我们依然可以在重试失败后使用reraise来决定我们时候进行最后的尝试，使用reraise会把异常抛出交给我们的try except来处理</p>
<pre><code class="language-python">@retry(reraise=True, stop=stop_after_attempt(3))
def raise_my_exception():
    raise MyException(&quot;Fail&quot;)

try:
    raise_my_exception()
except MyException:
    # timed out retrying
    pass
</code></pre>
<h3 id="6-在retry前后增加log">6. 在retry前后增加log</h3>
<pre><code class="language-python">logger = logging.getLogger(__name__)

@retry(stop=stop_after_attempt(3), before=before_log(logger, logging.DEBUG))
def raise_my_exception():
    raise MyException(&quot;Fail&quot;)
    
@retry(stop=stop_after_attempt(3), after=after_log(logger, logging.DEBUG))
def raise_my_exception():
    raise MyException(&quot;Fail&quot;)
    
@retry(stop=stop_after_attempt(3),
       before_sleep=before_sleep_log(logger, logging.DEBUG))
def raise_my_exception():
    raise MyException(&quot;Fail&quot;)
</code></pre>
<h3 id="7-统计异常情况">7. 统计异常情况</h3>
<pre><code class="language-python">@retry(stop=stop_after_attempt(3))
def raise_my_exception():
    raise MyException(&quot;Fail&quot;)

try:
    raise_my_exception()
except Exception:
    pass

print(raise_my_exception.retry.statistics)
</code></pre>
<p>输出如下内容：</p>
<pre><code>{'start_time': 283085.571804807, 'attempt_number': 3, 'idle_for': 0, 'delay_since_first_attempt': 0.0002240639878436923}
</code></pre>
<h3 id="8-自定义异常回调函数">8. 自定义异常回调函数</h3>
<pre><code class="language-python">from tenacity import stop_after_attempt, retry_if_result, retry

def return_last_value(retry_state):
    &quot;&quot;&quot;return the result of the last call attempt&quot;&quot;&quot;
    return retry_state.result()

def is_false(value):
    &quot;&quot;&quot;Return True if value is False&quot;&quot;&quot;
    return value is False

# will return False after trying 3 times to get a different result
@retry(stop=stop_after_attempt(3),
       retry_error_callback=return_last_value,
       retry=retry_if_result(is_false))
def eventually_return_false():
    return False

print(eventually_return_false())
</code></pre>
<p>输出结果为 False</p>
<h1>项目Git地址</h1>
<p><a href="https://github.com/jd/tenacity" target="_blank" rel="noopener">https://github.com/jd/tenacity</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>retry</tag>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title>解决ssh登录ubuntu系统卡顿问题</title>
    <url>/2018/12/12/2018-12-12/</url>
    <content><![CDATA[<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
<p>最近某天突然登录服务器变的很慢，输入ssh命令后大概要多10多秒钟才连上服务器（设置了免密码登录），并且登录之后切换到root用户也要等很久，网上搜索发现也有其他人遇到类似问题，尝试了网上提到的设置ssh_config和sshd_config的某些参数没有明显变化，登录服务器依旧很慢，最终发现问题还是通过自己排查，这里记录下排查过程。</p>
<p>先执行ssh命令登录服务器，增加 -v 参数打印debug信息：</p>
<blockquote>
<p>ssh -v <a href="mailto:xuqi@10.168.2.178">xuqi@10.168.2.178</a></p>
</blockquote>
<p>发现在执行到“debug1: pledge: network” 这步时卡住很久，再google一次，找到了解决办法，执行如下命令后，登录时间明显缩短到约2秒钟</p>
<blockquote>
<p>systemctl restart systemd-logind</p>
</blockquote>
<p>大致的原因是dbus服务由于某些原因重启后，也必须重启systemd服务，否则就会出现这个bug。</p>
<h3 id="参考">参考</h3>
<p><a href="https://serverfault.com/questions/792486/ssh-connection-takes-forever-to-initiate-stuck-at-pledge-network" target="_blank" rel="noopener">https://serverfault.com/questions/792486/ssh-connection-takes-forever-to-initiate-stuck-at-pledge-network</a></p>
]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>股指期货概念介绍</title>
    <url>/2018/08/13/2018-08-14/</url>
    <content><![CDATA[<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
<h1>概念</h1>
<p>股指期货（Stock Index Futures）的全称是股价指数期货，也可称为股价指数期货、期指，是指以股价指数为标的物的标准化期货合约，双方约定在未来的某个特定日期，可以按照事先确定的股价指数的大小，进行标的指数的买卖。期货分为商品期货和金融期货，股指期货属于金融期货，作为期货交易的一种类型，股指期货交易与普通商品期货交易具有基本相同的特征和流程。</p>
<h1>主要作用</h1>
<ol>
<li>
<p>规避投资风险</p>
<p>当投资者不看好股市,可以通过股指期货的套期保值功能在期货上做空,锁定股票的账面盈利,从而不必将所持股票抛出,造成股市恐慌性下跌</p>
</li>
<li>
<p>套利</p>
<p>所谓套利，就是利用股指期货和现货指数基差在交割日必然收敛归零的原理,当期货升水超过一定幅度时通过做空股指期货并同时买入股指期货标的指数成分股，或者当期货贴水超过一定幅度时通过做多股指期货并同时进行融券卖空股票指数ETF，来获得无风险收益。</p>
</li>
<li>
<p>降低股市波动性</p>
<p>股指期货可以降低股市的日均振幅和月线平均振幅,抑制股市非理性波动,比如股指期货推出之前的五年里沪深300指数日均振幅为2.51%月线平均振幅为14.9%,推出之后的五年里日均振幅为1.95%月线平均振幅为10.7%,双双出现显著下降</p>
</li>
<li>
<p>丰富投资策略</p>
<p>股指期货等金融衍生品为投资者提供了风险对冲工具，可以丰富不同的投资策略，改变目前股市交易策略一致性的现状，为投资者提供多样化的财富管理工具，以实现长期稳定的收益目标。</p>
</li>
</ol>
<h1>风险</h1>
<p>除了金融衍生产品的一般性风险外，由于标的物自身的特点和合约设计过程中的特殊性，股指期货还具有一些特定的风险。</p>
<h3 id="基差风险">基差风险</h3>
<p>基差是某一特定地点某种商品的现货价格与同种商品的某一特定期货合约价格之间的价差。基差=现货价格-期货价格。</p>
<h3 id="合约品种差异造成的风险">合约品种差异造成的风险</h3>
<p>合约品种差异造成的风险，是指类似的合约品种，如日经225种股指期货和东京证券股指期货，在相同因素的影响下，价格变动不同。表现为两种情况：<br>
1〉是价格变动的方向相反。<br>
2〉是价格变动的幅度不同。类似合约品种的价格，在相同因素作用下变动幅度上的差异，也构成了合约品种差异的风险。</p>
<h3 id="标的物风险">标的物风险</h3>
<p>股指期货的标的物是市场上各种股票的价格总体水平，由于标的物设计的特殊性，是其特定风险无法完全锁定的原因。从套期保值的技术角度来看，商品期货、利率期货和外汇期货的套期保值者，都可以在一定期限内，通过建立现货与期货合约数量上的一致性、交易方向上的相反性来彻底锁定风险。而股指期货由于标的物的特殊性，使现货和期货合约数量上的一致仅具有理论上的意义，而不具有现实操作性。因为，股票指数设计中的综合性，以及设计中权重因素的考虑，使得在股票现货组合中，当股票品种和权数完全与指数一致时，才能真正做到完全锁定风险，而这在实际操作中的可行性几乎是零。因此，股指期货标的物的特殊性，使完全意义上的期货与现货间的套期保值成为不可能，因而风险将一直存在。</p>
<h3 id="交割制度风险">交割制度风险</h3>
<p>股指期货采用现金交割的方式完成清算。相对于其他结合实物交割进行清算的金融衍生产品而言，存在更大的交割制度风险。如在利率期货交易中，符合规格的债券现货，无论如何也可以满足一部分交割要求。股指期货则只能是百分之百的现金交割，而不可能以对应股票完成清算。</p>
<h1>规则制度</h1>
<h3 id="合约价值">合约价值</h3>
<p>沪深300和上证50一个点是300元，中证500是200元</p>
<h3 id="保证金">保证金</h3>
<p>投资者在进行期货交易时，必须按照其买卖期货合约价值的一定比例来缴纳资金，作为履行期货合约的财力保证，然后才能参与期货合约的买卖。这笔资金就是我们常说的保证金。</p>
<p>买卖一手股指期货合约占用的保证金比例一般为合约价值的10%-20%(具体由交易所规定)，自20170918起中金所将保证金比例调整为15%，假如沪深300指数为3900点，相当于3900*300*15%=17.5万元，但在开户时账户上必须有50万的资金，完成开户验资过后留够一手保证金加上一定的余额即可，所以大致需要20万以上的资金，而中证50期指大致需要50万资金，上证50期指大致需要15万的资金。</p>
<h3 id="手续费">手续费</h3>
<p>在正常情况下手续费为合约价值的万分之零点七，比如20150302沪深300指数点位为3600点，手续费为万分之零点七，即3600*300*0.00007=75元，</p>
<p>20170918起平今仓手续费调整为万分之六点九，假设沪深300指数为3900点，当天买入且当天卖出一手沪深300期指需要付出3900*300*0.00069=807元的手续费，平昨仓手续费依然是万分之零点七，即昨天买入今天卖出一手沪深300期指的手续费为3900*300*0.00007=82元，等同于变相抑制T+0。</p>
<h3 id="结算制度">结算制度</h3>
<p>每日无负债结算制度也称为“逐日盯市”制度，简单说来，就是期货交易所要根据每日市场的价格波动对投资者所持有的合约计算盈亏并划转保证金账户中相应的资金。</p>
<p>期货交易实行分级结算，交易所首先对其结算会员进行结算，结算会员再对非结算会员及其客户进行结算。交易所在每日交易结束后，按当日结算价格结算所有未平仓合约的盈亏、交易保证金及手续费、税金等费用，对应收应付的款项同时划转，相应增加或减少会员的结算准备金。</p>
<p>交易所将结算结果通知结算会员后，结算会员再根据交易所的结算结果对非结算会员及客户进行结算，并将结算结果及时通知非结算会员及客户。若经结算，会员的保证金不足，交易所应立即向会员发出追加保证金通知，会员应在规定时间内向交易所追加保证金。若客户的保证金不足，期货公司应立即向客户发出追加保证金通知，客户应在规定时间内追加保证金。投资者可在每日交易结束后上网查询账户的盈亏，确定是否需要追加保证金或转出盈利。</p>
<h3 id="交易规则">交易规则</h3>
<ul>
<li>
<p>交易时间: 周一至周五，上午：9:30-11:30，下午：13:00-15:00</p>
</li>
<li>
<p>涨跌幅: 上一个交易日收盘价的±10%</p>
</li>
<li>
<p>最大下单数</p>
<p>中金所暂时规定限价指令每次最大下单数量为20手，市价指令每次最大下单数量为10手,进行投机交易的客户单个合约的最大持仓限额为5000手,单个账户日内交易超过20手视为过度交易行为，套期保值交易开仓数量和持仓数量不受此限.</p>
</li>
<li>
<p>合约代码</p>
<ul>
<li>沪深300股指期货：IF</li>
<li>中证500股指期货：IC</li>
<li>上证50股指期货：IH</li>
</ul>
</li>
<li>
<p>合约类型</p>
<ul>
<li>当月现货合约</li>
<li>下月</li>
<li>下季</li>
<li>隔季</li>
</ul>
<p>随着每个月的交割以后，进行一次合约的滚动推进。比如在九月份，就具有九月、十月、十二月和次年三月四个合约进行交易，在十月底需要对十月合约进行交割。</p>
</li>
<li>
<p>T + 0</p>
<p>T+0即当日买进当日卖出,没有时间和次数限制,而T+1即当日买进,次日卖出,买进的当日不能当日卖出,当前期货交易一律实行T+0交易,大部分国家的股票交易也是T+0的,我国的股票市场由于历史原因而实行T+1交易制度。</p>
</li>
<li>
<p>卖空</p>
<p>股指期货合约可以十分方便地卖空，等价格回落后再买回。股票融券交易也可以卖空，但难度相对较大。当然一旦卖空后价格不跌反涨，投资者会面临损失。</p>
</li>
<li>
<p>合约交割</p>
<p>股票买入后可以一直持有，正常情况下股票数量不会减少。但股指期货都有固定的到期日，到期就要进行平仓或者交割。因此交易股指期货不能象买卖股票一样，交易后就不管了，必须注意合约到期日，以决定是平仓，还是等待合约到期进行现金结算交割。</p>
<p>沪深300指数期货会在每个月第三个星期五交割，并且以沪深300现货指数截止15:00之前两个小时的算术平均价作为交割结算价，所以不论平时期货和现货的基差有多大，沪深300指数期货最终必然会强制向沪深300现货指数收敛归零，导致期货会紧跟现货指数，具有很强的联动性，就好比小狗跟着主人散步时一样，小狗有时候会跑在主人前面，有时会在主人后面，但最终前进方向是由主人决定的，套利机制就是那根狗绳。</p>
</li>
<li>
<p>合约结算</p>
<p>股指期货合约采用保证金交易，一般只要付出合约面值约10-15%的资金就可以买卖一张合约，这一方面提高了盈利的空间，但另一方面也带来了风险，因此必须每日结算盈亏。买入股票后在卖出以前，账面盈亏都是不结算的。但股指期货不同，交易后每天要按照结算价对持有在手的合约进行结算，账面盈利可以提走，但账面亏损第二天开盘前必须补足（即追加保证金）。而且由于是保证金交易，亏损额甚至可能超过你的投资本金，这一点和股票交易不同。</p>
</li>
</ul>
<h3 id="基差">基差</h3>
<p>股指期货合约与对应股票指数之间的价差，基差=现货价格-期货价格，当期货价格高于现货被称为<strong>升水</strong>，当期货价格低于现货价格被称为<strong>贴水</strong>，比如20160302 IF1603股指期货的价格为3009点，沪深300指数为3051点，基差为3051-3009=42点，2015年度沪深300股指期货主力合约与现货指数的平均基差为±1.5%，这是不太正常的，原因在于国内融资与融券的比例失衡，国外的融资和融券比例一般为3:1，而国内达到300:1以上，融资融券比例失衡致使融券套利机制无法发挥正常作用，会导致基差出现偏差。</p>
<h3 id="持仓量">持仓量</h3>
<p>多头和空头尚未平仓的合约总数，比如20160302 IF1603合约的持仓量为3.87万手，2015年沪深300股指期货单边日均持仓量13万手，占用的(双边)保证金规模约500亿元，假设其中一半的空单是套期保值盘则对应的股票市值约700亿元，而沪深300指数300只成分股的股票总市值达20万亿以上，也就是说依靠股指期货对冲风险的股票占比还不到1%，说明国内股指期货的规模依然不够大，需降低门槛让更多的中小投资者能够参与进来.2012年，2013年，2014年，2015年，2016年每月月末平均持仓量分别为78300手，102000手，164000手，131000手，44000手，2012年成交持仓比为5.5，2013年为7.9，2014年为5.4，2015年为8.6，2016年为0.39。</p>
<h3 id="参与主体">参与主体</h3>
<p>套期保值者、投机者、套利者</p>
<h3 id="主要策略">主要策略</h3>
<h4 id="1-套期保值">1. 套期保值</h4>
<p>股指期货套期保值和其他期货套期保值一样，其基本原理是利用股指期货与股票现货之间的类似走势，通过在期货市场进行相应的操作来管理现货市场的头寸风险。</p>
<p>由于股指期货的套利操作，股指期货的价格和股票现货（股票指数）之间的走势是基本一致的，如果两者步调不一致到足够程度，就会引发套利盘入这种情况下，那么如果保值者持有一篮子股票现货，他认为当前股票市场可能会出现下跌，但如果直接卖出股票，他的成本会很高，于是他可以在股指期货市场建立空头，在股票市场出现下跌的时候，股指期货可以获利，以此可以弥补股票出现的损失。这就是所谓的<strong>空头保值</strong>。</p>
<p>另一个基本的套期保值策略是所谓的<strong>多头保值</strong>。一个投资者预期要几个月后有一笔资金投资股票市场，但他觉得如今的股票市场很有吸引力，要等上几个月的话，可能会错失建仓良机，于是他可以在股指期货上先建立多头头寸，等到未来资金到位后，股票市场确实上涨了，建仓成本提高了，但股指期货平仓获得的的盈利可以弥补现货成本的提高，于是该投资者通过股指期货锁定了现货市场的成本。</p>
<h4 id="2-投机交易">2. 投机交易</h4>
<p>股市指数期货提供了很高风险的机会。其中一个简单的投机策略是利用股市指数期货预测市场走势以获取利润。若预期市场价格回升，投资者便购入期货合约并预期期货合约价格将上升，相对于投资股票，其低交易成本及高杠杆比率使股票指数期货更加吸引投资者。他们亦可考虑购入那个交易月份的合约或投资于恒生指数或分类指数期货合约。</p>
<h4 id="3-套利">3. 套利</h4>
<p>针对股指期货与股指现货之间、股指期货不同合约之间的不合理关系进行套利的交易行为。股指期货合约是以股票价格指数作为标的物的金融期货和约，期货指数与现货指数（沪深300）维持一定的动态联系。但是，有时期货指数与现货指数会产生偏离，当这种偏离超出一定的范围时（无套利定价区间的上限和下限），就会产生套利机会。利用期指与现指之间的不合理关系进行套利的交易行为叫<strong>无风险套利（Arbitrage）</strong> ，利用期货合约价格之间不合理关系进行套利交易的称为<strong>价差交易（Spread Trading）</strong>。</p>
]]></content>
      <categories>
        <category>金融</category>
      </categories>
      <tags>
        <tag>期货</tag>
      </tags>
  </entry>
  <entry>
    <title>Okex合约交易基本概念介绍</title>
    <url>/2018/05/25/Okex%E5%90%88%E7%BA%A6%E4%BA%A4%E6%98%93%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
<h3 id="概念">概念</h3>
<p>虚拟合约是合约交易的买卖对象，是由合约交易所统一制定的，规定了某一特定的时间交割一定数量商品的标准化合约。</p>
<p>OKEX的合约是OKEX推出的以BTC/LTC等币种进行结算的虚拟合约产品，每一张合约分别代表100美元的BTC，或10美元的其他币种（LTC,ETH等）,投资者可以通过买入做多合约来获取虚拟数字货币价格上涨的收益，或通过卖出做空来获取虚拟数字货币收益。合约的杠杆倍数为10或20倍。</p>
<p>OKEX在设计虚拟合约时做了相应的调整，每一张合约代表价值100美元的比特币，这样的设计使得虚拟合约的杠杆倍数始终稳定在一个固定值，从而利于套保和套利。</p>
<p>OKEX比特币虚拟合约的杠杆表现为法币收益层面的杠杆稳定：投入100美元，所能得到的收益=100美元 * 比特币的涨跌幅 * 固定的杠杆倍数。</p>
<h3 id="合约类型">合约类型</h3>
<p>目前OKEX根据合约时间长短提供三种合约交易，分别是当周、次周、季度。</p>
<ul>
<li>当周合约：指在距离交易日最近的北京时间周五下午4点进行交割的合约。</li>
<li>次周合约：指在距离交易日最近的北京时间第二个周五下午4点进行交割的合约。</li>
<li>季度合约：指交割日为3,6,9,12月中距离当前最近的一个月份的北京时间最后一个周五下午4点进行交割的合约。</li>
</ul>
<p>新合约将于交割日当日下午16:10开始交易</p>
<h3 id="合约品种">合约品种</h3>
<p>BTC面值为100美元，报价时的最小变动单位为0.01美元,其他币种合约的面值为10美元，报价时的最小变动单位为0.001美元</p>
<p>BTC、LTC、ETH、ETC、BCH、XRP、EOS、BTG</p>
<h3 id="交易规则">交易规则</h3>
<p>买入开多，卖出开空，买入平空，卖出平多</p>
<p>开仓:</p>
<pre><code>未实现盈亏的计算公式：多仓未实现盈亏=（合约面值 / 结算基准价 - 合约面值 / 当前价格）* 持仓数量； 空仓未实现盈亏=（合约面值 / 当前价格 - 合约面值 / 结算基准价）* 持仓数量 
</code></pre>
<p>平仓:</p>
<pre><code>已实现盈亏的计算公式：多仓已实现盈亏=（合约面值 / 结算基准价 -合约面值 /平仓价格） * 平仓数量； 空仓已实现盈亏=（合约面值 / 平仓价格-合约面值 /结算基准价）* 平仓数量 
</code></pre>
<h3 id="风控规则">风控规则</h3>
<ul>
<li>全仓保证金制度、逐仓保证金制度、限价爆仓制度</li>
<li>全仓保证金制度与逐仓保证金制度，投资者二者只能选其一</li>
<li>全仓保证金: 当用户选择全仓保证金时，用户转入虚拟合约账户的所有余额，所有合约产生的盈亏都将作为合约的持仓保证金</li>
</ul>
<blockquote>
<p>全仓保证金模式下，开仓的要求是10倍杠杆开仓后，保证金率不低于90%，20倍杠杆开仓后，保证金率不低于80%</p>
</blockquote>
<p>所有虚拟合约账户中的BTC和LTC都将作为虚拟合约持仓的保证金，保证金数量将会随价格变化而变动。当虚拟合约价格朝着不利于投资者方向运动时，账户权益即会发生损失。当用户的保证金率变为0%时，账户即被爆仓，此时被爆仓的用户的损失接近或等于其虚拟合约账户中的所有资产。用户通过转入保证金和开仓合约的数量调整时机杠杆倍数。转入的保证金越多，开仓的合约数量越少，虚拟合约的实际杠杆倍数即越小，越不容易被爆仓。</p>
<p>用户的保证金率=用户所有保证金/用户持仓所需的保证金-调整系数。在10倍杠杆时，合约的调整系数=10%，20倍杠杆时，合约的调整系数=20%；当保证金率小于等于0时，账户将被爆仓，所有仓位将被限价强平，未能强平的委托将在交割时进行爆仓分摊</p>
<ul>
<li>
<p>逐仓保证金制度：</p>
<p>用户在合约开仓时所需要的保证金作为虚拟合约持仓的固定保证金，当虚拟合约价格发生变化时，保证金数值不发生变化。当虚拟合约价格朝向不利于用户方向运动时，未实现盈亏将发生损失。当用户的该合约该仓位的保证金率((固定保证金+未实现盈亏) * 开仓均价 * 杠杆 / (合约面值 * 持仓数量) - 调整系数；10倍杠杆，合约的调整系数=10%；20倍杠杆，合约的调整系数=20%，保证金率小于等于0%时，该合约的该仓位将被爆仓，此时被爆仓的用户损失接近或等于其该合约该方向仓位下的固定保证金。</p>
</li>
</ul>
<blockquote>
<p>采用逐仓保证金模式时，每个合约的双向持仓将会独立计算其保证金和收益，只有开仓可用保证金大于等于开仓所需的保证金数量，用户才能进行委托。而逐仓保证金时，每个合约的开仓可用保证金可能不一致。</p>
</blockquote>
<h3 id="委托方式">委托方式</h3>
<h5 id="1-计划委托">1. 计划委托</h5>
<p>计划委托指令指的是预先设置委托和触发条件，当最新的成交价格达到事先设定的触发价格时，即会将事先设置的委托送入市场。</p>
<h5 id="2-跟踪委托">2. 跟踪委托</h5>
<p>跟踪委托指的是在行情发生较大幅度回调的情况下，将客户事先设定的委托送入市场的策略。当市场的最新价格达到投资者设定该策略后最高（最低）市场价格的（1±客户设定回调幅度）后，即会触发客户设定的策略，将客户事先设定的委托送入市场中。</p>
<h5 id="3-冰山委托">3. 冰山委托</h5>
<p>冰山委托指的是投资者在进行大额交易时，为避免对市场造成过大冲击，将大单委托自动拆为多笔委托，根据当前的最新买一/卖一价格和客户设定的价格策略自动进行小单委托，在上一笔委托被全部成交或最新价格明显偏离当前委托价时，自动重新进行委托。</p>
<h5 id="4-时间加权委托">4. 时间加权委托</h5>
<p>时间加权委托指的是客户希望大额交易BTC时，为避免过大冲击成本，通过策略将大单拆细为多个小额委托，根据最新的对手方委托量自动选择委托量，主动与对手方成交进行连续买入的策略。</p>
<h3 id="保证金制度">保证金制度</h3>
<ul>
<li>10倍</li>
<li>20倍</li>
</ul>
<h3 id="手续费">手续费</h3>
<p>开仓和平仓都征收手续费；若 maker 的手续费为负数，意味着您主动挂单为合约提供流动性，平台将赠送您手续费。合约交割手续费不受用户等级影响(BTC收取0.015%，非BTC收取0.05%)；爆仓导致的平仓不收手续费。</p>
<p>等级 近30天交易量(BTC) 挂单成交手续费 吃单成交手续费</p>
<p>Lv1 &lt;10000 0.03% 0.05%</p>
<p>Lv2 ≥10000 0.025% 0.045%</p>
<p>Lv3 ≥20000 0.02% 0.04%</p>
<p>Lv4 ≥30000 0.015% 0.035%</p>
<p>Lv5 ≥60000 0.01% 0.03%</p>
<p>Lv6 ≥100000 0.005% 0.025%</p>
<p>Lv7 ≥200000 0% 0.02%</p>
<p>Lv8 ≥300000 -0.01% 0.02%</p>
<h3 id="借币利息">借币利息</h3>
<ul>
<li>
<p>计息规则：单笔借币订单独立计息。借币成功时首次计息，之后满24小时计息一次。每满15天，系统将未还清借币进行复息结算（未还利息计入下一阶段本金中），并开始下一阶段计息。</p>
</li>
<li>
<p>还币规则：优先还最早生成的借币订单。优先还利息，再还本金。单笔借币订单的本金和应还利息全部还清后，单笔借币订单状态转换为已还清，随后此订单不再计息。</p>
</li>
</ul>
<p>借币日息usdt eth btc 0.1%，其他0.02%，不满一天按一天算</p>
<h3 id="爆仓">爆仓</h3>
<p>用户资产：本金+已借-已产生的利息</p>
<p>负债：所有“已借”资产</p>
<p>风险率=用户资产/负债</p>
<p>当风险率跌到130%将有短信提示接近爆仓水平；当风险率跌到110%单仓将被强平。</p>
<p>风险率：评估币币杠杆账户爆仓风险的指标。当风险率≥150%时，账户中多余的资产部分可通过资金划转转出；当风险率≤130%，风险率评估为风险，系统会给用户发短信提示风险；当风险率≤110%，系统将强制爆仓，并发短信告知用户。</p>
<p>风险率计算公式：风险率=[(计价货币总资产-计价货币未还利息)/最新成交价+(交易货币总资产-交易货币未还利息)]/(计价货币借入资产/最新成交价+交易货币借入资产)*100%</p>
<p>爆仓：当某币币杠杆账户的风险率≤110%时，系统会执行爆仓操作，使用该账户内所有资产去偿还借币债务。</p>
<p>爆仓风险率=110%</p>
<p>预计爆仓价格：在OKEx.com每一笔借币均须交纳一定比例的保证金，当市场发生不利变化，比如市场发生行情逆转，朝相反方向变化时，当前币币杠杆账户总资产缩水到一定限度时，系统会强制将该币币杠杆账户资产按市场最优价格以挂单形式卖出清算借币以及利息。</p>
<p>预计爆仓价格计算公式：预计爆仓价格=(计价货币借入资产*爆仓风险率+计价货币未还利息-计价货币总资产)/(交易货币总资产-交易货币未还利息-交易货币借入资产*爆仓风险率)</p>
<h3 id="其他">其他</h3>
<p>合约限价机制</p>
<ul>
<li>新合约生成10分钟内：最高价=现货指数（1+5%），最低价=现货指数（1-5%）。</li>
<li>合约生成了10分钟后：最高价=近10分钟溢价平均值+现货指数（1+3%）,最低价=近10分钟溢价均值+现货指数（1-3%），溢价=合约价格-现货价格。<br>
若计算后的价格超过最高偏离度的现货指数25%或价格小于0，则最高价=现货指数（1+25%），最低价=现货指数（1-25%）。</li>
<li>以上规则，开平仓都受限制，若开多或平空，当委托价高于最高价，则将触发限价；若开空或平多，当委托价低于最新价，则将触发限价。</li>
</ul>
<h4 id="术语">术语</h4>
<p>清算已实现盈亏：</p>
<p>每周五下午4:00会进行清结算，需要每个合约的本周已实现盈亏结转到用户余额中，此部分金额可以用于开仓和提现。</p>
<p>清算未实现盈亏：</p>
<p>每周五下午4:00会进行清结算，若用户持有次周，季度合约的仓位，则需将仓位中未实盈亏结转到已实现盈亏中。</p>
<p>爆仓平多/平空：</p>
<p>逐仓：当用户将仓位中的”已用保证金“亏完时，则该仓位会被爆仓，系统将该持仓进行强制平仓.</p>
<p>全仓：当用户将账户权益（存入金额+已实现盈亏+未实现盈亏）亏损完后，系统将用户的所有持仓进行强制平仓。</p>
<p>交割平多/交割平空：</p>
<p>当合约到期时（如每周五下午4:00当周合约到期），系统以最近一小时现货指数的算术平均值作为交割价对所有开仓的合约进行交割平仓，交割平仓后产生的盈亏部分加入已实现盈亏。</p>
<p>爆仓平仓剩余：</p>
<p>当用户爆仓时，系统会按爆仓价格进行强制平仓，但在撮合成交时可能与爆仓价格有所偏差，价格偏差所导致的盈余则称之为爆仓平仓剩余。</p>
<p>穿仓分摊：</p>
<p>当市场行情波动较大，用户爆仓后，按照爆仓价格无法成交时，导致亏损范围大于保证金。因此OKEX平台采用“分摊”制度，从本周盈利的用户中，每个人等比例分摊穿仓部分的损失。</p>
<h4 id="合约爆仓问题">合约爆仓问题</h4>
<p><a href="https://support.okex.com/hc/zh-cn/articles/360000139652-%E5%90%88%E7%BA%A6%E7%88%86%E4%BB%93%E9%97%AE%E9%A2%98" target="_blank" rel="noopener">https://support.okex.com/hc/zh-cn/articles/360000139652-合约爆仓问题</a></p>
<h4 id="合约结算交割问题">合约结算交割问题</h4>
<p>交割规则有关于穿仓的介绍</p>
<p><a href="https://support.okex.com/hc/zh-cn/articles/360000105511-%E5%90%88%E7%BA%A6%E7%BB%93%E7%AE%97%E4%BA%A4%E5%89%B2%E9%97%AE%E9%A2%98" target="_blank" rel="noopener">https://support.okex.com/hc/zh-cn/articles/360000105511-合约结算交割问题</a></p>
]]></content>
      <categories>
        <category>金融</category>
      </categories>
      <tags>
        <tag>期货</tag>
        <tag>合约</tag>
        <tag>okex</tag>
      </tags>
  </entry>
  <entry>
    <title>《如何验证因子有效性》 听课笔记</title>
    <url>/2018/05/19/%E3%80%8A%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E5%9B%A0%E5%AD%90%E6%9C%89%E6%95%88%E6%80%A7%E3%80%8B%20%E5%90%AC%E8%AF%BE%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1>一维零投资组合</h1>
<p><img src="images/15267001868391.jpg" alt=""></p>
<p><img src="images/15267003855597.jpg" alt=""></p>
<p>先对股票按因子大小排序， nt是top，nb是bottom，nb中停牌的股票跳过停牌的股票，已纳入的股票如果停牌的也不能调出且需要保留仓位</p>
<p><img src="images/15267006658022.jpg" alt=""></p>
<p>公式一：每只股票期末收益累加除以股票数<br>
公式二：计算零投资组合当期收益<br>
公式三：计算累计收益，把第一期净值作为1，连成每期收益率，最后减去1</p>
<p><img src="images/15267011538977.jpg" alt=""><br>
<img src="images/15267014437363.jpg" alt=""><br>
<img src="images/15267154692447.jpg" alt=""><br>
<img src="images/15267155512097.jpg" alt=""><br>
<img src="images/15267163339922.jpg" alt=""><br>
<img src="images/15267164374438.jpg" alt=""></p>
<h1>关键点</h1>
<ul>
<li>PE -&gt; EP，使取值空间连续</li>
<li>停牌</li>
<li>复权（后复权）</li>
</ul>
<h1>自定义股票池</h1>
<p><img src="images/15267167359285.jpg" alt=""></p>
<h1>调仓周期</h1>
]]></content>
      <categories>
        <category>策略研究</category>
      </categories>
      <tags>
        <tag>多因子</tag>
      </tags>
  </entry>
  <entry>
    <title>systemd入门教程</title>
    <url>/2018/03/29/systemd%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p>最近在处理数字货币行情数据，使用websocket接收行情数据写入磁盘，发现运行时间久了偶尔出现socket close的异常，重试多次无效后程序异常退出，所以考虑将python程序作为linux 守护进程运行，了解了supervisord和systemd，决定使用更强大的systemd。</p>
<h1>基本概念</h1>
<p>systemd 是一个 Linux 系统基础组件的集合，提供了一个系统和服务管理器，运行为 PID 1 并负责启动其它程序。功能包括：支持并行化任务；同时采用 socket 式与 D-Bus 总线式激活服务；按需启动守护进程（daemon）；利用 Linux 的 cgroups 监视进程；支持快照和系统恢复；维护挂载点和自动挂载点；各服务间基于依赖关系进行精密控制。systemd 支持 SysV 和 LSB 初始脚本，可以替代 sysvinit。除此之外，功能还包括日志进程、控制基础系统配置，维护登陆用户列表以及系统账户、运行时目录和设置，可以运行容器和虚拟机，可以简单的管理网络配置、网络时间同步、日志转发和名称解析等。</p>
<p>systemd架构图</p>
<p><img src="images/15222891502855.jpg" alt=""></p>
<h2 id="常用工具">常用工具</h2>
<ul>
<li>systemd-analyze: 查看启动耗时</li>
<li>systemctl: 用来查看系统状态、启动停止服务，在systemctl参数中添加-H &lt;用户名&gt;@&lt;主机名&gt;可以实现对其他机器的远程控制。该过程使用ssh链接</li>
<li>journalctl: Systemd统一管理所有Unit的启动日志</li>
</ul>
<h2 id="unit">unit</h2>
<p>一个单元配置文件可以描述如下内容之一：系统服务(.service)、挂载点(.mount)、sockets(.sockets) 、系统设备(.device)、交换分区(.swap)、文件路径(.path)、启动目标(.target)、由 systemd 管理的计时器(.timer)</p>
<h2 id="如何编写服务脚本">如何编写服务脚本</h2>
<pre><code>
[Unit]

Description=Network Manager

Wants=network.target

Before=network.target network.service

                                                                                                                                                                               

[Service]

Type=dbus

BusName=org.freedesktop.NetworkManager

ExecStart=/usr/sbin/NetworkManager --no-daemon

# NM doesn't want systemd to kill its children for it

KillMode=process

 

[Install]

WantedBy=multi-user.target

Alias=dbus-org.freedesktop.NetworkManager.service

Also=NetworkManager-dispatcher.service
</code></pre>
<h3 id="整个文件分三个部分，-Unit-·-Service-·-Install">整个文件分三个部分，[Unit]·[Service]·[Install]</h3>
<ul>
<li>
<p>[Unit]：记录unit文件的通用信息。</p>
</li>
<li>
<p>[Service]：记录Service的信息</p>
</li>
<li>
<p>[Install]：安装信息。</p>
</li>
</ul>
<h4 id="Unit主要包含以下内容：">Unit主要包含以下内容：</h4>
<p>●  Description：对本service的描述。</p>
<p>●  Before, After：定义启动顺序，Before=xxx.service，代表本服务在xxx.service启动之前启动。After=xxx.service,代表本服务在xxx之后启动。</p>
<p>●  Requires: 这个单元启动了，那么它“需要”的单元也会被启动; 它“需要”的单元被停止了，它自己也活不了。但是请注意，这个设定并不能控制某单元与它“需要”的单元的启动顺序（启动顺序是另外控制的），即 Systemd 不是先启动 Requires 再启动本单元，而是在本单元被激活时，并行启动两者。于是会产生争分夺秒的问题，如果 Requires 先启动成功，那么皆大欢喜; 如果 Requires 启动得慢，那本单元就会失败（Systemd 没有自动重试）。所以为了系统的健壮性，不建议使用这个标记，而建议使用 Wants 标记。可以使用多个 Requires。</p>
<p>●  RequiresOverridable：跟 Requires 很像。但是如果这条服务是由用户手动启动的，那么 RequiresOverridable 后面的服务即使启动不成功也不报错。跟 Requires 比增加了一定容错性，但是你要确定你的服务是有等待功能的。另外，如果不由用户手动启动而是随系统开机启动，那么依然会有 Requires 面临的问题。</p>
<p>●  Requisite：强势版本的 Requires。要是这里需要的服务启动不成功，那本单元文件不管能不能检测等不能等待都立刻就会失败。</p>
<p>●  Wants：推荐使用。本单元启动了，它“想要”的单元也会被启动。但是启动不成功，对本单元没有影响。</p>
<p>●  Conflicts：一个单元的启动会停止与它“冲突”的单元，反之亦然。</p>
<h4 id="Service主要包含以下内容：">Service主要包含以下内容：</h4>
<p>●  Type：service的种类，包含下列几种类型：</p>
<pre><code>----simple 默认，这是最简单的服务类型。意思就是说启动的程序就是主体程序，这个程序要是退出那么一切都退出。

-----forking 标准 Unix Daemon 使用的启动方式。启动程序后会调用 fork() 函数，把必要的通信频道都设置好之后父进程退出，留下守护精灵的子进程

-----oneshot种服务类型就是启动，完成，没进程了。
</code></pre>
<p>notify,idle类型比较少见，不介绍。</p>
<p>●  ExecStart：服务启动时执行的命令，通常此命令就是服务的主体。</p>
<pre><code>------如果你服务的类型不是 oneshot，那么它只可以接受一个命令，参数不限。

------多个命令用分号隔开，多行用 \ 跨行。
</code></pre>
<p>●  ExecStartPre, ExecStartPost：ExecStart执行前后所调用的命令。</p>
<p>●  ExecStop：定义停止服务时所执行的命令，定义服务退出前所做的处理。如果没有指定，使用systemctl stop xxx命令时，服务将立即被终结而不做处理。</p>
<p>●  Restart：定义服务何种情况下重启（启动失败，启动超时，进程被终结）。可选选项：no, on-success, on-failure,on-watchdog, on-abort</p>
<p>●  SuccessExitStatus：参考ExecStart中返回值，定义何种情况算是启动成功。</p>
<pre><code>eg：SuccessExitStatus=1 2 8 SIGKILL
</code></pre>
<h4 id="Install主要包含以下内容：">Install主要包含以下内容：</h4>
<p>●  WantedBy：何种情况下，服务被启用。</p>
<pre><code>eg：WantedBy=multi-user.target（多用户环境下启用）
</code></pre>
<p>●  Alias：别名</p>
<h1>例子</h1>
<p>新建文件 /etc/systemd/system/huobi.service</p>
<p>内容如下:</p>
<pre><code>[Unit]
Description=huobi downloader
After=rc-local.service

[Service]
Type=simple
User=root
Group=root
WorkingDirectory=/usr/lib/code/atom
ExecStart=/home/ubuntu/anaconda3/bin/python3.6 exchange/downloader.py huobi /data2/huobi/huobi.log
Restart=always

[Install]
WantedBy=multi-user.target
</code></pre>
<p>观察系统日志，发现程序异常退出后systemd重启的了服务</p>
<pre><code>root@ip-172-31-4-62:/usr/lib/code/atom#  journalctl -u huobi.service
-- Logs begin at Mon 2018-03-26 17:51:39 CST, end at Thu 2018-03-29 16:39:27 CST. --
Mar 29 10:58:46 ip-172-31-4-62 systemd[1]: Started huobi downloader.
Mar 29 11:02:18 ip-172-31-4-62 systemd[1]: huobi.service: Main process exited, code=killed, status=9/KILL
Mar 29 11:02:18 ip-172-31-4-62 systemd[1]: huobi.service: Unit entered failed state.
Mar 29 11:02:18 ip-172-31-4-62 systemd[1]: huobi.service: Failed with result 'signal'.
Mar 29 11:02:18 ip-172-31-4-62 systemd[1]: huobi.service: Service hold-off time over, scheduling restart.
Mar 29 11:02:18 ip-172-31-4-62 systemd[1]: Stopped huobi downloader.
Mar 29 11:02:18 ip-172-31-4-62 systemd[1]: Started huobi downloader.
Mar 29 11:29:58 ip-172-31-4-62 python3.6[9124]: Traceback (most recent call last):
Mar 29 11:29:58 ip-172-31-4-62 python3.6[9124]:   File &quot;./exchange/ex_huobi.py&quot;, line 66, in dispatch
Mar 29 11:29:58 ip-172-31-4-62 python3.6[9124]:     raw_data = await ws.recv()
Mar 29 11:29:58 ip-172-31-4-62 python3.6[9124]:   File &quot;/home/ubuntu/anaconda3/lib/python3.6/site-packages/websockets/protocol.py&quot;, line 323, i
Mar 29 11:29:58 ip-172-31-4-62 python3.6[9124]:     raise ConnectionClosed(self.close_code, self.close_reason)
Mar 29 11:29:58 ip-172-31-4-62 python3.6[9124]: websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1006 (connection
Mar 29 11:29:58 ip-172-31-4-62 systemd[1]: huobi.service: Service hold-off time over, scheduling restart.
Mar 29 11:29:58 ip-172-31-4-62 systemd[1]: Stopped huobi downloader.
Mar 29 11:29:58 ip-172-31-4-62 systemd[1]: Started huobi downloader.
Mar 29 13:30:44 ip-172-31-4-62 python3.6[19180]: Traceback (most recent call last):
Mar 29 13:30:44 ip-172-31-4-62 python3.6[19180]:   File &quot;./exchange/ex_huobi.py&quot;, line 66, in dispatch
Mar 29 13:30:44 ip-172-31-4-62 python3.6[19180]:     raw_data = await ws.recv()
Mar 29 13:30:44 ip-172-31-4-62 python3.6[19180]:   File &quot;/home/ubuntu/anaconda3/lib/python3.6/site-packages/websockets/protocol.py&quot;, line 323,
Mar 29 13:30:44 ip-172-31-4-62 python3.6[19180]:     raise ConnectionClosed(self.close_code, self.close_reason)
Mar 29 13:30:44 ip-172-31-4-62 python3.6[19180]: websockets.exceptions.ConnectionClosed: WebSocket connection is closed: code = 1006 (connectio
Mar 29 13:30:45 ip-172-31-4-62 systemd[1]: huobi.service: Service hold-off time over, scheduling restart.
Mar 29 13:30:45 ip-172-31-4-62 systemd[1]: Stopped huobi downloader.
Mar 29 13:30:45 ip-172-31-4-62 systemd[1]: Started huobi downloader.
</code></pre>
<h1>参考</h1>
<p><a href="https://wiki.archlinux.org/index.php/systemd_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)" target="_blank" rel="noopener">https://wiki.archlinux.org/index.php/systemd_(简体中文)</a></p>
<p><a href="https://www.hi-linux.com/posts/3761.html" target="_blank" rel="noopener">https://www.hi-linux.com/posts/3761.html</a></p>
<p><a href="https://blog.csdn.net/fu_wayne/article/details/38018825" target="_blank" rel="noopener">https://blog.csdn.net/fu_wayne/article/details/38018825</a></p>
]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>systemd</tag>
      </tags>
  </entry>
  <entry>
    <title>逐笔，分笔，逐单，分时数据概念区别</title>
    <url>/2018/03/29/%E9%80%90%E7%AC%94%EF%BC%8C%E5%88%86%E7%AC%94%EF%BC%8C%E9%80%90%E5%8D%95%EF%BC%8C%E5%88%86%E6%97%B6%E6%95%B0%E6%8D%AE%E6%A6%82%E5%BF%B5%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
<h1>逐笔成交：</h1>
<p>交易过程中的单次成交，是交易过程的真实成交情况。这是Level-2的专有数据，用一个实例来解释这个概念：假设目前的卖一是10元、100手，这时有人以10元委托买入100手，那么这100手是如何成交的呢？这要取决于卖盘由几个委托单构成，如果卖一是一个委托单，那就是一笔成交，即100手；而如果卖一是由40手和60手两笔委托构成，那么这100股就会分成两次成交，即40手一次，60手一次，逐笔成交就是2笔。</p>
<p>一般显示的数据格式为在几分几秒以多少价格分几笔成交了多少手。<strong>在这里我们要注意的是成交手数有时候是带小数点的，这是因为股票买进的股数最少是100股，委托的股数也应是100的整数倍，卖出却没有限制，因此成交的手数会有小数点。</strong> 另外一点就是如果在成交价格和手数前面没有显示，则一半是默认的1笔。</p>
<h1>分笔/分时成交：</h1>
<p>3-5秒一次的行情采集期间累计的成交量和最后的成交价，可能是几笔成交的集合。这是大家长期以来唯一能看到的成交数据.</p>
<p>一般显示的数据格式为在几分几秒以多少价格成交了多少手。**这里需要注意的是成交手数永远是整数，不会出现小数点数字。**其中现手累计数就是总手数。总手数也叫做成交量。有些软件在现量后面标注蓝色S和红色B，前者代表卖，后者代表买。（软件自己根据时间估计主动买还是主动卖）</p>
<p>目前市面上出现了LEVEL-2行情数据，比较具有代表性的是大智慧，在那里把分笔成交是叫分时成交，实际上就是我们在普通分析软件上F1看到的“分笔成交明细”，但是他和LEVEL-2行情数据提供的逐笔成交明细是不一样的。**分笔数据由于是合成混合数据，它是以最后1笔的买卖方向来表示该时间内（3秒或者5秒）的买卖方向。**目前市面上的成交明细数据都是分笔成交，有些号称是LEVEL-2逐笔的明细数据其实也是分笔，即LEVEL-2行情软件里右侧小窗口显示的3秒分笔数据，虽然来自LEVEL-2行情，但仍然是分笔（分时）成交，而不是LEVEL-2行情软件里左侧显示的逐笔成交。因为左侧显示的逐笔成交在LEVEL-2行情软件里是不能保存的，也不能够导出供二次开发。能够导出的只有右侧小窗口里的分笔成交</p>
<h1>逐单/委托单：</h1>
<p>我们每次向系统发出委托时，都有个委托合同编号，这个就是单。例如你一次买2000股股票，则是20手，那么这一单就是20手。但目前每种软件的推测统计都不一致，会导致不同软件显示数据出现差异。</p>
<p>委托单的明细，这是交易所行情系统中没有发布的数据，还以刚才的例子说明，交易所只发出了40手和60手两笔成交（逐笔），并没有指出是一笔100手的买单吃掉了40手、60手两笔卖单。LEVEL-2行情能够根据成交的时间和队列等数据计算出全部已成交的委托单明细，这在交易分析中具有重大意义。（股票盘子越大，推测逐单数据误差越大,因为委托队列只显示前50个委托单;相对来说小盘股的DDE指标更为可靠）</p>
<h1>分时:</h1>
<p>一般指一分钟成交集合;</p>
<h1>问题：</h1>
<p>盘中数据的统计分析长期以来是对分时数据的统计分析，比如最简单的内盘和外盘，大单买入/卖出等，这种统计有两个明显的缺陷：</p>
<p>第一、仅统计了主动成交方单方面的成交数据，而机构交易完全可能在被动成交方</p>
<p>第二、分时数据不是真实的成交数据，大单不一定是大单，可能是很多散户在几秒中之内同时交易的结果，虽然使用level-2的逐笔成交来统计可以避免这一情况的发生，但立即就又产生了新的问题，即一笔真实的大单委托往往被分割成数笔成交，又捕捉不到真实的大单了。</p>
<p>其他：一个孤独的数字是缺乏意义的，但是一些连续的数字则是充满想像的。一般来说，成交手数比较大而集中的时候，表示有大资金活跃迹象，该股出现价格异动的概率就大，应该引起投资者的注意。而如果半天也没人买或者都是一些小单子在交易，则至少短期不大可能成为好股。</p>
]]></content>
      <categories>
        <category>金融</category>
      </categories>
      <tags>
        <tag>tick</tag>
      </tags>
  </entry>
  <entry>
    <title>比特币挖矿</title>
    <url>/2018/02/18/%E6%AF%94%E7%89%B9%E5%B8%81%E6%8C%96%E7%9F%BF/</url>
    <content><![CDATA[<h1>比特币介绍</h1>
<p>比特币（BitCoin）的概念最初由中本聪在2009年提出，根据中本聪的思路设计发布的开源软件以及建构其上的P2P网络。比特币是一种P2P形式的数字货币。点对点的传输意味着一个去中心化的支付系统。</p>
<h2 id="货币特征">货币特征</h2>
<ul>
<li>去中心化：比特币是第一种分布式的虚拟货币，整个网络由用户构成，没有中央银行。去中心化是比特币安全与自由的保证 。</li>
<li>全世界流通：比特币可以在任意一台接入互联网的电脑上管理。不管身处何方，任何人都可以挖掘、购买、出售或收取比特币。</li>
<li>专属所有权：操控比特币需要私钥，它可以被隔离保存在任何存储介质。除了用户自己之外无人可以获取。</li>
<li>低交易费用：可以免费汇出比特币，但最终对每笔交易将收取约1比特分的交易费以确保交易更快执行。</li>
<li>无隐藏成本：作为由A到B的支付手段，比特币没有繁琐的额度与手续限制。知道对方比特币地址就可以进行支付。</li>
<li>跨平台挖掘：用户可以在众多平台上发掘不同硬件的计算能力。</li>
</ul>
<h2 id="比特币与分叉币比较">比特币与分叉币比较</h2>
<p><img src="images/15188818662912.jpg" alt=""></p>
<h1>什么是挖矿</h1>
<p>比特币是怎么产出的？</p>
<p>首先我们来了解一下“区块链”，比特币的核心原理是“区块链”，每一个区块对应一个帐单，将所有的区块链接起来就是区块链，任何交易信息和转账记录都记录在区块链中。要注意的是区块链存在于整个互联网中，所以任何比特币持有者都不担心比特币遭受损失。</p>
<p>每隔一个时间点，比特币系统会在系统节点上生成一个随机代码，互联网中的所有计算机都可以去寻找此代码，谁找到此代码，就会产生一个区块，随即得到一个比特币，这个过程就是人们常说的挖矿。</p>
<h1>挖矿设备介绍</h1>
<p>现在市面上起码有几百种加密货币，主流的可以流通交易的也有不下20种。这么多的加密货币虽然都基于区块链技术，但不管是为了实现某些功能，还是为了形成差异，都会有所不同，从而导致挖不同的币使用的矿机也有所不同。通常来说，一台矿机只能挖一种或几种币，所以要挖什么比就要买什么型号的矿机。当然也存在全能选手，比如电脑就是，只是好多币种用电脑（CPU+显卡）挖的效率太低，无法盈利。</p>
<p>矿机可以有多种分类方式，硬件上可以分为ASIC矿机、GPU矿机、FPGA矿机，以及玩客云那类CDN矿机等等。按照所有权划分，可以分为本地矿机和云矿机。</p>
<p>首先，比特币（BTC）、以太坊（ETH）、比特币现金（BCH）、莱特币（LTC）、达世币（DASH）等主流币种，普遍采用PoW共识机制，挖矿就是通过贡献算力来维护网络安全、稳定的运行，并由此获得奖励币，所以都需要性能尽可能强大的矿机。但针对不同币种的算法，又细分出两种不同的矿机：ASIC矿机与GPU矿机。</p>
<p>中本聪打造比特币的时候，希望比特币是一个去中心化的货币，不仅使用、交易如此，挖矿也应该如此。但是事与愿违，随着比特币等加密货币的价值越来越高，挖矿成为了一个产业，竞争越来越激烈，对挖矿算力的追求越来越高，所以从普通电脑挖矿，进化出了ASIC矿机与GPU矿机。</p>
<p><img src="images/15188819449294.jpg" alt=""></p>
<p>主流矿机比较</p>
<p><img src="images/15188829992827.jpg" alt=""></p>
<p>目前市场上最热门的矿机是蚂蚁矿机S9，具体配置如下</p>
<p><img src="images/15188820707031.jpg" alt=""></p>
<h1>矿池的选择</h1>
<p>矿池的选择主要考虑以下两个因素：</p>
<ul>
<li>分配模式</li>
<li>手续费</li>
</ul>
<h2 id="分配模式说明：">分配模式说明：</h2>
<ol>
<li>Slush方式</li>
</ol>
<p>Slush矿池基于积分制，较老的shares将比新的shares拥有更低的权重，以减少一轮中切换矿池的投机分子。<br>
2. Pay-Per-Share方式</p>
<p>该方式为立即为每一个share支付报酬。该支出来源于矿池现有的比特币资金，因此可以立即取现，而不用等待区块生成完毕或者确认。这样可以避免矿池运营者幕后操纵。这中方法减少了矿工的风险，但将风险转移给了矿池的运营者。运营者可以收取手续费来弥补这些风险可能造成的损失<br>
3. Luke-Jr方式</p>
<p>该方式借用了其他方式的长处，如Slush方式一样，矿工需要提供工作证明来获得shares，如puddinpop方式一样，当区块生成时马上进行支付。但是不象之前的方式，针对一个区块的shares，会被再次利用于生成下一个区块。为了区分一下参与矿工的交易传输费用，只有当矿工的余额超过1BTC时才进行支付。如果没有达到1BTC，那么将在下一个区块生成时进行累计。如果矿工在一周内没有提供一个share，那么矿池会将剩下的余额进行支付，不管余额是多少。<br>
4. Triplemining方式</p>
<p>该方式是将一些中等大小矿池的计算力合并起来，然后将获得奖励的1%按照各个矿池计算力的比例分发给矿池运营者。<br>
5. P2Pool方式</p>
<p>P2Pool的挖矿节点工作在类似比特币区块链的一种shares链上。由于没有中心，所以也不会受到DoS攻击。和其他现有的矿池技术都不一样—每个节点工作的区块，都包括支付给前期shares的所有者以及该节点自己的比特币。99%的奖励（注：50BTC+交易费用）会平均分给矿工，另外0.5%会奖励给生成区块的人。<br>
6. Puddinpop方式</p>
<p>一种使用“元哈希”技术的方式，使用特定的puddinpop挖矿软件，现在没有矿池用这种方式</p>
<p>注意：</p>
<blockquote>
<p>一个share（注：贡献/股份）为一个矿池给客户端的一个合法的工作证明，这也同时是用来生成区块的工作证明，但是没有这么复杂，只需要很少的时间就能达到一个share。</p>
</blockquote>
<h1>收益预测</h1>
<p>蚂蚁矿机单机价格18000元，功率为1350w - 1512w，电费按0.3元/度计算，收益情况如下</p>
<h2 id="计算方式1">计算方式1</h2>
<p>矿池算力排名<br>
<a href="https://btc.com/stats/pool?pool_mode=day" target="_blank" rel="noopener">https://btc.com/stats/pool?pool_mode=day</a></p>
<p>每十分钟产生一个区块，每个区块12.5个比特币，每天全球产生12.5*24*6=1800BTC</p>
<p>s9算力13.5T，当前全网算力22.52EH/s，1E=1024P,1P=1024T,1T=1024G,一台s9一天产生的比特币是[13.5/(22.52<em>1024</em>1024)]*1800≈.001029054BTC</p>
<p>总收入</p>
<p>13.5/(22.52*1024*1024) * 1800 * 65000 * 365 = 24414.295 元</p>
<p>每天耗电36度，每年13140度电，电费约为 1.5*24*0.3 * 365 = 3942 元</p>
<p>总利润为 24414.295 - 3942 = 20472.295 元</p>
<h2 id="计算方式2">计算方式2</h2>
<p>挖矿算器</p>
<p><a href="https://btc.com/tools/mining-calculator" target="_blank" rel="noopener">https://btc.com/tools/mining-calculator</a></p>
<p><img src="images/15188826456334.jpg" alt=""></p>
<h1>参考</h1>
<p><a href="http://www.kuangjijia.com/category/492.html" target="_blank" rel="noopener">http://www.kuangjijia.com/category/492.html</a><br>
<a href="https://shop.bitmain.com/productDetail.htm?pid=00020180205094056650FrOW7847062D" target="_blank" rel="noopener">https://shop.bitmain.com/productDetail.htm?pid=00020180205094056650FrOW7847062D</a><br>
<a href="https://www.zhihu.com/question/20792042" target="_blank" rel="noopener">https://www.zhihu.com/question/20792042</a></p>
<p>挖掘机哪家强？主流矿机比拼，蚂蚁矿机领先<br>
<a href="http://www.sohu.com/a/155209866_114877" target="_blank" rel="noopener">http://www.sohu.com/a/155209866_114877</a><br>
彩云评测：比特大陆蚂蚁S9比特币挖矿机<br>
<a href="https://www.cybtc.com/article-2338-1.html" target="_blank" rel="noopener">https://www.cybtc.com/article-2338-1.html</a><br>
一个挖矿者血本无归的教训总结<br>
<a href="http://www.hnr.cn/finance/zt/b/df/201706/t20170626_2980454.html" target="_blank" rel="noopener">http://www.hnr.cn/finance/zt/b/df/201706/t20170626_2980454.html</a></p>
]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>挖矿</tag>
      </tags>
  </entry>
  <entry>
    <title>正本清源区块链1 笔记</title>
    <url>/2018/02/11/2018-02-10/</url>
    <content><![CDATA[<p>我的微信公众号：pyquant</p>
<p><img src="https://raw.githubusercontent.com/eryk/blog_img/master/20190424095328.jpg" alt=""></p>
<h1>区块链的价值是共识</h1>
<p>共识算法其实分很多种，目前最常提到的，比特币和以太坊所用到的，是叫做POW的共识算法，基于工作量证明的一种信息保障的算法。</p>
<h4 id="POW共识算法，效率低下">POW共识算法，效率低下</h4>
<p>POW目前的局限是出块速度被限定了，比特币差不多10分钟出一个区块，所有交易均需要记录在区块内，所以这样也就限制了交易频率，由于一个区块只有1M，可以承载的交易信息是有限的，所以目前比特币的交易频次被限定在非常低的量级上，差不多一秒才可以支撑不到10个交易。</p>
<p><img src="images/15182776820585.jpg" alt=""></p>
<h4 id="升级方案：">升级方案：</h4>
<ul>
<li>提升出块大小，比特现金把区块大小提升到了8M区块</li>
<li>提升出块速度，降低出块奖励</li>
<li>区块分片化存储的方案，现在比特币这样的区块链虽然是去中心化分布式存储，但每个全节点存储的是记录全集，也就是规模总量和本地查询明显是受到制约的。</li>
<li>闪电网络是指将小额的，频繁交易，先通过一些分支节点进行储存和计算，并在一定时间内整合归并到主链</li>
</ul>
<h1>以太坊是平台</h1>
<p>以太坊可以认为是区块链的第二代平台，因为对智能合约的支持，以太坊的应用想象空间增加了很多，而且其出块效率也明显高于比特币。交易结算周期也明显有了更好的表现。</p>
<p>以太坊是一个平台，上面跑了几千种虚拟货币，其中之一是以太坊自身的代币。而这个平台不但可以发布货币，还可以发布应用，智能合约的应用</p>
<h1>智能合约</h1>
<p>在区块中传递的合约，或者说传递的字符串，不是单纯的字符串和信息，而是一段可执行的脚本，比如说，有触发条件，有交互能力。</p>
<p><img src="images/15182781379931.jpg" alt=""></p>
<blockquote>
<p>比特币是资产还是货币？</p>
</blockquote>
<h1>硬分叉</h1>
<p>硬分叉，是分叉方约定，在某个区块节点开始，启用新的系统架构继续前进，不再和主链保持一致，但同时也继承了该节点之前的所有区块。在这个节点之后，双方各自挖各自的矿，各自爆各自的块，各自走各自的路</p>
<p>其实硬分叉不需要主链允许或通过，任何人都可以发起硬分叉，都可以基于自己的理解和判断发起一个新的分支，但对于信仰者来说，每个分叉都是对共识的撕裂，是在破坏共识。共识算法本身就是防范故障或者恶意分叉的，而人为强行分叉显然是算法所不能处理的。</p>
<h1>EOS</h1>
<p>99%的ICO是基于以太坊的，其实EOS的ICO，目前而言，也是基于以太坊的。但EOS要做的并不只是躺在以太坊身上薅点韭菜的钱。他们的野心还是蛮大的，按照白皮书的说法，感觉是想成为第三代区块链的平台，</p>
<h1>零知识证明</h1>
<p>可以有效保护交易隐私，隐藏交易来源并防止追溯，同时也能保证交易是安全的，因为任何试图修改交易的行为都无法通过验证。</p>
<h1>信息安全</h1>
<p>第一，算力劫持，其实共识算法并非是完美无瑕的，其存在的假设前提是，大部分节点是正确的，可信任的。所以不同的共识算法，理论上都存在一些风险，就是如果坏人掌握了足够多的节点。比如说基于POW共识的比特币，如果一家矿场或者矿池掌握了超过全网51%的算力，理论上可以劫持所有交易，改变交易数据。而基于DPOS的需要保障2/3的节点是可靠的，否则也存在强行分叉或者干扰主链的风险。</p>
<p>第二，重放攻击，这是硬分叉首先需要小心解决的问题，如果系统设计不周全，会导致在分叉上执行的交易被复制到主链，从而带来币拥有者未确认的交易发生，造成损失。所以很多交易所和钱包服务商，不敢去支持名目繁多的分叉币，也是担心由此带来风险。</p>
<p>第三，关于私钥安全，由于新入场的区块链玩家很多，实际上很多人并不明白区块链私钥的意义和价值，会出现这样的情况，认为在交易所，或者钱包的账号和密码是最关键的，保护好了账号密码就万无一失，但糊里糊涂就被人钓鱼，把私钥拱手送出。</p>
<p>第四，交易平台和钱包工具的安全，这在历史上出现过很多起，最近也出现过，一些交易所失窃，或者钱包工具失窃，导致用户的币丢失，而且基本上全都无可挽回。</p>
<p>第五，智能合约的安全，有一个基于区块链众筹的风险投资基金，叫做the DAO，这个众筹计划是用一段智能合约代码约束的，这段代码被发布到了网上，并募集了超过数亿美元的资金，看上去是一个非常不错的故事，但很遗憾，这段代码中有一个安全风险，结果，黑客通过代码漏洞轻松劫持了超过5500万美元</p>
<h1>回顾</h1>
<p>1、共识算法是区块链的核心技术；<br>
2、当前的共识算法存在一些问题，是区块链应用场景普及所需要面对的重大问题。<br>
3、从比特币到以太坊，实际上区块链的技术方案正在演进，但谁是第三代，目前还有待争议。<br>
4、智能合约是区块链应用场景扩展最具有想象力的地方，不过受限于基础架构和算力问题，目前智能合约还很难做出复杂应用，图灵完备在当前阶段尚不具备应用意义。<br>
5、零知识证明还没有全面应用起来，但这个逻辑被认可度是非常高的。<br>
6、共识算法，零知识证明，都是人类数学和信息科学的重大进步，并不单纯是为区块链服务的，更不是为发币的骗子们服务的。<br>
8、信息安全在区块链投资中的重要性非常高，而目前绝大部分新入场的用户对此并没有足够清醒的认识，整个区块链产业出现的严重安全事故已经很多起了，入局者希望能引以为诫。</p>
<h1>代币</h1>
<p>现在主要有两种模式，一种是跟法币绑定的，一个很神奇的东西，叫做USDT，是香港一家公司发行的，他宣称 ，每发行一个USDT，背后都有1美元的储蓄作为担保，并且有多个商业银行担保。也就是和美元1：1购买，1：1赎回，那么他的商业模式是什么呢？赎回的时候收取1%的手续费。</p>
]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>gitlab 持续集成</title>
    <url>/2018/02/05/gitlab%20%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/</url>
    <content><![CDATA[<h1>安装gitlab-runner</h1>
<p><a href="https://docs.gitlab.com/runner/install/index.html" target="_blank" rel="noopener">https://docs.gitlab.com/runner/install/index.html</a></p>
<p>国内镜像地址</p>
<p><a href="https://mirrors.tuna.tsinghua.edu.cn/help/gitlab-ci-multi-runner/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/help/gitlab-ci-multi-runner/</a></p>
<h1>注册Runner</h1>
<p><a href="https://docs.gitlab.com/runner/register/" target="_blank" rel="noopener">https://docs.gitlab.com/runner/register/</a></p>
<h4 id="步骤">步骤</h4>
<p>注意：用户为root用户</p>
<pre><code>root@sw:/home/sw# gitlab-runner register xuqi
Running in system-mode.

Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/):
http://10.168.2.114/

Please enter the gitlab-ci token for this runner:

输入gitlab的token

Please enter the gitlab-ci description for this runner:
[sw]: xuqi
Please enter the gitlab-ci tags for this runner (comma separated):

Whether to lock the Runner to current project [true/false]:
[true]: true
Registering runner... succeeded                     runner=wzb81TcG
Please enter the executor: docker, parallels, shell, virtualbox, docker+machine, kubernetes, docker-ssh, ssh, docker-ssh+machine:
shell
Runner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded!
</code></pre>
<p>注意： token位置在http://localhost/xxx/xxx/settings/ci_cd 页面里的Runners settings里</p>
<h4 id="如何删除在gitlab中不再使用的runner">如何删除在gitlab中不再使用的runner</h4>
<blockquote>
<p>gitlab-runner verify --delete</p>
</blockquote>
<h2 id="关于executors的选择">关于executors的选择</h2>
<p><a href="https://docs.gitlab.com/runner/executors/README.html" target="_blank" rel="noopener">https://docs.gitlab.com/runner/executors/README.html</a></p>
<h1>如何编写.gitlab-ci.yml</h1>
<h3 id="官方文档">官方文档</h3>
<p><a href="https://gitlab.com/help/ci/yaml/README.md" target="_blank" rel="noopener">https://gitlab.com/help/ci/yaml/README.md</a></p>
<h4 id="stages">stages</h4>
<blockquote>
<p>stages用来定义可以被job调用的stages。stages的规范允许有灵活的多级pipelines。</p>
</blockquote>
<h4 id="Jobs">Jobs</h4>
<blockquote>
<p>.gitlab-ci.yml允许指定无限量jobs。每个jobs必须有一个唯一的名字，而且不能是上面提到的关键字。job由一列参数来定义jobs的行为</p>
</blockquote>
<h3 id="demo">demo</h3>
<pre><code>image: python:3.6.1

before_script:
   - export BIZDATE=`date +%Y%m%d`
   - export PROJECT_NAME=$CI_PROJECT_NAME
   - export VERSION=$CI_COMMIT_TAG-$CI_COMMIT_SHA

stages:
  - build
  - package
  - deploy

build:
  stage: build
  script: 
    - /home/gitlab-runner/anaconda3/bin/python3.6 -O -m compileall .
    - find . -name '*.pyc' -exec rename 's/.cpython-36.opt-1//' {} \;
    - find . -name '*.pyc' -execdir mv {} .. \;
    - find . -name '*.py' -type f -print -exec rm {} \;
    - find . -name '__pycache__' -exec rm -rf {} \;
    
package:
  stage: package
  script:
    - rm -rf .git
    - rm -rf .gitlab-ci.yml
    - $(tar -zcf ../deploy-$VERSION.tar.gz .)
    - $(mkdir -p /home/gitlab-runner/backup/$PROJECT_NAME/$BIZDATE)
    - $(cp ../deploy-$VERSION.tar.gz /home/gitlab-runner/backup/$PROJECT_NAME/$BIZDATE/)
    - $(rm -rf ../deploy-$VERSION.tar.gz)
    - rm -rf .

deploy:
  stage: deploy
  script:
    - echo 'deploy'

</code></pre>
<p>服务器版本，使用脚本编写如上内容</p>
<pre><code>before_script:
   - export PROJECT_NAME=$CI_PROJECT_NAME
   - export VERSION=$CI_COMMIT_TAG-$CI_COMMIT_SHA
   - export WORK_DIR=`pwd`
   - export HOST=''

stages:
  - deploy

deploy:
  stage: deploy
  only:
    - /^release-.*$/
  script:
    - ~/script/deploy.sh $WORK_DIR $HOST
</code></pre>
<p><a href="http://deploy.sh" target="_blank" rel="noopener">deploy.sh</a> 脚本内容</p>
<pre><code>workdir=$1
BIZDATE=`date +%Y%m%d`
echo $workdir
cd $workdir
rm -rf .git
rm -rf .gitlab-ci.yml
tar -zcf ../bak-$VERSION.tar.gz .
mkdir -p /home/gitlab-runner/backup/$PROJECT_NAME/$BIZDATE
cp ../bak-$VERSION.tar.gz /home/gitlab-runner/backup/$PROJECT_NAME/$BIZDATE/
rm -rf ../bak-$VERSION.tar.gz
/home/gitlab-runner/anaconda3/bin/python3.6 -O -m compileall .
find . -name '*.pyc' -exec rename 's/.cpython-36.opt-1//' {} \;
find . -name '*.pyc' -execdir mv {} .. \;
find . -name '*.py' -type f -print -exec rm {} \;
find . -name '__pycache__' -exec rm -rf {} \;
#rm -rf $1/*

tar -zcf ../deploy-$VERSION.tar.gz .
for line in `cat hosts`
do
   pem=`echo $line | cut -d \: -f 1`
   host=`echo $line | cut -d \: -f 2`
   echo $pem
   echo $host
   scp -i ~/keys/$pem ../deploy-$VERSION.tar.gz ubuntu@$host:/home/ubuntu/
done
echo 'finish'
</code></pre>
<h1>参考</h1>
<p><a href="https://scarletsky.github.io/2016/07/29/use-gitlab-ci-for-continuous-integration/" target="_blank" rel="noopener">https://scarletsky.github.io/2016/07/29/use-gitlab-ci-for-continuous-integration/</a></p>
<p><a href="https://segmentfault.com/a/1190000010442764" target="_blank" rel="noopener">https://segmentfault.com/a/1190000010442764</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>ci</tag>
      </tags>
  </entry>
  <entry>
    <title>交易订单类型介绍</title>
    <url>/2018/01/13/%E4%BA%A4%E6%98%93%E8%AE%A2%E5%8D%95%E7%B1%BB%E5%9E%8B%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h1>Filled相关Order类型：</h1>
<ol>
<li>
<p>Market Order</p>
<ul>
<li>当订单规模很大时，broker可能会将订单拆分成多个规模较小的订单，导致以不同价格成交不同订单</li>
<li>bid-ask spreads 较大时风险较大</li>
</ul>
</li>
<li>
<p>Limit Order</p>
<ul>
<li>Some brokers may charge different commissions between Market &amp; Limit Orders.</li>
</ul>
</li>
<li>
<p>Market On Close(MOC) Order</p>
<blockquote>
<p>A Market-on-Close (MOC) order is a market order that is submitted to execute as close to the closing price as possible.</p>
</blockquote>
</li>
<li>
<p>Limit On Close(LOC) Order</p>
<blockquote>
<p>A Limit-on-close (LOC) order will be submitted at the close and will execute if the closing price is at or better than the submitted limit price.</p>
</blockquote>
</li>
<li>
<p>Market On Open(MOO) Order</p>
<blockquote>
<p>A Market-on-Open (MOO) order combines a market order with the OPG time in force to create an order that is automatically submitted at the market’s open and fills at the market price.</p>
</blockquote>
</li>
<li>
<p>Limit On Open(LOO) Order</p>
<blockquote>
<p>A Limit-on-Open (LOO) order combines a limit order with the OPG time in force to create an order that is submitted at the market’s open, and that will only execute at the specified limit price or better. Orders are filled in accordance with specific exchange rules.</p>
</blockquote>
</li>
<li>
<p>Martet To Limit(MTL) Order</p>
<blockquote>
<p>A Market-to-Limit (MTL) order is submitted as a market order to execute at the current best market price. If the order is only partially filled, the remainder of the order is canceled and re-submitted as a limit order with the limit price equal to the price at which the filled portion of the order executed.</p>
</blockquote>
</li>
<li>
<p>Iceberg/Reserve Orders</p>
<blockquote>
<p>提交大额股票、权证、期货和期权定单的投资者可能希望取消其定单的所有欲交易量以避免其他市场参与者可以预见并采取相应行动。冰山/保留属性（可在显示尺寸区域设置）可以帮助投资者以增量方式提交提交大宗定单，同时又只公开显示整体定单尺寸的某一特定部分。客户可以通过设置布局管理者或选择相应的区域向TWS的交易页面添加显示尺寸区域，输入定单时客户可以填充此项以显示整个定单的一部分。</p>
</blockquote>
<blockquote>
<p>Investors submitting large volume orders for stocks, warrants, futures and options may wish to conceal the full size of their order to avoid anticipatory action from other market participants. The Iceberg/Reserve attribute, applied through the Display Size field, provides a way to submit large volume orders to the market in increments while publicly displaying only a specified portion of the total order size. The Display Size field can be added to a trading page within TWS by configuring the Layout Manager and selecting the appropriate field, which can be user-populated at the time of order input, to display just a fraction of the entire order.</p>
</blockquote>
</li>
</ol>
<h1>TIMING / DURATION：</h1>
<p>档提交一个订单后，当我们希望订单在指定时间内有效或订单的持续时间，可以使用如下订单类型</p>
<ol>
<li>
<p>Day Order</p>
<blockquote>
<p>A day order is an order to buy or sell a security that automatically expires if not executed on the day the order was placed. If it is not filled, it is canceled, and it is not filled if the limit or stop order price was not met during the trading session. It is one of several different order duration types that determines how long the order is in the market before it is canceled.</p>
</blockquote>
</li>
<li>
<p>Good Till Cancelled(GTC)</p>
<blockquote>
<p>A good 'til canceled (GTC) order can be placed by an investor to buy or sell a security at a specified price that remains active until it is either rescinded by the investor or the trade is executed. GTC orders offer an alternative to placing a sequence of day orders, which expire at the end of each trading day. Rather than leave orders open ended, which poses the risk of being forgotten by investors until an eventual execution, GTC orders are commonly set to expire of 30 to 90 days after the trades are entered.</p>
</blockquote>
<ul>
<li>GTC Buy Orders</li>
<li>GTC Sell Orders</li>
</ul>
</li>
<li>
<p>Good Till Date/Time(GTD)</p>
<blockquote>
<p>The GTD (Good-til-Date/Time) time in force lets you select an expiration date and time up until which an order will continue to work. Setting this attribute requires both a time in force selection of GTD, a date entry in the Expiration Date field, and a time entry in the Expiration Time field if that level of detail is required. Note that if you only enter a good-till date, the unfilled order will cancel at the close of the market on the specified day.</p>
</blockquote>
</li>
<li>
<p>Time Of Day Order</p>
<blockquote>
<p>An order to buy or sell an asset that is placed at a specific time period during a trading session. A time-of-day order enters the market at a predetermined minute and remains good until canceled, unless otherwise specified.</p>
</blockquote>
</li>
</ol>
<h1>CONTIGENCY ORDERS</h1>
<p>如果我们希望订单在满足某些特定条件才执行的话，特别是当你无法一直监视市场的时候。<br>
这些订单类型允许交易者在一定条件满足时自动开仓或平仓。</p>
<ol>
<li>
<p>Fill Or Kill(FOK): 全额即时订单</p>
<p>全额即时订单也称为全部即刻执行否则撤销订单，指要求立即以特定的价格（通常只能为限价）予以执行，否则撤销订单。全额即时订单只能全部成交，而不能成交订单数量的一部分。</p>
<blockquote>
<p>Fill or kill (FOK) is a type of time-in-force designation used in securities trading that instructs a brokerage to execute a transaction immediately and completely or not at all. This type of order is most likely to be used by active traders and is usually for a large quantity of stock. The order must be filled in its entirety or canceled (killed).</p>
</blockquote>
</li>
<li>
<p>Fill And Kill(FAK): 非全额即时订单</p>
<p>非全额即时订单指要求立即以特定的价格（可以为限价或市价）予以执行，否则撤销的订单。非全额即时订单允许部分成交，在部分成交时未成交的部分立刻撤销。</p>
</li>
<li>
<p>Immediate Or Cancel(IOC)</p>
<blockquote>
<p>The Immediate-or Cancel (IOC) time in force applied to an order dictates that any portion of the order that does not fill immediately will be canceled.</p>
</blockquote>
</li>
<li>
<p>All Or None(AON)</p>
<blockquote>
<p>All or none (AON) is an instruction used on a buy or sell order that instructs the broker to fill the order completely or not at all.  ** If there are not enough shares available to fill the order completely, the order is canceled when the market closes. ** An AON order is considered a duration order because the investor provides instructions to the trader about how the order must be filled, which impacts how long the order remains active.</p>
</blockquote>
</li>
</ol>
<h1>For Automatic OPENING of a Position</h1>
<ol>
<li>
<p>Market If Touched(MIT) Order</p>
<p>触价指令是指市场价格只要触及客户所规定的价格水平时就生效的指令。当市场价格触及指定价格时才执行买进或卖出动作。</p>
<blockquote>
<p>A Market if Touched (MIT) is an order to buy (or sell) an instrument below (or above) the market. Its purpose is to take advantage of sudden or unexpected changes in share or other prices and provides investors with a trigger price to set an order in motion. Investors may be waiting for excessive strength (or weakness) to cease, which might be represented by a specific price point. MIT orders can be used to determine whether or not to enter the market once a specific price level has been achieved. This order is held in the system until the trigger price is touched, and is then submitted as a market order. An MIT order is similar to a stop order, except that an MIT sell order is placed above the current market price, and a stop sell order is placed below.</p>
</blockquote>
</li>
<li>
<p>Limit If Touched(LIT) Order: 触及限价定单</p>
<blockquote>
<p>触及限价定单是一种以特定或更优的价格，以及低于（或高于）市价的价格买入（或卖出）金融产品的定单。这类定单被持有在系统中直到触发价格被触及。触及限价定单与限价止损定单相似，除了触及限价卖出定单以高于当前市场价格被下达，而限价止损卖出定单则是以低于市价被下达的。<br>
使用触及限价定单帮助确保，如果定单被执行的话，定单将不会以劣于限价的价格执行。</p>
</blockquote>
</li>
</ol>
<h1>For Automatic CLOSING of a Position</h1>
<ol>
<li>
<p>Stop Order: 止损定单</p>
<blockquote>
<p>止损定单指令系统在用户指定的止损触发价格被达到提交一份买或卖的市价单。止损定单不担保某个特定的执行价格且有可能执行价格远离其止损价格。卖出止损定单总是以低于当前的市场价格下达，通常用于限制某个多头股票头寸的损失或保护其利润。买入止损定单总是以高于当前的市场价格下达，通常用于限制某个卖空头寸的损失或帮助其保护利润。</p>
</blockquote>
</li>
<li>
<p>Stop Limit Order: 止损限价单</p>
<blockquote>
<p>止损限价单指令系统在用户指定的止损触发价格被触碰或超越时提交一份买或卖限价单。该定单由两个基本部分组成：止损价和限价。当一笔交易以止损价或通过止损价发生时，定单成为可执行的并以限价单（以某个特定的价格或更好的价格买入或卖出的定单）的形式进入市场。<br>
止损限价单避免了止损单具有的价格风险（此风险是指不能担保执行价格），但投资人需承担即使在止损价格达到时定单仍不能执行的风险。投资人有可能完全“失去市场”。</p>
</blockquote>
</li>
<li>
<p>Trailing Stop Order: 追踪止损定单</p>
<blockquote>
<p>一个卖出追踪止损定单将止损价格设置为低于市场价格的一个固定金额，并带有附加的“追踪”金额。随着市场价格上涨，止损价格上涨的幅度为追踪金额，但如果股票价格下跌，止损价格不改变，当止损价格被触及时，一份市价定单将被提交。这种方法被设计用来允许投资者对可能损失的最大值指定限额，而不用对可能收益的最大值设定限额。“买入”追踪止损定单是卖出追踪止损定单的镜像，最适合用在下跌的市场中。</p>
</blockquote>
</li>
<li>
<p>Trailing Stop Limit Order: 追踪止损限价定单</p>
<blockquote>
<p>追踪止损限价定单允许投资者对可能损失的最大值指定限额，而不用对可能收益的最大值设定限额。追踪止损限价卖出定单与市场价格一起移动，并根据用户定义的“追踪”金额，连续地以低于市价的固定金额重新计算止损触发价格。限价定单价格同样根据限价抵消被连续地计算。随着市场价格上涨，止损价格和限价的上涨幅度分别为追踪金额和限价抵消，但如果股票价格下跌，止损价格保持不变，当止损价格被触及时，一份限价定单将以最后计算的限价被提交。追踪止损限价“买入”定单是追踪止损限价卖出定单的镜像，并通常被用在下跌的市场中。</p>
</blockquote>
</li>
</ol>
<h1>More COMPLEX Types of Contingency Orders</h1>
<ol>
<li>
<p>Conditional / Contingent Order</p>
</li>
<li>
<p>Bracketed Order: 括号定单</p>
<blockquote>
<p>括号定单旨在通过用两个方向相反的定单将定单“括”起来以帮助您限制损失、锁定利润。给买单加括号，使用的是一份高位卖出限价定单和一份低位卖出止损定单。给卖单加括号，使用的是一份高位买入止损定单和一份低位买入限价定单。<br>
高位和低位括号定单的定单数量与最初的定单数量相匹配。默认情况下，括号定单从当前价格偏离1.0。您能够在特定定单的定单行上更改该偏离金额，也可使用全局配置中的定单预设功能修改产品、合约或策略的默认水平值。</p>
</blockquote>
</li>
<li>
<p>One Cancels Other(OCO) &amp; One Cancels All(OCA) Orders</p>
<blockquote>
<p>A one-cancels-the-other order (OCO) is a pair of orders stipulating that if one order is executed, then the other order is automatically canceled. A one-cancels-the-other order (OCO) combines a stop order with a limit order on an automated trading platform. When either the stop or limit level is reached and the order executed, the other order will be automatically canceled. Seasoned traders use OCO orders to mitigate risk.<br>
one-Cancels All (OCA) order type allows an investor to place multiple and possibly unrelated orders assigned to a group. The aim is to complete just one of the orders, which in turn will cause TWS to cancel the remaining orders. The investor may submit several orders aimed at taking advantage of the most desirable price within the group. Completion of one piece of the group order causes cancellation of the remaining group orders while partial completion causes the group to rebalance. An investor might desire to sell 1000 shares of only ONE of three positions held above prevailing market prices. The OCA order group allows the investor to enter prices at specified target levels and if one is completed, the other two will automatically cancel. Alternatively, an investor may wish to take a LONG position in eMini S&amp;P stock index futures in a falling market or else SELL US treasury futures at a more favorable price. Grouping the two orders using an OCA order type offers the investor two chances to enter a similar position, while only running the risk of taking on a single position.</p>
</blockquote>
</li>
<li>
<p>One Triggers Other(OTO) &amp; One Triggers All(OTA) Orders</p>
</li>
</ol>
<h1>订单优先原则</h1>
<ol>
<li>
<p>价格优先原则</p>
<p>价格优先原则指交易所（或做市商）在对投资者的订单进行撮合时，按照价格的高低原则进行排序，较高价格的买进订单优先于较低价格的买进订单，较低价格的卖出订单优先于较高价格的卖出订单。</p>
</li>
<li>
<p>时间优先原则</p>
<p>按比例分配原则是指所有订单在价格相同的情况下，成交数量基于订单数量按比例进行分配。纽约证券交易所的大厅交易、芝加哥期权交易所等采取了按比例分配的订单优先原则。</p>
</li>
<li>
<p>按比例分配原则</p>
<p>按比例分配原则是指所有订单在价格相同的情况下，成交数量基于订单数量按比例进行分配。纽约证券交易所的大厅交易、芝加哥期权交易所等采取了按比例分配的订单优先原则。</p>
</li>
<li>
<p>数量优先原则</p>
<p>在价格一样、甚至价格一样且无法区分时间先后的情况下，有些交易所规定应遵循数量优先原则。数量优先原则而有两种形式，一是在订单价格相同且时间也相同的情况下，订单数量较大者优先于订单数量较小者；二是在数量上完全匹配的订单（即买进订单和卖出订单在数量上相等）优先于数量不一致的订单。第一种形式使得经纪商优先处理数量较大的订单，因而提高了流动性；第二种形式则减少了订单部分执行的情况。</p>
</li>
<li>
<p>客户优先原则</p>
<p>客户优先原则通常指在同一价格条件下，公共订单优先于经纪商自营账户的订单。纽约证券交易所采取这一原则，客户的订单优先于专家的订单。客户优先原则减轻了客户与经纪商自营之间的利益冲突。</p>
</li>
</ol>
<h1>参考</h1>
<p><a href="https://www.interactivebrokers.com/cn/index.php?f=3361" target="_blank" rel="noopener">https://www.interactivebrokers.com/cn/index.php?f=3361</a><br>
<a href="https://www.zhihu.com/question/23667442" target="_blank" rel="noopener">https://www.zhihu.com/question/23667442</a></p>
]]></content>
      <categories>
        <category>金融</category>
      </categories>
      <tags>
        <tag>order</tag>
      </tags>
  </entry>
  <entry>
    <title>比特币资源收集</title>
    <url>/2017/12/22/%E6%AF%94%E7%89%B9%E5%B8%81%E8%B5%84%E6%BA%90%E6%94%B6%E9%9B%86/</url>
    <content><![CDATA[<h1>资源</h1>
<p><a href="https://github.com/kennethreitz/awesome-coins" target="_blank" rel="noopener">https://github.com/kennethreitz/awesome-coins</a></p>
<h1>数据</h1>
<ol>
<li><a href="https://www.cryptocompare.com/api" target="_blank" rel="noopener">https://www.cryptocompare.com/api</a></li>
</ol>
<blockquote>
<p>Cryptocurrency data API for over 40 exchanges and 600 coins(BTC,ETH,XMR + 600 other cryptos)</p>
</blockquote>
<blockquote>
<p>Get open, high, low, close, volumefrom and volumeto from the each minute historical data. This data is only stored for 7 days, if you need more,use the hourly or daily path. It uses BTC conversion if data is not available because the coin is not trading in the specified currency</p>
</blockquote>
<ol start="2">
<li><a href="https://bitcoincharts.com/about/markets-api/" target="_blank" rel="noopener">https://bitcoincharts.com/about/markets-api/</a></li>
</ol>
<blockquote>
<p>Bitcoincharts’ API is accessable through HTTP<br>
Parameters are passed using GET-requests<br>
returned data is JSON encoded<br>
Don’t query more often than once every 15 minutes!</p>
</blockquote>
<blockquote>
<p>Trade data is available as CSV, delayed by approx. 15 minutes. It will return the 2000 most recent trades.</p>
</blockquote>
<ol start="3">
<li>
<p><a href="http://api.bitcoincharts.com/v1/csv/" target="_blank" rel="noopener">http://api.bitcoincharts.com/v1/csv/</a></p>
</li>
<li>
<p><a href="https://www.coinigy.com/bitcoin-data/" target="_blank" rel="noopener">https://www.coinigy.com/bitcoin-data/</a></p>
</li>
<li>
<p><a href="https://www.quora.com/Where-can-I-get-per-tick-historical-bitcoin-price-data" target="_blank" rel="noopener">https://www.quora.com/Where-can-I-get-per-tick-historical-bitcoin-price-data</a></p>
</li>
<li>
<p><a href="https://coinmarketcap.com/historical/" target="_blank" rel="noopener">https://coinmarketcap.com/historical/</a></p>
</li>
<li>
<p><a href="https://github.com/CoinCapDev/CoinCap.io" target="_blank" rel="noopener">https://github.com/CoinCapDev/CoinCap.io</a></p>
</li>
<li>
<p><a href="http://www.yucezhe.com/product/data#!?series=digital_currency" target="_blank" rel="noopener">http://www.yucezhe.com/product/data#!?series=digital_currency</a></p>
</li>
</ol>
<h1>回测&amp;交易</h1>
<ol>
<li><a href="https://github.com/CoinTK/CoinTK" target="_blank" rel="noopener">https://github.com/CoinTK/CoinTK</a></li>
</ol>
<blockquote>
<p>Bitcoin Trading Algorithm Backtesting and Analysis Toolkit</p>
</blockquote>
<ol start="2">
<li><a href="https://gekko.wizb.it/docs/introduction/about_gekko.html" target="_blank" rel="noopener">https://gekko.wizb.it/docs/introduction/about_gekko.html</a></li>
</ol>
<blockquote>
<p>A bitcoin trading bot written in node - <a href="https://gekko.wizb.it/" target="_blank" rel="noopener">https://gekko.wizb.it/</a></p>
</blockquote>
<ol start="3">
<li>
<p><a href="https://cryptotrader.org/" target="_blank" rel="noopener">https://cryptotrader.org/</a></p>
</li>
<li>
<p><a href="http://www.abuquant.com/lecture/lecture_10.html" target="_blank" rel="noopener">http://www.abuquant.com/lecture/lecture_10.html</a></p>
</li>
</ol>
<blockquote>
<p>比特币, 莱特币的走势数据分析 <a href="http://www.abuquant.com/" target="_blank" rel="noopener">http://www.abuquant.com/</a></p>
</blockquote>
<ol start="5">
<li><a href="https://github.com/ctubio/Krypto-trading-bot" target="_blank" rel="noopener">https://github.com/ctubio/Krypto-trading-bot</a></li>
</ol>
<blockquote>
<p>Self-hosted crypto trading bot (automated high frequency market making) in node.js, angular, typescript and c++ <a href="https://127.0.0.1:3000" target="_blank" rel="noopener">https://127.0.0.1:3000</a></p>
</blockquote>
<ol start="6">
<li><a href="https://www.kaggle.com/smitad/bitcoin-trading-strategy-simulation" target="_blank" rel="noopener">https://www.kaggle.com/smitad/bitcoin-trading-strategy-simulation</a></li>
</ol>
<h1>API</h1>
<h2 id="Python">Python</h2>
<p><a href="https://python-binance.readthedocs.io/en/latest/overview.html" target="_blank" rel="noopener">https://python-binance.readthedocs.io/en/latest/overview.html</a></p>
<blockquote>
<p>binance</p>
</blockquote>
<h2 id="Java">Java</h2>
<p><a href="https://github.com/timmolter/XChange" target="_blank" rel="noopener">https://github.com/timmolter/XChange</a></p>
<blockquote>
<p>XChange is a Java library providing a streamlined API for interacting with 60+ Bitcoin and Altcoin exchanges providing a consistent interface for trading and accessing market data.</p>
</blockquote>
<p><a href="https://www.botvs.com/api" target="_blank" rel="noopener">https://www.botvs.com/api</a></p>
<h1>源码实现</h1>
<p><a href="https://github.com/bisq-network/exchange" target="_blank" rel="noopener">https://github.com/bisq-network/exchange</a></p>
<blockquote>
<p>The decentralized bitcoin exchange <a href="https://bisq.network" target="_blank" rel="noopener">https://bisq.network</a></p>
</blockquote>
<p><a href="https://github.com/bitcoin/bitcoin" target="_blank" rel="noopener">https://github.com/bitcoin/bitcoin</a></p>
<blockquote>
<p>Bitcoin Core integration/staging tree</p>
</blockquote>
<p><a href="https://github.com/jamesob/tinychain" target="_blank" rel="noopener">https://github.com/jamesob/tinychain</a></p>
<blockquote>
<p>A pocket-sized implementation of Bitcoin</p>
</blockquote>
]]></content>
      <categories>
        <category>金融</category>
      </categories>
      <tags>
        <tag>数字货币</tag>
      </tags>
  </entry>
  <entry>
    <title>jupyter性能分析工具</title>
    <url>/2017/12/05/jupyter%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h1>magic functions:</h1>
<ol>
<li>%time: 记录script运行时间</li>
<li>%timeit: 循环n次，记录平均执行时间</li>
<li>%run &amp; %prun: 分析script的执行效率</li>
<li>%lprun: 分析一条语句在function中执行效率</li>
<li>%mprun: 查看script脚本使用内存量</li>
<li>%memit: 循环n次，记录平均内存使用量</li>
</ol>
<h1>安装</h1>
<pre><code>pip install jupyter_contrib_nbextensions
pip install line-profiler
pip install psutil
pip install memory_profiler
</code></pre>
<h1>jupyter load 插件</h1>
<pre><code>%load_ext line_profiler
%load_ext memory_profiler
</code></pre>
<h1>Time Profiling</h1>
<h2 id="time-timeit">time &amp; timeit</h2>
<pre><code class="language-python">In [7]: %time {1 for i in xrange(10*1000000)}
CPU times: user 0.72 s, sys: 0.16 s, total: 0.88 s
Wall time: 0.75 s

In [8]: %timeit 10*1000000
10000000 loops, best of 3: 38.2 ns per loop

In [9]: %timeit -n 1000 10*1000000
1000 loops, best of 3: 67 ns per loop
</code></pre>
<h2 id="prun">%prun</h2>
<pre><code class="language-python">In [10]: from time import sleep

In [11]: def foo(): sleep(1)

In [12]: def bar(): sleep(2)

In [13]: def baz(): foo(), bar()

In [14]: %prun baz()
7 function calls in 3.001 seconds

Ordered by: internal time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     2    3.001    1.500    3.001    1.500 {time.sleep}
     1    0.000    0.000    3.001    3.001 &lt;ipython-input-17-c32ce4852c7d&gt;:1(baz)
     1    0.000    0.000    2.000    2.000 &lt;ipython-input-11-2689ca7390dc&gt;:1(bar)
     1    0.000    0.000    1.001    1.001 &lt;ipython-input-10-e11af1cc2c91&gt;:1(foo)
     1    0.000    0.000    3.001    3.001 &lt;string&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
</code></pre>
<h1>Memory Profiling</h1>
<h2 id="mprun">%mprun</h2>
<pre><code class="language-python">In [17]: %mprun -f foo foo(100000)
Filename: foo.py

Line #    Mem usage    Increment   Line Contents
================================================
     1    20.590 MB     0.000 MB   def foo(n):
     2    20.590 MB     0.000 MB       phrase = 'repeat me'
     3    21.445 MB     0.855 MB       pmul = phrase * n
     4    25.020 MB     3.574 MB       pjoi = ''.join([phrase for x in xrange(n)])
     5    25.020 MB     0.000 MB       pinc = ''
     6    43.594 MB    18.574 MB       for x in xrange(n):
     7    43.594 MB     0.000 MB           pinc += phrase
     8    41.102 MB    -2.492 MB       del pmul, pjoi, pinc
</code></pre>
<p>在jupyter中运行报如下错误：</p>
<pre><code>ERROR: Could not find file &lt;ipython-input-10-6aab78230286&gt;
NOTE: %mprun can only be used on functions defined in physical files, and not in the IPython environment.
</code></pre>
<h2 id="memit">%memit</h2>
<pre><code class="language-python">In [18]: %memit -r 3 [x for x in xrange(1000000)]
maximum of 3: 75.320312 MB per loop
</code></pre>
<h1>参考</h1>
<p><a href="http://jupyter-contrib-nbextensions.readthedocs.io/en/latest/install.html#install-the-python-package" target="_blank" rel="noopener">http://jupyter-contrib-nbextensions.readthedocs.io/en/latest/install.html#install-the-python-package</a></p>
<p><a href="http://mortada.net/easily-profile-python-code-in-jupyter.html" target="_blank" rel="noopener">http://mortada.net/easily-profile-python-code-in-jupyter.html</a></p>
<p><a href="https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/" target="_blank" rel="noopener">https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/</a></p>
<p><a href="http://pynash.org/2013/03/06/timing-and-profiling/" target="_blank" rel="noopener">http://pynash.org/2013/03/06/timing-and-profiling/</a></p>
<p><a href="http://nbviewer.jupyter.org/gist/jiffyclub/3062428" target="_blank" rel="noopener">http://nbviewer.jupyter.org/gist/jiffyclub/3062428</a></p>
<p><a href="http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/notebooks/completion_profiling.html" target="_blank" rel="noopener">http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/notebooks/completion_profiling.html</a></p>
<p><a href="https://pypi.python.org/pypi/memory_profiler/0.41" target="_blank" rel="noopener">https://pypi.python.org/pypi/memory_profiler/0.41</a></p>
<p><a href="https://github.com/rkern/line_profiler" target="_blank" rel="noopener">https://github.com/rkern/line_profiler</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title>使用树莓派+kodi搭建多媒体环境</title>
    <url>/2017/12/03/%E4%BD%BF%E7%94%A8%E6%A0%91%E8%8E%93%E6%B4%BE+osmc%E6%90%AD%E5%BB%BA%E5%A4%9A%E5%AA%92%E4%BD%93%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h1>制作启动盘</h1>
<ul>
<li>下载 RASPBIAN STRETCH WITH DESKTOP，地址如下</li>
</ul>
<p><a href="https://www.raspberrypi.org/downloads/raspbian/" target="_blank" rel="noopener">https://www.raspberrypi.org/downloads/raspbian/</a></p>
<ul>
<li>使用SDFormatter 格式化sd卡</li>
<li>使用win32diskimager将 .img文件写入sd卡</li>
</ul>
<h1>安装kodi</h1>
<p>参考如下步骤</p>
<p><a href="http://kodi.wiki/view/HOW-TO:Install_Kodi_on_Raspberry_Pi" target="_blank" rel="noopener">http://kodi.wiki/view/HOW-TO:Install_Kodi_on_Raspberry_Pi</a></p>
<h1>mac 添加nfs服务</h1>
<p>在 /etc/exports 文件中添加如下内容，IP地址为树莓派ip地址</p>
<blockquote>
<p>/Users/eryk/Documents/movie 192.168.1.10 (rw)</p>
</blockquote>
<p>然后启动nfs服务，树莓派可以从mac目录读取视频文件</p>
<pre><code>sudo nfsd enable
sudo nfsd update
sudo nfsd status
</code></pre>
<h1>树莓派开机mount nfs目录</h1>
<p>使用如下命令mount nfs 目录</p>
<blockquote>
<p>sudo mount 192.168.1.4:/Users/eryk/Documents/movie /home/pi/movie</p>
</blockquote>
<p>如果想在树莓派开机启动自动mount nfs目录，需要在/etc/fstab中添加如下设置</p>
<blockquote>
<p>192.168.1.4:/Users/eryk/Documents/movie /home/pi/movie nfs defaults 0 0</p>
</blockquote>
<h1>kodi设置中文</h1>
<ol>
<li>system–&gt;settings–&gt;Interface–&gt;skin，把 fonts 改成 Arial based；</li>
<li>system–&gt;settings–&gt;Interface–&gt;Regional，改Language改成Chinese(Simple)</li>
</ol>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>树莓派</tag>
        <tag>kodi</tag>
      </tags>
  </entry>
  <entry>
    <title>数据预处理-清洗转换</title>
    <url>/2017/11/30/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86-%E6%B8%85%E6%B4%97%E8%BD%AC%E6%8D%A2/</url>
    <content><![CDATA[<p>转自：<a href="http://www.dataivy.cn/blog/data_etl/?wt_tb=1%7C1511709850969" target="_blank" rel="noopener">http://www.dataivy.cn/blog/data_etl/?wt_tb=1|1511709850969</a></p>
<p>当数据质量校验完成后，针对有问题的数据要进行的是数据清洗和转换，另外还包括对正常数据的转换。数据清洗的主要作用包括：纠正错误、删除重复项、统一规格、修正逻辑、转换构造和数据压缩。</p>
<h1>1. 纠正错误</h1>
<p>错误数据是数据源环境中经常出现的一类问题。数据错误的形式包括：</p>
<ul>
<li>数据值错误：数据直接是错误的，例如超过固定域集、超过极值、拼写错误、属性错误、源错误等。</li>
<li>数据类型错误：数据的存储类型不符合实际情况，如日期类型的以数值型存储，时间戳存为字符串等。</li>
<li>数据编码错误：数据存储的编码错误，例如将UTF-8写成UTF-80。</li>
<li>数据格式错误：数据的存储格式问题，如半角全角字符、中英文字符等。</li>
<li>数据异常错误：如数值数据输成全角数字字符、字符串数据后面有一个回车操作、日期越界、数据前后有不可见字符等。</li>
<li>依赖冲突：某些数据字段间存储依赖关系，例如城市与邮政编码应该满足对应关系，但可能存在二者不匹配的问题。</li>
<li>多值错误：大多数情况下，每个字段存储的是单个值，但也存在一个字段存储多个值的情况，其中有些可能是不符合实际业务规则的。<br>
这类错误产生的原因是业务系统不够健全，尤其是在数据产生之初的校验和入库规则不规范，导致在接收输入后没有进行判断或无法检测而直接写入后台数据库造成的。</li>
</ul>
<h1>2. 删除重复项</h1>
<p>由于各种原因，数据中可能存在重复记录或重复字段（列），对于这些重复项目（行和列）需要做去重处理。</p>
<p>对于重复项的判断，基本思想是“排序和合并”，先将数据库中的记录按一定规则排序，然后通过比较邻近记录是否相似来检测记录是否重复。这里面其实包含了两个操作，一是排序，二是计算相似度。</p>
<p>常见的排序算法：</p>
<ul>
<li>插入排序</li>
<li>冒泡排序</li>
<li>选择排序</li>
<li>快速排序</li>
<li>堆排序</li>
<li>归并排序</li>
<li>基数排序</li>
<li>希尔排序</li>
</ul>
<p>常见的判断相似度的算法：</p>
<ul>
<li>基本的字段匹配算法</li>
<li>标准化欧氏距离</li>
<li>汉明距离</li>
<li>夹角余弦</li>
<li>杰卡德距离</li>
<li>马氏距离</li>
<li>曼哈顿距离</li>
<li>闵可夫斯基距离</li>
<li>欧氏距离</li>
<li>切比雪夫距离</li>
<li>相关系数</li>
<li>信息熵</li>
</ul>
<p>对于重复的数据项，尽量需要经过业务确认并进行整理提取出规则。在清洗转换阶段，对于重复数据项尽量不要轻易做出删除决策，尤其不能将重要的或有业务意义的数据过滤掉，校验和重复确认的工作必不可少。</p>
<h1>3. 统一规格</h1>
<p>由于数据源系统分散在各个业务线，不同业务线对于数据的要求、理解和规格不同，导致对于同一数据对象描述规格完全不同，因此在清洗过程中需要统一数据规格并将一致性的内容抽象出来。</p>
<p>数据字段的规则大致可以从以下几个方面进行统一：</p>
<ul>
<li>名称，对于同一个数据对象的名称首先应该是一致的。例如对于访问深度这个字段，可能的名称包括访问深度、人均页面浏览量、每访问PV数。</li>
<li>类型：同一个数据对象的数据类型必须统一，且表示方法一致。例如普通日期的类型和时间戳的类型需要区分。</li>
<li>单位：对于数值型字段，单位需要统一。例如万、十万、百万等单位度量。</li>
<li>格式：在同一类型下，不同的表示格式也会产生差异。例如日期中的长日期、短日期、英文、中文、年月日制式和缩写等格式均不一样。</li>
<li>长度：同一字段长度必须一致。</li>
<li>小数位数：小数位数对于数值型字段尤为重要，尤其当数据量累积较大时会因为位数的不同而产生巨大偏差。</li>
<li>计数方法：对于数值型等的千分位、科学计数法等的计数方法的统一。</li>
<li>缩写规则：对于常用字段的缩写，例如单位、姓名、日期、月份等的统一。例如将周一表示为Monday还是Mon还是M。</li>
<li>值域：对于离散型和连续型的变量都应该根据业务规则进行统一的值域约束。</li>
<li>约束：是否允许控制、唯一性、外键约束、主键等的统一。</li>
</ul>
<p>统一数据规格的过程中，需要重要的一点是确认不同业务线带来数据的规格一致性，这需要业务部门的参与、讨论和确认，以明确不同体系数据的统一标准。</p>
<h1>4. 修正逻辑</h1>
<p>在多数据源的环境下，很可能存在数据异常或冲突的问题。</p>
<p>例如不同的数据源对于订单数量的数据统计冲突问题，结果出现矛盾的记录。通常，这是由于不同系统对于同一个数据对象的统计逻辑不同而造成的，逻辑的不一致会直接导致结果的差异性；除了统计逻辑和口径的差异，也有因为源数据系统基于性能的考虑，放弃了外键约束，从而导致数据不一致的结果；另外，也存在极小的数据丢失的可能性，通常由于并发量和负载过高、服务器延迟甚至宕机等原因导致的数据采集的差异。</p>
<p>对于这类的数据矛盾，首先需要明确各个源系统的逻辑、条件、口径，然后定义一套符合各个系统采集逻辑的规则，并对异常源系统的采集逻辑进行修正。</p>
<p>某些情况下，也可能存在业务规则的错误导致的数据采集的错误，此时需要从源头纠正错误的采集逻辑，然后再进行数据清洗和转换。</p>
<h1>5. 转换构造</h1>
<p>数据变换是数据清理过程的重要步骤，是对数据的一个的标准的处理，几乎所有的数据处理过程都会涉及该步骤。数据转换常见的内容包括：数据类型转换、数据语义转换、数据值域转换、数据粒度转换、表/数据拆分、行列转换、数据离散化、数据离散化、提炼新字段、属性构造、数据压缩等。</p>
<h2 id="数据类型转换">数据类型转换</h2>
<p>当数据来自不同数据源时，不同类型的数据源数据类型不兼容可能导致系统报错。这时需要将不同数据源的数据类型进行统一转换为一种兼容的数据类型。</p>
<h2 id="数据语义转换">数据语义转换</h2>
<p>传统数据仓库中基于第三范式可能存在维度表、事实表等，此时在事实表中会有很多字段需要结合维度表才能进行语义上的解析。例如，假如字段M的业务含义是浏览器类型，其取值分为是1/2/3/4/5，这5个数字如果不加转换则很难理解为业务语言，更无法在后期被解读和应用。</p>
<h2 id="数据粒度转换">数据粒度转换</h2>
<p>业务系统一般存储的是明细数据，有些系统甚至存储的是基于时间戳的数据，而数据仓库中的数据是用来分析的，不需要非常明细的数据，一般情况下，会将业务系统数据按照数据仓库中不同的粒度需求进行聚合。</p>
<h2 id="表-数据拆分">表/数据拆分</h2>
<p>某些字段可能存储多中数据信息，例如时间戳中包含了年、月、日、小时、分、秒等信息，有些规则中需要将其中部分或者全部时间属性进行拆分，以此来满足多粒度下的数据聚合需求。同样的，一个表内的多个字段，也可能存在表字段拆分的情况。</p>
<h2 id="行列转换">行列转换</h2>
<p>某些情况下，表内的行列数据会需要进行转换（又称为转置），例如协同过滤的计算之前，user和term之间的关系即互为行列并且可相互转换，可用来满足基于项目和基于用户的相似度推荐计算。</p>
<h2 id="数据离散化">数据离散化</h2>
<p>将连续取值的属性离散化成若干区间，来帮助消减一个连续属性的取值个数。例如对于收入这个字段，为了便于做统计，根据业务经验可能分为几个不同的区间：0～3000、3001～5000、5001～10000、10001～30000、大于30000，或者在此基础上分别用1、2、3、4、5来表示。</p>
<h2 id="数据标准化">数据标准化</h2>
<p>不同字段间由于字段本身的业务含义不同，有些时间需要消除变量之间不同数量级造成的数值之间的悬殊差异。例如将销售额进行离散化处理，以消除不同销售额之间由于量级关系导致的无法进行多列的复合计算。数据标准化过程还可以用来解决个别数值较高的属性对聚类结果的影响。</p>
<h2 id="提炼新字段">提炼新字段</h2>
<p>很多情况下，需要基于业务规则提取新的字段，这些字段也称为复合字段。这些字段通常都是基于单一字段产生，但需要进行复合运算甚至复杂算法模型才能得到新的指标。</p>
<h2 id="属性构造">属性构造</h2>
<p>有些建模过程中，也会需要根据已有的属性集构造新的属性。例如，几乎所有的机器学习都会讲样本分为训练集、测试集、验证集三类，那么数据集的分类（或者叫分区）就属于需要新构建的属性，用户做机器学习不同阶段的样本使用。</p>
<p>提示  在某些场景中，也存在一些特殊转换方法。例如在机器学习中，有些值是离散型的数据但存在一定意义，例如最高学历这个字段中包含博士、研究生、大学、高中这4个值，某些算法不支持直接对文本进行计算，此时需要将学历这个字段进行转换。常见的方法是将值域集中的每个值拆解为一个字段，每个字段取值为0或1（布尔型或数值型）。这时，就会出现4个新的字段，对于一条记录来看（通常是一个人），其最高学历只能满足一个，例如字段博士为1，那么其余的字段（研究生、大学、高中）则为0。因此这个过程实际上是将1个字段根据值域（4个值的集合）拆解为4个字段。</p>
<h1>6. 数据压缩</h1>
<p>数据压缩是指在保持原有数据集的完整性和准确性，不丢失有用信息的前提下，按照一定的算法和方式对数据进行重新组织的一种技术方法。</p>
<p>对大规模的数据进行复杂的数据分析与数据计算通常需要耗费大量时间，所以在这之前需要进行数据的约减和压缩，减小数据规模，而且还可能面临交互式的数据挖掘，根据数据挖掘前后对比对数据进行信息反馈。这样在精简数据集上进行数据挖掘显然效率更高，并且挖掘出来的结果与使用原有数据集所获得结果基本相同。</p>
<p>数据压缩的意义不止体现在数据计算过程中，还有利于减少存储空间，提高其传输、存储和处理效率，减少数据的冗余和存储的空间，这对于底层大数据平台具有非常重要的意义。</p>
<p>数据压缩有多种方式可供选择：</p>
<ul>
<li>数据聚合：将数据聚合后使用，例如如果汇总全部数据，那么基于更粗粒度的数据更加便利。</li>
<li>维度约减：通过相关分析手动消除多余属性，使得参与计算的维度（字段）减少；也可以使用主成分分析、因子分析等进行维度聚合，得到的同样是更少的参与计算的数据维度。</li>
<li>数据块消减：利用聚类或参数模型替代原有数据，这种方式常见于多个模型综合进行机器学习和数据挖掘。</li>
<li>数据压缩：数据压缩包括无损压缩和有损压缩两种类型。数据压缩常用于磁盘文件、视频、音频、图像等。</li>
</ul>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>数据清洗</tag>
      </tags>
  </entry>
  <entry>
    <title>深圳市价委托的类型</title>
    <url>/2017/11/24/%E6%B7%B1%E5%9C%B3%E5%B8%82%E4%BB%B7%E5%A7%94%E6%89%98%E7%9A%84%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<p>深圳市价委托的类型有五种，分别为：对手方最优价格、本方最优价格、最优五档即时成交剩余撤销、即时成交剩余撤销（FAK）、全额成交或撤销委托（FOK）。</p>
<h1>对手方最优价格委托</h1>
<p>对手方最优价格委托指投资者无须指定委托价格，当委托申报指令进入交易主机时，交易主机以当时集中申报簿有效竞价范围内对手方队列的最优价格为其指定价格的委托类型。</p>
<ol>
<li>“对手方最优价格委托”无需输入指定价格，如果当时交易主机中集中申报簿的对手方队列中存在有效申报，则与当时对手方队列中价格最优的申报成交；“价格最优的申报”是指集中申报簿中买方“买一”队列或卖方“卖一”队列。</li>
<li>没有完全成交的“对手方最优价格委托”将以限价形式保存在交易主机集中申报簿的本方队列中，其指定价格为委托已成交部分的成交价，也就是委托申报进入交易主机当时对手方队列的最优价格.</li>
<li>如果当时集中申报簿中对手方队列没有有效对手盘，交易主机直接对“对手方最优价格委托”作撤单处理。</li>
</ol>
<h1>本方最优价格委托</h1>
<p>本方最优价格委托是指投资者无须指定委托价格，当委托申报指令进入交易主机时，交易主机以当时集中申报簿有效竞价范围内本方队列最优价格为其指定价格的委托类型。</p>
<ol>
<li>“本方最优价格委托”无需输入指定价格，如果当时交易主机中集中申报簿的本方队列存在有效申报，则以当时本方队列的最优价格为指定价格以限价形式保存在交易主机的集中申报簿中；</li>
<li>如果当时集中申报簿本方队列中没有有效申报，交易主机对“本方最优价格委托”作撤销处理。</li>
</ol>
<h1>即时成交剩余撤销委托</h1>
<p>即时成交剩余撤销委托是指无需指定委托价格，委托进入交易主机时能立即成交部分即予以撮合，未成交部分立即自动撤销的委托方式，一笔委托可以同对手方数笔不同价格的委托撮合成交。</p>
<ol>
<li>“即时成交剩余撤销委托”无需指定价格，如果当时交易主机集中申报簿的对手方队列中存在有效申报，则按对手方申报队列顺序以对手方价格为成交价进行逐笔配对；</li>
<li>“即时成交剩余撤销委托”可以与不同价格的对手方委托撮合成交，直至无有效对手盘（即在涨跌幅限制范围内或在最后一笔成交价为基础的有效竞价范围内交易主机中现有的对手方队列中无委托）；</li>
<li>若“即时成交剩余撤销委托”成交后有剩余的委托（包括部分成交、未有成交的情形），交易主机立即对剩余部分作撤单处理。</li>
</ol>
<h1>最优五档即时成交剩余撤销委托</h1>
<p>“最优五档即时成交剩余撤销委托”是为了避免市场价格波动过大而对“即时成交剩余撤销委托”的改良。其与“即时成交剩余撤销委托”方式的区别就在于“即时成交剩余撤销委托”可以与对手方数笔不同价格的委托撮合，直至无有效对手盘，而“最优五档即时成交剩余撤销委托”只能与一定范围内的对手方队列成交。</p>
<h1>全额成交或撤销委托</h1>
<p>全额成交或撤销委托是指无需指定委托价格，委托进入交易主机时能立即全部成交即予以撮合，否则委托全部撤销的委托方式，该委托可以与对手方数笔不同价格的委托撮合成交。</p>
<h1>问题</h1>
<ol>
<li>
<p>市价委托可以撤单吗</p>
<p>根据《深圳证券交易所交易规则》，市价申报主要包括：对手方最优价格申报、本方最优价格申报、最优五档即时成交剩余撤销申报、即时成交剩余撤销申报、全额成交或撤销申报等五种，其中对手方最优价格申报和本方最优价格申报部分成交时，未成交部分可以主动撤单，其余情况主机会自动撤单，而不能主动撤单。</p>
</li>
</ol>
<h1>测试结果</h1>
<ol>
<li>市价委托(深圳对方最优价格)
<ul>
<li>买入: 按照涨停价下单</li>
<li>卖出: 按照价格0下单</li>
</ul>
</li>
<li>市价委托(深圳本方最优价格)
<ul>
<li>买入: 按照买一价下单，按照时间优先原则排列订单</li>
<li>卖出: 按照卖一价下单，按照时间优先原则排列订单</li>
</ul>
</li>
<li>市价委托(深圳即时成交剩余撤销)
<ul>
<li>买入: 按照涨停价下单</li>
</ul>
</li>
<li>市价委托(上海五档即成剩撤 / 深圳五档即成剩撤)
<ul>
<li>卖出： 按照价格0下单</li>
</ul>
</li>
<li>市价委托(深圳全额成交或撤销)
<ul>
<li>买入: 按照涨停价下单，买入量大于5档时还会继续买入</li>
</ul>
</li>
<li>市价委托(上海五档即成转限价)</li>
</ol>
<h1>参考</h1>
<p>深圳证券交易所关于五种市价委托方式的业务说明<br>
<a href="http://www.szse.cn/UpFiles/Attach/1045/2005/11/14/1442302347.doc" target="_blank" rel="noopener">http://www.szse.cn/UpFiles/Attach/1045/2005/11/14/1442302347.doc</a></p>
]]></content>
      <categories>
        <category>金融</category>
      </categories>
      <tags>
        <tag>期货</tag>
      </tags>
  </entry>
  <entry>
    <title>Tradex笔记</title>
    <url>/2017/11/06/Tradex%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>TradeX 是为从事股票程序化交易的投资者提供一个接口，通过将自己的交易策略编写成计算机代码，实现自动 自动快速读取行情进行分析，以及股票下单、撤单、查询，做到股票的全自动买卖。</p>
<p>优势</p>
<ol>
<li>多语言支持: 封装 C++,C#，Python，Delphi，Java，VB</li>
<li>支持 Level 2 行情(专用账户版，用户需自行购买通达信 Level2 行情账户)包含十档行情、逐笔成交、买卖队列和深圳逐笔委托行情(上交所不对外提供逐笔委托)，需开通通达信的 Level 2 金融终端账户</li>
<li>支持扩展行情: 包含期货、期权、三版、港股数据</li>
<li>支持股票五档实时行情，实测速度比 TdxhqApi 快 10%~30%;包含各周期 K 线、分时、分笔成交，五档行情，F10 公司信息资料</li>
<li>社区活跃</li>
<li>支持市场上绝大部分券商</li>
<li>接口是 tcp 直连获取行情</li>
</ol>
<p>劣势:</p>
<ol>
<li>所有行情接口均要求客户端主动查询请求行情数据，而非推送行情;每种行情接口各自对应于不同的通讯协议。每种行情接口的都可以建立单连接和批量多连接;如果要快速获取大量股票数据，则可能需要用到批量多连接。</li>
<li>只支持windows系统，32 位的 Python 2.7 / Python 3.6.x</li>
<li></li>
</ol>
<p>问题：</p>
<ol>
<li>需要自行维护停牌/退市股票列表，否则查询股票时服务器会自动返回600839的行情信息</li>
<li>分笔数据间隔3s，建议更小的时间间隔获取数据，否则最多可能出现3s延迟</li>
<li>不支持使用同一 Level 2 行情账户同时从多点连接，如果的确需要，您需要购买多个 Level 2 账户。 普通的五档实时行情、扩展行情没有任何 IP 限制，可以多点登录连接</li>
</ol>
]]></content>
      <categories>
        <category>量化交易系统</category>
      </categories>
      <tags>
        <tag>TradeX</tag>
      </tags>
  </entry>
  <entry>
    <title>期货分析与交易入门 live 笔记</title>
    <url>/2017/11/06/%E6%9C%9F%E8%B4%A7%E5%88%86%E6%9E%90%E4%B8%8E%E4%BA%A4%E6%98%93%E5%85%A5%E9%97%A8%20live%20%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1>手续费</h1>
<p>包括期货交易所和期货公司收取，期货公司手续费是交易所基础上的1.1 ～ 1.5 倍</p>
<h1>书籍推荐</h1>
<ol>
<li>道：斯坦利·克罗的《期货交易策略》和江恩的《如何从商品期货交易中获利》</li>
<li>术：中国期货业协会编的《铁矿石期货》，我们必须要了解铁矿石供给来源、中国铁矿石的进口量、铁矿石需求情况、铁矿石现货有哪些关键指标</li>
</ol>
<h1>关于大周期和小周期趋势问题</h1>
<p>把握好小周期，积少成多</p>
<h1>期货定义</h1>
<p>期货合约指由期货交易所统一制订的、规定在将来某一特定的时间和地点交割一定数量和质量实物商品或金融商品的标准化合约。</p>
<h1>期货交易所</h1>
<ol>
<li>商品期货交易所：大连商品期货交易所、郑州商品期货交易所、上海期货交易所</li>
<li>金融期货交易所：中国金融期货交易所</li>
</ol>
<h1>仓单</h1>
<h1>交易平台</h1>
<p>文华财经、随身行（手机版）</p>
<h1>期货结算</h1>
<h1>涨跌停板</h1>
<p>不同品种幅度不同，不同保证金会放大涨跌停，比如10倍杠杆，涨幅5%，对应本金则涨幅50%</p>
<h1>持仓限额</h1>
]]></content>
      <categories>
        <category>金融</category>
      </categories>
      <tags>
        <tag>期货</tag>
      </tags>
  </entry>
  <entry>
    <title>python编译打包pyc脚本</title>
    <url>/2017/10/27/python%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85pyc%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<pre><code class="language-shell">cd $1
python3 -O -m compileall .
find . -name '*.pyc' -exec rename 's/.cpython-36.opt-1//' {} \;
find . -name '*.pyc' -execdir mv {} .. \;
find . -name '*.py' -type f -print -exec rm {} \;
find . -name '__pycache__' -exec rmdir {} \;
zip -r ../$1.zip ./*
</code></pre>
<p>转自：<a href="https://my.oschina.net/bfbd/blog/864310" target="_blank" rel="noopener">https://my.oschina.net/bfbd/blog/864310</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pyc</tag>
      </tags>
  </entry>
  <entry>
    <title>jupyter-notebook启动报错</title>
    <url>/2017/10/23/2017-10-23/</url>
    <content><![CDATA[<p>执行启动命令如下：</p>
<pre><code>nohup jupyter-notebook --ip=127.0.0.1 --port=8801 --notebook-dir=/home/eryk/jupyter_home &amp;
</code></pre>
<p>错误信息如下：</p>
<pre><code>PermissionError: [Errno 13] Permission denied: '/run/user/1000/jupyter'
</code></pre>
<p>解决办法：</p>
<pre><code>unset XDG_RUNTIME_DIR
</code></pre>
<p>参考：<br>
<a href="https://github.com/jupyter/notebook/issues/1318" target="_blank" rel="noopener">https://github.com/jupyter/notebook/issues/1318</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title>linux用户进程执行过程被系统kill掉了</title>
    <url>/2017/09/22/linux%E7%94%A8%E6%88%B7%E8%BF%9B%E7%A8%8B%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%E8%A2%AB%E7%B3%BB%E7%BB%9Fkill%E6%8E%89%E4%BA%86/</url>
    <content><![CDATA[<p>系统日志显示</p>
<pre><code>Sep 22 12:40:44 gpu01 systemd[1]: Stopping User Manager for UID 1001...
Sep 22 12:40:44 gpu01 systemd[1453]: Stopped target Default.
Sep 22 12:40:44 gpu01 systemd[1453]: Stopped target Basic System.
Sep 22 12:40:44 gpu01 systemd[1453]: Stopped target Timers.
Sep 22 12:40:44 gpu01 systemd[1453]: Stopped target Sockets.
Sep 22 12:40:44 gpu01 systemd[1453]: Stopped target Paths.
Sep 22 12:40:44 gpu01 systemd[1453]: Reached target Shutdown.
Sep 22 12:40:44 gpu01 systemd[1453]: Starting Exit the Session...
Sep 22 12:40:44 gpu01 systemd[1453]: Received SIGRTMIN+24 from PID 28725 (kill).
Sep 22 12:40:44 gpu01 systemd[1]: Stopped User Manager for UID 1001.
Sep 22 12:40:44 gpu01 systemd[1]: Removed slice User Slice of xxx.
</code></pre>
<p>google到如下解释：<br>
<a href="https://serverfault.com/questions/774491/what-is-sigrtmin24-in-syslog" target="_blank" rel="noopener">https://serverfault.com/questions/774491/what-is-sigrtmin24-in-syslog</a></p>
<p>当用户session都退出之后，之前后台执行的进程就会被kill掉</p>
<p>所以程序运行最好用nohup xxx &amp;</p>
<p>这还有一篇文章介绍nohup 和 &amp; 的区别，核心意思是说：</p>
<blockquote>
<p>用nohup运行命令可以使命令永久的执行下去，和用户终端没有关系，例如我们断开SSH连接都不会影响他的运行，注意了nohup没有后台运行的意思；&amp;才是后台运行</p>
<p>&amp;是指在后台运行，但当用户推出(挂起)的时候，命令自动也跟着退出</p>
</blockquote>
<p><a href="http://blog.csdn.net/zhang_red/article/details/52789691" target="_blank" rel="noopener">http://blog.csdn.net/zhang_red/article/details/52789691</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>CTA策略(Commodity Trading Advisor Strategy)</title>
    <url>/2017/09/21/2017-09-21/</url>
    <content><![CDATA[<p>CTA(Commodity Trading Advisors)商品交易顾问，通常也被称作管理期货基金，是由于其最初主要活跃于商品市场。CTA基金起源于1949年，随着期货交易品种的不断扩展，CTA基金在资产的风险管理与运作方面显得日趋重要，很多机构投资者诸如养老金、信托基金等都开始大量采用CTA作为他们投资组合中的重要组成部分，并在优化组合、分散风险等方面取得了良好的效果。</p>
<h2 id="研究对象">研究对象</h2>
<ul>
<li>狭义：期货</li>
<li>广义：大宗商品期货，国债期货（利率期货），股票，外汇（包括spots和futures）</li>
</ul>
<h2 id="研究周期">研究周期</h2>
<p>分钟、小时和日线，少量tick</p>
<h2 id="研究方法">研究方法</h2>
<p>量价指标总结规律</p>
<h2 id="特点">特点</h2>
<ul>
<li>低相关性</li>
</ul>
<p>CTA策略投资于期货市场，和市场上大多数基础资产的相关性低</p>
<ul>
<li>高收益（回撤可控）</li>
<li>非线性（横盘期=加仓期）</li>
</ul>
<p>除去低相关、高收益（回撤可控）之外，量化CTA基金还有一个显著的特性就是收益非线性。CTA基金的收益方式体现在低胜率、高盈亏比上，即一年的2-3波行情就能将全年的收益实现，其他时间是处于横盘或者回撤的状态。</p>
<h2 id="CTA分类">CTA分类</h2>
<p>传统的CTA策略都是趋势追随策略</p>
<p>广义上来说，CTA策略应该是趋势追踪策略为主，反转策略为辅</p>
<h2 id="CTA基金分类">CTA基金分类</h2>
<ul>
<li>公募期货基金(Public Funds)</li>
<li>私募期货基金(Private Pools)</li>
<li>个人管理期货账户</li>
</ul>
<h2 id="参考">参考</h2>
<p>什么是CTA策略？<br>
<a href="https://zhuanlan.zhihu.com/p/20494478" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/20494478</a></p>
<p>如何理解CTA交易策略?<br>
<a href="https://www.zhihu.com/question/38663897" target="_blank" rel="noopener">https://www.zhihu.com/question/38663897</a></p>
<p>量化CTA策略背后的逻辑？<br>
<a href="https://www.zhihu.com/question/36960610?sort=created" target="_blank" rel="noopener">https://www.zhihu.com/question/36960610?sort=created</a></p>
<p>CTA Fund<br>
<a href="https://baike.baidu.com/item/CTA%20Fund/1785877" target="_blank" rel="noopener">https://baike.baidu.com/item/CTA Fund/1785877</a></p>
]]></content>
      <categories>
        <category>交易策略</category>
      </categories>
      <tags>
        <tag>cta</tag>
      </tags>
  </entry>
  <entry>
    <title>ETF套利(ETF’s Arbitrage)</title>
    <url>/2017/09/06/ETF%E5%A5%97%E5%88%A9/</url>
    <content><![CDATA[<h1>什么是ETF套利</h1>
<p>ETF套利，是指投资者可以在一级市场通过指定的ETF交易商向基金管理公司用一篮子股票组合申购ETF份额或把ETF份额赎回成一篮子股票组合，同时又可以在二级市场上以市场价格买卖ETF。</p>
<p>假设在某个时段中，某只ETF成分股暴跌，使得该ETF的净值迅速走低，但该ETF的市场价格未能及时跟上，两者短暂地出现了一个价差，这时就可以选择买入ETF一篮子股票组合申购成ETF(以净值计价)，然后将ETF在二级市场上出售(以市场价格计价)，从而实现低买高卖，获取价差。</p>
<h1>ETF套利的原理</h1>
<p>一切要从ETF套利交易开始说起。这项交易模式在国内券商中比较普遍，甚至大型的私募基金也在做这种交易。</p>
<p>ETF套利交易原理通俗地说，就是一价原则，同一件产品在不同的市场有不同的价格，通过利用这些价差来获得盈利。比如上证50ETF对应的是上证50指数(1594.903, -6.48, -0.40%)成份股所组成的一揽子股票组合，组合中各只成份股权重不同，而不同的权重造成了一个兑换比例，投资者可以通过这种比例获得ETF份额，同时这些ETF份额也可以像股票一样在二级市场上交易。</p>
<p>于是ETF套利就有两种交易顺序，一种是从股票二级市场购入一揽子股票，按照一定比例兑换成ETF份额，然后在ETF二级市场上卖出份额，这样的前提是一揽子股票价格比ETF价格低，所谓溢价；另一种则刚好相反，从ETF二级市场买入份额，按照一定比例兑换成一揽子股票，再拿到股票二级市场卖出，这样的前提是ETF价格低于一揽子股票价格，所谓折价。</p>
<p>以光大证券操作ETF套利为例，8月16日上午，套利交易指令已经成交了72.7亿元股票，这说明光大证券正在进行溢价套利，希望用一揽子股票组合兑换ETF份额，并卖出ETF份额。</p>
<p>该公司公告称，捅娄子的策略投资部在当天卖出了18.5亿元的50ETF、180ETF，如此计算尚有近54亿元的误操作股票没有处理，按照上述套利原则，这有可能是当日的溢价套利空间已经消失。</p>
<h1>ETF套利四大技巧</h1>
<p>交易型开放式指数基金（ETF）综合了开放式和封闭式基金的优点，既可向基金公司申购或赎回基金份额，又可像封闭式基金一样在二级市场按照市价进行买卖。由于跨市场间交易形式和交易机制的不同，基金一级市场份额净值和二级市场买卖价格间会存在价差的情况，这样套利空间应运而生。</p>
<h2 id="瞬间套利">瞬间套利</h2>
<p>ETF基本的套利交易主要有两种。一是折价套利，当ETF基金份额二级市场价格小于基金份额净值时，可通过二级市场买入ETF，之后在一级市场赎回一篮子股票，卖出股票组合获取现金。另外一种是溢价套利，和折价套利的方向相反，当ETF二级市场价格超过份额净值时，可买入股票组合，一级市场申购基金份额，之后在二级市场卖出获取现金。这两种就是ETF最常规的套利模式——瞬间套利。需要注意的是由于ETF申购赎回都有最小规模限制，例如100万份，瞬间套利并不适合中小投资者操作。</p>
<h2 id="延时套利">延时套利</h2>
<p>作为瞬间套利的延伸，ETF套利可以采取延时套利模式，也就是说投资者“非同步”地买卖ETF和一篮子股票，完成一圈完整交易的时间较长，这类套利其实更像是T+0交易。</p>
<p>充分利用ETF交易规则，在相对低点，申购或买入ETF，在相对高点，再将ETF卖出或赎回。和瞬间套利相比，这类套利能否成功更看重指数短期的走势，风险更大。在实际操作中，为了确保收益的稳定性，减少风险，一般是当天完成一个交易轮回。</p>
<h2 id="事件套利">事件套利</h2>
<p>第三类ETF套利是事件套利。当ETF标的指数成分股停牌或涨跌停时，可利用ETF进行事件套利，套取看涨的股票或者减持看空的股票。事件套利的收益取决于停牌成分股的个体因素，具体包括两种模式。如果预计成分股在复牌后大幅度上涨，折价套利具体操作是在二级市场买入ETF，在一级市场进行赎回，得到一篮子股票组合，留下停牌股票，卖出其他股票。 　　例如，2008年10月9日长安汽车停牌，2009年2月16日复牌，期间深100指数涨幅32%，汽车板块因国家政策鼓励涨幅更甚，预计长安汽车开盘后会涨停复牌，投资者二级市场成功买入可能性较低。可通过赎回深100ETF，按停牌前价格3.67元获得长安汽车股票，复牌后该股有7个涨停板。如果预估成分股在复牌后会大幅度下跌，溢价套利具体操作是在二级市场上买入其他成分股组合和利用“允许现金替代”的标志，用现金来替代停牌股票，然后在一级市场申购ETF，然后在二级市场上卖出ETF。2008年的“长电事件”是这种套利的典型案例，当年5月8日，长江电力因整体上市开始停牌，此后沪深股市大幅下挫，上证指数跌幅近50%，为了降低损失，将长电套现，可先从二级市场市价买入上证50ETF其他49只股票，之后一级市场申购上证50ETF份额，再在二级市场卖出上证50ETF，顺利将长江电力出货。</p>
<h2 id="期现套利">期现套利</h2>
<p>股指期货和融资融券的推出，为做空A股市场提供了较好的工具。沪深指数期货是国内A股市场第一只也是唯一一只指数期货品种。沪深300指数包含的成分股多达300只，采用完全复制法难道较大，ETF根据标的指数，且能在二级市场交易，是期现套利中较好的现货工具。由于技术上的原因，国内目前还没有直接标的沪深300指数的ETF，多数进行期现套利的投资者采用的是“75%上证180ETF+25%深证100ETF”复合指数ETF作为现货替代品。</p>
<p>自从2010年4月16日股指期货上市以来，上证180ETF和深100ETF二级市场成交量大幅激增。例如，股指期货上市初期，期货相对现货存在着一定的溢价，所谓的套利基本都是买入ETF，卖出股指期货合约，而在期现价差消除后，套利平仓盘卖出ETF，买入股指期货合约。</p>
<h1>ETF套利与衍生品</h1>
<p>A股首只股票指数期货品种沪深300期货自推出以来，成交活跃，已成为期货市场的主力品种之一。理论上来讲，剔除时间价值后，期货应与现货具有完全相同的走势。但事实上，由于期货投资者与现货投资者大多情况下分属两个投资群体，其对市场事件会有不同程度的解读，从而造成期货价格与现货价格的偏离。</p>
<p>一旦价格偏离幅度大于套利成本，则套利投资者可以通过买入低估品种，同时卖出高估品种锁定价差。具体而言，当期货价格高于现货时，投资者可以通过买入沪深300ETF，卖出期货合约，锁定溢价，也就是我们常说的正向套利；相反，当期货价格低于现货时，投资者则可以通过买入期货，卖出沪深300ETF的方式获得反向套利折价。</p>
]]></content>
      <categories>
        <category>交易策略</category>
      </categories>
      <tags>
        <tag>etf</tag>
      </tags>
  </entry>
  <entry>
    <title>PB系统介绍</title>
    <url>/2017/08/28/2017-08-28/</url>
    <content><![CDATA[<h1>概念</h1>
<p>证券公司PB业务（Prime Broker），即主经纪商业务，也称为主券商业务或大宗经纪业务，是指证券公司向专业机构投资者和高净值客户等提供集中托管清算、后台运营、研究支持、杠杆融资、证券拆借、资金募集等一站式综合金融服务。</p>
<h1>模式</h1>
<p><img src="images/15038839873491.jpg" alt=""></p>
<h1>相关文档</h1>
<p>券商PB业务历史演进及对私募基金的影响浅析<br>
<a href="https://wenku.baidu.com/view/c9a4952ae45c3b3566ec8b2e.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/c9a4952ae45c3b3566ec8b2e.html</a></p>
<p>PB业务整体情况介绍及相关建议<br>
<a href="https://wenku.baidu.com/view/ae353b446529647d26285208.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/ae353b446529647d26285208.html</a></p>
<p>PB系统介绍<br>
<a href="https://wenku.baidu.com/view/d55488ca376baf1ffd4fad8f.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/d55488ca376baf1ffd4fad8f.html</a></p>
<p>我国证券公司发展PB业务现状及建议<br>
<a href="https://wenku.baidu.com/view/a794f2475022aaea998f0fba.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/a794f2475022aaea998f0fba.html</a></p>
<p><a href="https://www.zhihu.com/question/41086914/answer/98165214" target="_blank" rel="noopener">https://www.zhihu.com/question/41086914/answer/98165214</a></p>
]]></content>
      <categories>
        <category>量化交易系统</category>
      </categories>
      <tags>
        <tag>pb</tag>
      </tags>
  </entry>
  <entry>
    <title>迅投交易终端</title>
    <url>/2017/08/24/%E8%BF%85%E6%8A%95%E4%BA%A4%E6%98%93%E7%BB%88%E7%AB%AF/</url>
    <content><![CDATA[<p>迅投交易终端——股票期货一体交易</p>
<p>迅投交易终端是一款集股票交易、期货交易、组合交易为一体的智能化金融交易工具软件。其开放式的策略接口、智能算法交易、组合交易管理、多账户管理、高度自定义交易界面、完整数据导入导出功能，为大资金客户、机构客户和自动化交易客户提供了一支虚拟交易团队，高效、精准、优秀地完成每一个任务指令，为用户做多品种交易、大资金分批建仓、对冲套利交易提供极大的便利性，是投资者最强大的交易助手。</p>
<h1>策略接口：</h1>
<p>√ 开放的策略交易接口，无缝对接多种研发平台；<br>
√ 迅投解决交易周边问题，复杂策略高效执行；<br>
√ 策略与交易安全隔离，核心策略安全有保障。</p>
<h1>智能算法交易：</h1>
<p>√ 一键智能下单，软件自动下单、撤单、追单，减少人为操作失误；<br>
√ 支持多种算法交易策略，有效控制冲击成本、减少交易滑点；<br>
√ 各种策略参数在交易界面灵活设置，方便调用；<br>
√ 自动化执行与人工监控相结合，交易任务高效有序完成。</p>
<h1>组合交易管理：</h1>
<p>√ 完美股票组合导入导出，支持多篮子股票并行操作；<br>
√ 配合高效算法交易模块，一键轻松实现一篮子股票的批量交易，自动下单、撤单、追单；<br>
√ 支持多种策略快速下达组合交易任务；<br>
√ 支持预设多种手动补单策略；<br>
√ 篮子交易任务过程动态可视、人为可控。</p>
<h1>多账户管理：</h1>
<p>√ 多账户统一管理，实现多个账户的登录、委托、撤单、查询等功能；<br>
√ 分组管理、分组交易、批量下单；<br>
√ 支持多种交易任务分配方式；<br>
√ 支持跨公司账户交易管理。</p>
<h1>高度自定义交易界面：</h1>
<p>√ 所有模块随意拖拽、组合、定制，打造独一无二的自定义交易界面；<br>
√ 支持下单面板快捷复制，多品种交易尽在掌握；<br>
√ 单面板一键快捷下单，前所未有的轻松交易体验。</p>
<h1>完整数据导入导出：</h1>
<p>√ 支持多种格式的交易、分析数据导入导出，为投资者的交易分析、交易策略实现提供最大的便利性。</p>
<p>原文地址: <a href="http://www.thinktrader.net/product/index.html" target="_blank" rel="noopener">http://www.thinktrader.net/product/index.html</a></p>
]]></content>
      <categories>
        <category>量化交易系统</category>
      </categories>
      <tags>
        <tag>level2</tag>
        <tag>order book</tag>
        <tag>level1</tag>
      </tags>
  </entry>
  <entry>
    <title>leve1、level2 解释</title>
    <url>/2017/08/24/leve1%E5%92%8Clevel2%20%E8%A7%A3%E9%87%8A/</url>
    <content><![CDATA[<h1>Level 1 Market Data</h1>
<p>Basic market data is known as level 1 market data, and includes the following information:</p>
<ul>
<li><strong>Bid price</strong>: The highest price that a trader is willing to buy an asset at.</li>
<li><strong>Bid size</strong>: The number of shares, forex lots or contracts that are available at the bid price.</li>
<li><strong>Ask price</strong>: The lowest price that a trader is willing to sell an asset at.</li>
<li><strong>Ask size</strong>: The number of shares, forex lots or contracts that are available at the ask price.</li>
<li><strong>Last price</strong>: The price at which the most recent trade was completed.</li>
<li><strong>Last size</strong>: The number of shares, forex lots or contracts that were traded in the most recent trade.</li>
</ul>
<p>Level 1 market data provides all of the information needed to trade using most trading systems. If you are trading a price action or indicator based strategy, then Level 1 market data should satisfy your informational needs.</p>
<p>Scalpers, and traders who trade based on changes in how other traders are bidding and offering (offer and ask are used interchangeably), will need Level 2 market data, which provides multiple levels of bids and offers.</p>
<h1>Level 2 Market Data</h1>
<p>Additional market data is known as level 2 market data, the order book, or the depth of market, and includes the following additional information:</p>
<ul>
<li>
<p><strong>Highest bid prices</strong>: The highest 5 to 15 prices (depending upon the market) where traders are willing to buy an asset. This means you not only see the current bid, but also all the bids currently below it. In actively traded stocks, there will typically be bids every $0.01 below the current bid, and in actively traded futures, there will typically be a bid each tick below the current bid. If there is a gap between the current bid and next bid, that typically means the stock or contract may experience a larger bid/ask spread and less volume.</p>
</li>
<li>
<p><strong>Bid sizes</strong>: The number of shares, forex lots or contracts that are available at each of the bid prices.</p>
</li>
<li>
<p><strong>Lowest ask prices</strong>: The lowest 5 to 15 prices (depending upon the market) where traders are willing to sell an asset. This means you not only see the current ask, but also all the asks above the current ask. In actively traded stocks, there will typically be asks every $0.01 above the current ask, and in actively traded futures, there will typically be an ask each tick above the current ask. If there is a gap between the current ask and next ask, that typically means the stock or contract may experience a larger bid/ask spread and less volume.</p>
</li>
<li>
<p><strong>Ask sizes</strong>: The number of shares, forex lots or contracts that are available at each of the ask prices.</p>
</li>
</ul>
<p>Level 2 market data provides the additional information that is needed to trade based on changes that occur in the bids and offers. Level 2 market data is also known as the order book, because it shows the orders that are currently pending for the market. It is also known as the depth of market, or market depth, because it shows the number of contracts (or shares or lots) that are available at each of the bid and ask prices.</p>
<p><img src="images/15035650306126.jpg" alt=""></p>
<h1>Order Book</h1>
<blockquote>
<p>An order book is the list of orders (manual or electronic) that a trading venue (in particular stock exchanges) uses to record the interest of buyers and sellers in a particular financial instrument. A matching engine uses the book to determine which orders can be fulfilled i.e. what trades can be made.   --wikipedia</p>
</blockquote>
<h1>Level2行情</h1>
<h3 id="买卖行情">买卖行情</h3>
<p>买入委托和卖出委托前10档的委托价和委托量,投资者可以看得更远,哪个价位有阻力？哪个价位有支撑？哪个价位有大笔挂单,一目了然。</p>
<h3 id="总买总卖">总买总卖</h3>
<p>当前全部买入(卖出)委托的总量和加权均价,据此投资者可以判断盘中的支撑位(委买均价)、阻力位(委卖均价)、支撑力度(委买总量)、阻力大小(委卖总量),还可以根据这些数据的动态变化分析多空双方力量的变化,寻找行情的转折点</p>
<h3 id="成交明细">成交明细</h3>
<p>在Level-2之前,沪深交易所提供的都是行情快照,大家看到的分笔成交其实是两次快照期间累计的成交量和最后一笔的价格,而逐笔成交则是真实的每笔成交价和成交量的明细数据。逐笔成交极大地提高了行情的透明度。</p>
<h3 id="买卖队列">买卖队列</h3>
<p>买一或卖一的前50笔委托单明细,根据委托单的大小或委托单是否有规律,可以判断委托是机构、大户、或散户所为。</p>
<h1>逐笔数据与分笔数据的根本区别</h1>
<p>国内的Tick数据指的是 按固定时间间隔取个快照记录下来</p>
<ol>
<li>逐笔成交一般显示的数据格式为在几分几秒以多少价格分几笔成交了多少手。在这里我们要注意的是成交手数有时候是带小数点的，这是因为股票买进的股数最少是100股，委托的股数也应是100的整数倍，卖出却没有限制，因此成交的手数会有小数点。另外一点就是如果在成交价格和手数前面没有显示，则一半是默认的1笔。</li>
<li>分时成交一般显示的数据格式为在几分几秒以多少价格成交了多少手。这里需要注意的是成交手数永远是整数，不会出现小数点数字。其中现手累计数就是总手数。总手数也叫做成交量。有些软件在现量后面标注蓝色S和红色B，前者代表卖，后者代表买。目前市面上出现了LEVEL-2行情数据，比较具有代表性的是大智慧，在那里把分笔成交是叫分时成交，实际上就是我们在普通分析软件上F1看到的“分笔成交明细”，但是他和LEVEL-2行情数据提供的逐笔成交明细是不一样的。</li>
<li>分笔数据由于是合成混合数据，它是以最后1笔的买卖方向来表示该时间内（3秒或者6秒）的买卖方向，所以误差很大。（见下图说明）</li>
<li>一个孤独的数字是缺乏意义的，但是一些连续的数字则是充满想像的。一般来说，成交笔数越少，金额越大，表示成交比较强势，反之是弱势。尤其是成交手数比较大而集中的时候，表示有大资金活跃迹象，该股出现价格异动的概率就大，应该引起投资者的注意。而如果半天也没人买或者都是一些小单子在交易，则至少短期不大可能成为好股。</li>
<li>交易数据三要素----成交量、成交价格和成交笔数。不陌生的是前面两个，笔数就是交易批次。在成交量一定的前提下，笔数少说明交易力度强，反之就弱。笔数的变动与数量方向一致，交易为常态，反之就是非常态。</li>
</ol>
<p><img src="images/15035663072399.gif" alt=""></p>
<h1>引用</h1>
<p><a href="https://www.thebalance.com/order-book-level-2-market-data-and-depth-of-market-1031118" target="_blank" rel="noopener">https://www.thebalance.com/order-book-level-2-market-data-and-depth-of-market-1031118</a></p>
<p><a href="https://baike.baidu.com/item/Level-2" target="_blank" rel="noopener">https://baike.baidu.com/item/Level-2</a></p>
<p><a href="https://www.zhihu.com/question/26950456" target="_blank" rel="noopener">https://www.zhihu.com/question/26950456</a></p>
<p><a href="http://www.cnblogs.com/chuncn/archive/2009/03/13/1410144.html" target="_blank" rel="noopener">http://www.cnblogs.com/chuncn/archive/2009/03/13/1410144.html</a></p>
]]></content>
      <categories>
        <category>金融</category>
      </categories>
      <tags>
        <tag>level2</tag>
        <tag>order book</tag>
        <tag>level1</tag>
      </tags>
  </entry>
  <entry>
    <title>jupyter使用pyspark教程</title>
    <url>/2017/08/23/jupyter%E4%BD%BF%E7%94%A8pyspark%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<pre><code>启动jupyter遇到的问题
```
Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: scala.collection.immutable.HashSet$.empty()Lscala/collection/immutable/HashSet;
```
原因是因为spark依赖的scala版本与系统的不匹配，我的系统环境中scala版本是2.11.11，spark2.2.0目录下jars的scala版本是2.11.8
</code></pre>
]]></content>
  </entry>
  <entry>
    <title>anaconda添加第三方源</title>
    <url>/2017/08/19/anaconda%E6%B7%BB%E5%8A%A0%E7%AC%AC%E4%B8%89%E6%96%B9%E6%BA%90/</url>
    <content><![CDATA[<p>Anaconda 是一个用于科学计算的 Python 发行版，支持 Linux, Mac, Windows, 包含了众多流行的科学计算、数据分析的 Python 包。</p>
<p>Anaconda 安装包可以到 <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/</a> 下载。</p>
<p>TUNA 还提供了 Anaconda 仓库的镜像，运行以下命令:</p>
<pre><code>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/

conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/

conda config --set show_channel_urls yes
</code></pre>
<p>说明：</p>
<p>conda-forge:</p>
<blockquote>
<p>A community led collection of recipes, build infrastructure and distributions for the conda package manager.</p>
</blockquote>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Anaconda</tag>
      </tags>
  </entry>
  <entry>
    <title>10分钟搭建github博客</title>
    <url>/2017/08/18/10%E5%88%86%E9%92%9F%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h3 id="搭建github博客，参考如下步骤">搭建github博客，参考如下步骤</h3>
<pre><code>https://pages.github.com/
</code></pre>
<h3 id="注册域名，修改域名DNS地址">注册域名，修改域名DNS地址</h3>
<p>找个域名服务商注册个域名，我使用的是godaddy，如果以后需要指向国内空间，建议在国内域名服务商注册。</p>
<p>注册好域名后，可以直接将域名cname到github博客地址，也可以使用dnspod.com的dns解析域名，在域名管理中把dns地址修改dnspod的dns：</p>
<pre><code>    a.dnspod.com
    b.dnspod.com
    c.dnspod.com
</code></pre>
<p>然后需要在github上做个设置，把域名绑定到github账号上，否则直接访问域名会报404，具体设置步骤如下：</p>
<p><a href="https://help.github.com/articles/adding-or-removing-a-custom-domain-for-your-github-pages-site/" target="_blank" rel="noopener">https://help.github.com/articles/adding-or-removing-a-custom-domain-for-your-github-pages-site/</a></p>
<h3 id="使用hexo管理博客">使用hexo管理博客</h3>
<p>Hexo是一个简单、快速、强大的基于 Github Pages 的博客发布工具，支持Markdown格式，有众多优秀插件和主题。</p>
<p>hexo安装步骤参考：</p>
<p><a href="https://hexo.io/" target="_blank" rel="noopener">https://hexo.io/</a></p>
<p>推荐next博客主题，我的博客就是使用的这个主题，地址是：</p>
<p><a href="https://github.com/iissnan/hexo-theme-next" target="_blank" rel="noopener">https://github.com/iissnan/hexo-theme-next</a></p>
<h3 id="设置-config-yml和github-sshkey">设置_config.yml和github sshkey</h3>
<pre><code>deploy:
  type: git
  repo: https://github.com/YourgithubName/YourgithubName.github.io.git
  branch: master
</code></pre>
<p>hexo发布时会把更新提交到仓库，所以需要设置github sshkey</p>
<h3 id="发布文章">发布文章</h3>
<p>基本命令如下：</p>
<p>进入blog目录下，执行如下命令创建一篇博客</p>
<pre><code>hexo new post 文章标题
</code></pre>
<p>创建好后可以在markdown工具中编写文章，macbook下推荐用MWeb来写博客，MWeb有两种模式：文档库和外部模式，使用外部模式到blog目录下就可以编写了</p>
<p>编写好博客后发布：</p>
<pre><code>hexo d -g
</code></pre>
<p>等待几秒中后刷新博客地址就可以看到更新了。</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title>金融名词解释（持续更新）</title>
    <url>/2017/08/18/%E9%87%91%E8%9E%8D%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/</url>
    <content><![CDATA[<h1>基础概念</h1>
<ul>
<li>
<p>证券市场的交易机制</p>
<p>分为报价驱动市场(Quote-driven Market 和订单驱动市场(Order-driven Market)两类，前者依赖做市商提供流动性，后者通过限价单订单提供流动性,交易通过投资者的买进委托和卖出委托竞价所形成。中国的证券市场属于订单驱动市场，包括股票市场和期货市场。</p>
</li>
<li>
<p>金融市场微观结构理论</p>
<p>是对金融市场上金融资产的交易机制及其价格形成过程和原因进行分析。一般认为该理论产生于1960年代末，德姆塞茨1968年发表的论文《交易成本》奠定了其基础。</p>
</li>
<li>
<p>订单簿(order book)</p>
</li>
</ul>
<p><img src="source/images/15030188412534.jpg" alt=""></p>
<ul>
<li>
<p>信息簿(MessageBook)</p>
<p>包括最明细的订单撮合数据，包括每个订单的下单量、成交价、订单类型等信息</p>
</li>
<li>
<p>对冲</p>
</li>
</ul>
<p>金融学上，对冲（hedge）指特意减低另一项投资的风险的投资。它是一种在减低商业风险的同时仍然能在投资中获利的手法。一般对冲是同时进行两笔行情相关、方向相反、数量相当、盈亏相抵的交易。行情相关是指影响两种商品价格行情的市场供求关系存在同一性，供求关系若发生变化，同时会影响两种商品的价格，且价格变化的方向大体一致。方向相反指两笔交易的买卖方向相反，这样无论价格向什么方向变化，总是一盈一亏。当然要做到盈亏相抵，两笔交易的数量大小须根据各自价格变动的幅度来确定，大体做到数量相当。</p>
<h1>期货</h1>
<ul>
<li>合约</li>
</ul>
<blockquote>
<p>指由期货交易所统一制订的、规定在将来某一特定的时间和地点交割一定数量和质量实物商品或金融商品的标准化合约。通常所说的期货就是指期货合约。</p>
</blockquote>
<ul>
<li>主力合约</li>
</ul>
<blockquote>
<p>指的是成交量最大的合约。因为它是市场上最活跃的合约，所有投机者基本上都在参与这个合约。也有说法是主力合约是持仓量最大的合约，因为通常来讲，持仓量最大的合约也是成交量最大的合约。</p>
</blockquote>
<ul>
<li>IF、IH、IC</li>
</ul>
<blockquote>
<p>IF：（share price）Index Future，直译就是股指期货，标的物是沪深300指数。命名来自英文。<br>
IH：I表示股指期货，H是“沪”的拼音第一个字母。标的物是上证50。命名中英混杂。<br>
IC：I表示股指期货，C是China的第一个字母，标的物是中证500。命名更是不伦不类。</p>
</blockquote>
<ul>
<li>Open Interest</li>
</ul>
<p>未平仓合约，持仓兴趣</p>
]]></content>
      <categories>
        <category>金融</category>
      </categories>
  </entry>
  <entry>
    <title>python装pymssql时遇到error: command &#39;gcc&#39; failed with exit status 1</title>
    <url>/2017/08/17/python%E8%A3%85pymssql%E6%97%B6%E9%81%87%E5%88%B0error-command-gcc-failed-with-exit-status-1/</url>
    <content><![CDATA[<p>执行命令:</p>
<pre><code class="language-shell">pip install pymssql
</code></pre>
<p>报错信息如下：</p>
<pre><code>  Running setup.py install for pymssql ... error
    Complete output from command /home/lthpc/anaconda3/bin/python -u -c &quot;import setuptools, tokenize;__file__='/tmp/pip-build-cpwncwyq/pymssql/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))&quot; install --record /tmp/pip-4l_hdx9q-record/install-record.txt --single-version-externally-managed --compile:
    setup.py: platform.system() =&gt; 'Linux'
    setup.py: platform.architecture() =&gt; ('64bit', 'ELF')
    setup.py: platform.linux_distribution() =&gt; ('debian', 'stretch/sid', '')
    setup.py: platform.libc_ver() =&gt; ('glibc', '2.2.5')
    setup.py: Not using bundled FreeTDS
    setup.py: include_dirs = ['/usr/local/include']
    setup.py: library_dirs = ['/usr/local/lib']
    running install
    running build
    running build_ext
    cythoning _mssql.pyx to _mssql.c
    warning: _mssql.pyx:143:4: Exception already a builtin Cython type
    building '_mssql' extension
    creating build
    creating build/temp.linux-x86_64-3.6
    gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/include -I/home/lthpc/anaconda3/include/python3.6m -c _mssql.c -o build/temp.linux-x86_64-3.6/_mssql.o -DMSDBLIB
    _mssql.c:435:22: fatal error: sqlfront.h: No such file or directory
    compilation terminated.
    error: command 'gcc' failed with exit status 1
</code></pre>
<p>google得到以下解决办法：</p>
<p><a href="https://stackoverflow.com/questions/17368964/trying-to-install-pymssql-on-ubuntu-12-04-using-pip" target="_blank" rel="noopener">https://stackoverflow.com/questions/17368964/trying-to-install-pymssql-on-ubuntu-12-04-using-pip</a></p>
<p>尝试执行命令安装FreeTDS依赖包：</p>
<blockquote>
<p>sudo apt-get install freetds-dev</p>
</blockquote>
<p>如果安装过程出现依赖包版本的问题请先更新ubuntu软件源</p>
<blockquote>
<p>sudo apt-get update</p>
</blockquote>
<p>再次执行pymssql，安装成功:</p>
<pre><code class="language-shell">$ pip install pymssql
Collecting pymssql
  Using cached pymssql-2.1.3.tar.gz
Building wheels for collected packages: pymssql
  Running setup.py bdist_wheel for pymssql ... done
  Stored in directory: /home/lthpc/.cache/pip/wheels/c1/1e/75/bc600eb8a5c9ed77fb1edf15ae5a48b5b427b0390c9a7c9dff
Successfully built pymssql
Installing collected packages: pymssql
Successfully installed pymssql-2.1.3
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pip</tag>
        <tag>pymssql</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker+Grafana+Influxdb+Telegraf安装部署</title>
    <url>/2017/08/14/docker-grafana-influxdb-telegraf%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<h1>docker启动Grafana + Influexdb</h1>
<pre><code>docker run -d \
  --name docker-statsd-influxdb-grafana \
  -p 3003:3003 \
  -p 8083:8083 \
  -p 8086:8086 \
  -p 22022:22 \
  -p 8125:8125/udp \
  samuelebistoletti/docker-statsd-influxdb-grafana:latest
</code></pre>
<h1>设置InfluxDB</h1>
<p>打开 http:localhost:8083，设置用户名密码</p>
<pre><code>Username: root
Password: root
Port: 8086
</code></pre>
<h1>设置Grafana</h1>
<p>打开http:localhost:3003，登录用户名密码为</p>
<pre><code>Username: root
Password: root
</code></pre>
<p>登录之后按步骤设置数据源</p>
<pre><code>Url: http://localhost:8086
Database:	telegraf
User: telegraf
Password:	telegraf
</code></pre>
<h1>安装并设置TeleGraf</h1>
<p>下载地址：<a href="https://portal.influxdata.com/downloads" target="_blank" rel="noopener">https://portal.influxdata.com/downloads</a></p>
<h2 id="设置">设置</h2>
<p>/etc/telegraf/telegraf.conf<br>
修改influxdb地址，用户名及密码，设置hostname</p>
<p>重启服务</p>
<blockquote>
<p>service telegraf restart</p>
</blockquote>
<h1>导入Grafana Dashboard</h1>
<p>下载最新版本的dashboard配置：<br>
<a href="https://grafana.com/dashboards/1443/revisions" target="_blank" rel="noopener">https://grafana.com/dashboards/1443/revisions</a></p>
<p>在grafana的新建dashboard并导入配置，完成。</p>
<h1>注意</h1>
<p>docker内部已经启动了telegraf，如果不需要的话可以停掉，在多台服务器上安装并配置Telegraf写入同一Influxdb就可以实现对集群进行系统监控。</p>
<h1>参考</h1>
<ol>
<li><a href="https://linux.cn/article-5252-1.html" target="_blank" rel="noopener">使用 Grafana、collectd 和 InfluxDB 打造现代监控系统</a></li>
<li><a href="https://github.com/samuelebistoletti/docker-statsd-influxdb-grafana" target="_blank" rel="noopener">docker-statsd-influxdb-grafana</a></li>
<li><a href="https://anomaly.io/collectd-metrics-to-influxdb/" target="_blank" rel="noopener">Send CollectD metrics to InfluxDB</a></li>
</ol>
]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Grafana</tag>
        <tag>Docker</tag>
        <tag>Influxdb</tag>
        <tag>Telegraf</tag>
      </tags>
  </entry>
  <entry>
    <title>我的jupyter插件列表</title>
    <url>/2017/08/13/%E6%88%91%E7%9A%84jupyter%E6%8F%92%E4%BB%B6%E5%88%97%E8%A1%A8/</url>
    <content><![CDATA[<h1>jupyter notebook extensions 安装</h1>
<h2 id="pip方式安装">pip方式安装</h2>
<blockquote>
<p>pip install jupyter_contrib_nbextensions</p>
</blockquote>
<p>或者通过github master branch安装</p>
<blockquote>
<p>pip install <a href="https://github.com/ipython-contrib/jupyter_contrib_nbextensions/tarball/master" target="_blank" rel="noopener">https://github.com/ipython-contrib/jupyter_contrib_nbextensions/tarball/master</a></p>
</blockquote>
<h2 id="Conda方式安装">Conda方式安装</h2>
<blockquote>
<p>conda install -c conda-forge jupyter_contrib_nbextensions</p>
</blockquote>
<h2 id="通过github-仓库安装">通过github 仓库安装</h2>
<pre><code>git clone https://github.com/ipython-contrib/jupyter_contrib_nbextensions.git
pip install -e jupyter_contrib_nbextensions
</code></pre>
<h1>常用插件列表</h1>
<p>全部jupyter插件列表在这里：</p>
<blockquote>
<p><a href="http://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions.html" target="_blank" rel="noopener">http://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions.html</a></p>
</blockquote>
<p>我觉得有用的插件列表：</p>
<ul>
<li>
<p>Autopep8</p>
<p>格式化代码插件</p>
</li>
<li>
<p>Codefolding 和 Codefolding in Editor</p>
<p>折叠代码插件</p>
</li>
<li>
<p>Collapsible Headings</p>
<p>Collapsible Headings icon<br>
Allows notebook to have collapsible sections, separated by headings</p>
</li>
<li>
<p>contrib_nbextensions_help_item：帮助</p>
</li>
<li>
<p>Drag and Drop</p>
<p>This extension allows dragging&amp;dropping images from the desktop or other programs into a notebook.</p>
</li>
<li>
<p>ExecuteTime：</p>
<p>Display when each cell has been executed and how long it took</p>
</li>
<li>
<p>Freeze</p>
<p>Freeze cells (forbid editing and executing) or make them read-only</p>
</li>
<li>
<p>highlighter</p>
<p>markdown内容高亮</p>
</li>
<li>
<p>Hinterland</p>
<p>实时的自动补全，很不错</p>
</li>
<li>
<p>Nbextensions dashboard tab &amp; Nbextensions edit menu item</p>
</li>
<li>
<p>ScrollDown</p>
<p>自动向下滚动输出</p>
</li>
<li>
<p>Snippets &amp; Snippets Menu</p>
<p>插入代码片段的，可以自定义</p>
</li>
<li>
<p>Table of Contents (2)</p>
<p>The toc2 extension enables to collect all running headers and display them in a floating window, as a sidebar or with a navigation menu. The extension is also draggable, resizable, collapsable, dockable and features automatic numerotation with unique links ids, and an optional toc cell.</p>
</li>
<li>
<p>table_beautifier</p>
<p>Add bootstrap styling to tables in markdown cells and in html/md output</p>
</li>
<li>
<p>Toggle all line numbers</p>
<p>Add a toolbar button and hotkey to toggle all cells’ line numbers on or off</p>
</li>
<li>
<p>Tree Filter</p>
<p>An extension that allows you to filter by filename in the Jupyter notebook file tree (aka dashboard) page.</p>
</li>
<li>
<p>Variable Inspector</p>
<p>The Variable Inspector extension collects all defined variables and display them in a floating window.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>jupyer</tag>
      </tags>
  </entry>
  <entry>
    <title>pandas使用pivot时遇到Index contains duplicate entries, cannot reshape</title>
    <url>/2017/08/10/pandas%E4%BD%BF%E7%94%A8pivot%E6%97%B6%E9%81%87%E5%88%B0Index-contains-duplicate-entries-cannot-reshape/</url>
    <content><![CDATA[<p>原始数据样例如下：</p>
<pre><code>date        code    count
20170801    000001      10
20170802    000002      20
20170803    000001      30
</code></pre>
<p>使用pivot处理数据，命令如下：</p>
<blockquote>
<p>df.pivot(index=‘date’,columns=‘code’,values=‘count’)</p>
</blockquote>
<p>执行后报错信息：</p>
<blockquote>
<p>ValueError: Index contains duplicate entries, cannot reshape</p>
</blockquote>
<p>说明column有重复信息，使用如下命令检查重复列内容：</p>
<pre><code>df = df.sort_values(['date','code','count'],ascending=[1,1,0])
df = df[(df['code'] == df['code'].shift(1)) | (df['code'] == df['code'].shift(-1))]
</code></pre>
<p>发现code列有哪些重复数据</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>使用https方式连接jupyter</title>
    <url>/2017/08/09/jupyter%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>生成jupyter配置文件:</p>
<blockquote>
<p>jupyter notebook --generate-config</p>
</blockquote>
<p>注意：generate前是两个&quot;-&quot;，不知道为什么markdown里是两个，显示的时候成一个了</p>
<p>生成好的配置文件位置在：</p>
<blockquote>
<p>~/.jupyter/jupyter_notebook_config.py</p>
</blockquote>
<p>生成自签名SSL证书：</p>
<blockquote>
<p>cd ~/.jupyter<br>
openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout notebook_cert.key -out notebook_cert.pem</p>
</blockquote>
<p>生成一个登录密码的hash:</p>
<blockquote>
<p>python -c “import IPython;print(IPython.lib.passwd())”</p>
</blockquote>
<p>修改jupyter_notebook_config.py配置文件中的如下选项：</p>
<pre><code>c.NotebookApp.certfile = u'/home/xxxx/.jupyter/notebook_cert.pem'
c.NotebookApp.keyfile = u'/home/xxxx/.jupyter/notebook_cert.key'
c.NotebookApp.password = u'sha1:991ec9cd2f39:522598e19891bab1ecaa3a9072e71f45811af9f2'
</code></pre>
<p>重启jupyter，使用浏览器访问：https://your_domain_or_IP:8080</p>
<h3 id="参考">参考</h3>
<p><a href="http://jupyter-notebook.readthedocs.io/en/latest/public_server.html#notebook-server-security" target="_blank" rel="noopener">http://jupyter-notebook.readthedocs.io/en/latest/public_server.html#notebook-server-security</a></p>
<p><a href="http://www.linuxdiyf.com/linux/22884.html" target="_blank" rel="noopener">http://www.linuxdiyf.com/linux/22884.html</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>jupyter</tag>
      </tags>
  </entry>
</search>
